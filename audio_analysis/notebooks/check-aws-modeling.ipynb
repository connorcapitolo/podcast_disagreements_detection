{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cbb80f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1eb84537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/ec2-user/anaconda3/envs/tensorflow2_p36:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_anaconda_depends         5.1.0                    py36_2  \r\n",
      "_libgcc_mutex             0.1                 conda_forge    conda-forge\r\n",
      "_openmp_mutex             4.5                       1_gnu    conda-forge\r\n",
      "absl-py                   0.14.1                   pypi_0    pypi\r\n",
      "aiobotocore               1.3.0                    pypi_0    pypi\r\n",
      "aiohttp                   3.7.4.post0              pypi_0    pypi\r\n",
      "aioitertools              0.7.1              pyhd8ed1ab_0    conda-forge\r\n",
      "alabaster                 0.7.12                     py_0    conda-forge\r\n",
      "anaconda-client           1.7.2                      py_0    conda-forge\r\n",
      "anaconda-project          0.9.1              pyhd8ed1ab_0    conda-forge\r\n",
      "anyio                     2.1.0            py36h5fab9bb_0    conda-forge\r\n",
      "appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge\r\n",
      "argh                      0.26.2          pyh9f0ad1d_1002    conda-forge\r\n",
      "argon2-cffi               20.1.0           py36h8f6f2f9_2    conda-forge\r\n",
      "argparse                  1.4.0                    pypi_0    pypi\r\n",
      "asn1crypto                1.4.0              pyh9f0ad1d_0    conda-forge\r\n",
      "astor                     0.8.1                    pypi_0    pypi\r\n",
      "astroid                   2.8.2                    pypi_0    pypi\r\n",
      "astropy                   4.1              py36ha112f06_2    conda-forge\r\n",
      "async-timeout             3.0.1                   py_1000    conda-forge\r\n",
      "async_generator           1.10                       py_0    conda-forge\r\n",
      "atk-1.0                   2.36.0               h3371d22_4    conda-forge\r\n",
      "atomicwrites              1.4.0              pyh9f0ad1d_0    conda-forge\r\n",
      "attrs                     21.2.0                   pypi_0    pypi\r\n",
      "autopep8                  1.5.5              pyh44b312d_0    conda-forge\r\n",
      "autovizwidget             0.19.1                   pypi_0    pypi\r\n",
      "awscli                    1.22.4                   pypi_0    pypi\r\n",
      "babel                     2.9.0              pyhd3deb0d_0    conda-forge\r\n",
      "backcall                  0.2.0              pyh9f0ad1d_0    conda-forge\r\n",
      "backports                 1.0                        py_2    conda-forge\r\n",
      "backports.functools_lru_cache 1.6.1                      py_0    conda-forge\r\n",
      "backports.shutil_get_terminal_size 1.0.0                      py_3    conda-forge\r\n",
      "bcrypt                    3.2.0                    pypi_0    pypi\r\n",
      "beautifulsoup4            4.9.3              pyhb0f4dca_0    conda-forge\r\n",
      "binutils_impl_linux-64    2.35.1               h193b22a_2    conda-forge\r\n",
      "binutils_linux-64         2.35                h67ddf6f_30    conda-forge\r\n",
      "bitarray                  1.6.3            py36h8f6f2f9_0    conda-forge\r\n",
      "bkcharts                  0.2                      py36_0    conda-forge\r\n",
      "black                     20.8b1                     py_1    conda-forge\r\n",
      "blaze                     0.11.3                   py36_0    conda-forge\r\n",
      "bleach                    3.3.0              pyh44b312d_0    conda-forge\r\n",
      "blosc                     1.21.0               h9c3ff4c_0    conda-forge\r\n",
      "bokeh                     2.2.3            py36h5fab9bb_0    conda-forge\r\n",
      "boto                      2.49.0                     py_0    conda-forge\r\n",
      "boto3                     1.20.4                   pypi_0    pypi\r\n",
      "botocore                  1.23.4                   pypi_0    pypi\r\n",
      "bottleneck                1.3.2            py36h92226af_3    conda-forge\r\n",
      "brotlipy                  0.7.0           py36h8f6f2f9_1001    conda-forge\r\n",
      "bzip2                     1.0.8                h7f98852_4    conda-forge\r\n",
      "c-ares                    1.17.1               h36c2ea0_0    conda-forge\r\n",
      "ca-certificates           2021.5.30            ha878542_0    conda-forge\r\n",
      "cached-property           1.5.2                    pypi_0    pypi\r\n",
      "cachetools                4.2.4                    pypi_0    pypi\r\n",
      "cairo                     1.16.0            h7979940_1007    conda-forge\r\n",
      "certifi                   2021.10.8                pypi_0    pypi\r\n",
      "cffi                      1.15.0                   pypi_0    pypi\r\n",
      "chardet                   3.0.4           py36h9880bd3_1008    conda-forge\r\n",
      "charset-normalizer        2.0.6                    pypi_0    pypi\r\n",
      "click                     7.1.2              pyh9f0ad1d_0    conda-forge\r\n",
      "cloudpickle               1.6.0                      py_0    conda-forge\r\n",
      "clyent                    1.2.2                      py_1    conda-forge\r\n",
      "colorama                  0.4.3                    pypi_0    pypi\r\n",
      "contextlib2               0.6.0.post1                py_0    conda-forge\r\n",
      "contextvars               2.4                        py_0    conda-forge\r\n",
      "coverage                  6.0.1                    pypi_0    pypi\r\n",
      "cryptography              35.0.0                   pypi_0    pypi\r\n",
      "curl                      7.71.1               he644dc0_8    conda-forge\r\n",
      "cycler                    0.10.0                     py_2    conda-forge\r\n",
      "cython                    0.29.22          py36hc4f0c31_0    conda-forge\r\n",
      "cytoolz                   0.11.0           py36h8f6f2f9_3    conda-forge\r\n",
      "dask                      2021.2.0           pyhd8ed1ab_0    conda-forge\r\n",
      "dask-core                 2021.2.0           pyhd8ed1ab_0    conda-forge\r\n",
      "dataclasses               0.8                      pypi_0    pypi\r\n",
      "datashape                 0.5.4                      py_1    conda-forge\r\n",
      "dbus                      1.13.6               hfdff14a_1    conda-forge\r\n",
      "decorator                 4.4.2                      py_0    conda-forge\r\n",
      "defusedxml                0.6.0                      py_0    conda-forge\r\n",
      "diff-match-patch          20200713           pyh9f0ad1d_0    conda-forge\r\n",
      "dill                      0.3.4                    pypi_0    pypi\r\n",
      "distributed               2021.2.0         py36h5fab9bb_0    conda-forge\r\n",
      "distro                    1.6.0                    pypi_0    pypi\r\n",
      "docker                    5.0.0                    pypi_0    pypi\r\n",
      "docker-compose            1.29.2                   pypi_0    pypi\r\n",
      "dockerpty                 0.4.1                    pypi_0    pypi\r\n",
      "docopt                    0.6.2                    pypi_0    pypi\r\n",
      "docutils                  0.15.2                   pypi_0    pypi\r\n",
      "entrypoints               0.3             pyhd8ed1ab_1003    conda-forge\r\n",
      "environment-kernels       1.1.1                    pypi_0    pypi\r\n",
      "et_xmlfile                1.0.1                   py_1001    conda-forge\r\n",
      "expat                     2.2.10               h9c3ff4c_0    conda-forge\r\n",
      "fastcache                 1.1.0            py36h8f6f2f9_2    conda-forge\r\n",
      "filelock                  3.0.12             pyh9f0ad1d_0    conda-forge\r\n",
      "flake8                    3.8.4                      py_0    conda-forge\r\n",
      "flask                     1.1.2              pyh9f0ad1d_0    conda-forge\r\n",
      "flask-cors                3.0.10                   pypi_0    pypi\r\n",
      "font-ttf-dejavu-sans-mono 2.37                 hab24e00_0    conda-forge\r\n",
      "font-ttf-inconsolata      2.001                hab24e00_0    conda-forge\r\n",
      "font-ttf-source-code-pro  2.030                hab24e00_0    conda-forge\r\n",
      "font-ttf-ubuntu           0.83                 hab24e00_0    conda-forge\r\n",
      "fontconfig                2.13.1            hba837de_1004    conda-forge\r\n",
      "fonts-conda-ecosystem     1                             0    conda-forge\r\n",
      "fonts-conda-forge         1                             0    conda-forge\r\n",
      "freetype                  2.10.4               h0708190_1    conda-forge\r\n",
      "fribidi                   1.0.10               h36c2ea0_0    conda-forge\r\n",
      "fsspec                    2021.4.0                 pypi_0    pypi\r\n",
      "future                    0.18.2           py36h5fab9bb_3    conda-forge\r\n",
      "gast                      0.2.2                    pypi_0    pypi\r\n",
      "gcc_impl_linux-64         9.3.0               h70c0ae5_18    conda-forge\r\n",
      "gcc_linux-64              9.3.0               hf25ea35_30    conda-forge\r\n",
      "gdk-pixbuf                2.42.2               h0c95a7a_2    conda-forge\r\n",
      "get_terminal_size         1.0.0                haa9412d_0  \r\n",
      "gettext                   0.19.8.1          h0b5b191_1005    conda-forge\r\n",
      "gevent                    21.1.2           py36h8f6f2f9_0    conda-forge\r\n",
      "giflib                    5.2.1                h36c2ea0_2    conda-forge\r\n",
      "glib                      2.66.7               h9c3ff4c_0    conda-forge\r\n",
      "glib-tools                2.66.7               h9c3ff4c_0    conda-forge\r\n",
      "glob2                     0.7                        py_0    conda-forge\r\n",
      "gmp                       6.2.1                h58526e2_0    conda-forge\r\n",
      "gmpy2                     2.1.0b1          py36hbea7ad4_1    conda-forge\r\n",
      "google-auth               1.35.0                   pypi_0    pypi\r\n",
      "google-auth-oauthlib      0.4.6                    pypi_0    pypi\r\n",
      "google-pasta              0.2.0                    pypi_0    pypi\r\n",
      "graphite2                 1.3.13            h58526e2_1001    conda-forge\r\n",
      "graphviz                  2.46.1               h93c640b_4    conda-forge\r\n",
      "greenlet                  0.4.17           py36h8f6f2f9_2    conda-forge\r\n",
      "grpcio                    1.41.0                   pypi_0    pypi\r\n",
      "gst-plugins-base          1.18.3               h04508c2_0    conda-forge\r\n",
      "gstreamer                 1.18.3               h3560a44_0    conda-forge\r\n",
      "gtk2                      2.24.33              hab0c2f8_0    conda-forge\r\n",
      "gts                       0.7.6                h64030ff_2    conda-forge\r\n",
      "gxx_impl_linux-64         9.3.0               hd87eabc_18    conda-forge\r\n",
      "gxx_linux-64              9.3.0               h3fbe746_30    conda-forge\r\n",
      "h5py                      2.10.0                   pypi_0    pypi\r\n",
      "harfbuzz                  2.7.4                h5cf4720_0    conda-forge\r\n",
      "hdf5                      1.10.6          nompi_h6a2412b_1114    conda-forge\r\n",
      "hdijupyterutils           0.19.1                   pypi_0    pypi\r\n",
      "heapdict                  1.0.1                      py_0    conda-forge\r\n",
      "helpdev                   0.7.1              pyhd8ed1ab_0    conda-forge\r\n",
      "horovod                   0.19.5                   pypi_0    pypi\r\n",
      "html5lib                  1.1                pyh9f0ad1d_0    conda-forge\r\n",
      "icu                       68.1                 h58526e2_0    conda-forge\r\n",
      "idna                      3.3                      pypi_0    pypi\r\n",
      "idna_ssl                  1.1.0           py36h9f0ad1d_1001    conda-forge\r\n",
      "imageio                   2.9.0                      py_0    conda-forge\r\n",
      "imagesize                 1.2.0                      py_0    conda-forge\r\n",
      "immutables                0.15             py36h8f6f2f9_0    conda-forge\r\n",
      "importlib-metadata        4.8.2                    pypi_0    pypi\r\n",
      "importlib_metadata        3.7.0                hd8ed1ab_0    conda-forge\r\n",
      "iniconfig                 1.1.1              pyh9f0ad1d_0    conda-forge\r\n",
      "intel-openmp              2020.2                      254  \r\n",
      "intervaltree              3.0.2                      py_0    conda-forge\r\n",
      "ipykernel                 5.5.0            py36he448a4c_1    conda-forge\r\n",
      "ipyparallel               6.3.0            py36h5fab9bb_2    conda-forge\r\n",
      "ipython                   7.16.1           py36he448a4c_2    conda-forge\r\n",
      "ipython_genutils          0.2.0                      py_1    conda-forge\r\n",
      "ipywidgets                7.6.3              pyhd3deb0d_0    conda-forge\r\n",
      "isort                     5.7.0              pyhd8ed1ab_0    conda-forge\r\n",
      "itsdangerous              1.1.0                      py_0    conda-forge\r\n",
      "jbig                      2.1               h516909a_2002    conda-forge\r\n",
      "jdcal                     1.4.1                      py_0    conda-forge\r\n",
      "jedi                      0.17.2           py36h5fab9bb_1    conda-forge\r\n",
      "jeepney                   0.6.0              pyhd8ed1ab_0    conda-forge\r\n",
      "jinja2                    2.11.3             pyh44b312d_0    conda-forge\r\n",
      "jmespath                  0.10.0             pyh9f0ad1d_0    conda-forge\r\n",
      "joblib                    1.0.1              pyhd8ed1ab_0    conda-forge\r\n",
      "jpeg                      9d                   h36c2ea0_0    conda-forge\r\n",
      "json5                     0.9.5              pyh9f0ad1d_0    conda-forge\r\n",
      "jsonschema                3.2.0                      py_2    conda-forge\r\n",
      "jupyter                   1.0.0            py36h5fab9bb_6    conda-forge\r\n",
      "jupyter-console           6.4.0                    pypi_0    pypi\r\n",
      "jupyter-packaging         0.7.12             pyhd8ed1ab_0    conda-forge\r\n",
      "jupyter_client            6.1.11             pyhd8ed1ab_1    conda-forge\r\n",
      "jupyter_core              4.7.1            py36h5fab9bb_0    conda-forge\r\n",
      "jupyter_server            1.4.1            py36h5fab9bb_0    conda-forge\r\n",
      "jupyterlab                3.1.18                   pypi_0    pypi\r\n",
      "jupyterlab_launcher       0.13.1                     py_2    conda-forge\r\n",
      "jupyterlab_pygments       0.1.2              pyh9f0ad1d_0    conda-forge\r\n",
      "jupyterlab_server         2.3.0              pyhd8ed1ab_0    conda-forge\r\n",
      "jupyterlab_widgets        1.0.0              pyhd8ed1ab_1    conda-forge\r\n",
      "keras                     2.3.0                    pypi_0    pypi\r\n",
      "keras-applications        1.0.8                    pypi_0    pypi\r\n",
      "keras-preprocessing       1.1.0                    pypi_0    pypi\r\n",
      "kernel-headers_linux-64   2.6.32              h77966d4_13    conda-forge\r\n",
      "keyring                   22.0.1           py36h5fab9bb_0    conda-forge\r\n",
      "kiwisolver                1.3.1            py36h605e78d_1    conda-forge\r\n",
      "krb5                      1.17.2               h926e7f8_0    conda-forge\r\n",
      "lazy-object-proxy         1.5.2            py36h8f6f2f9_1    conda-forge\r\n",
      "lcms2                     2.12                 hddcbb42_0    conda-forge\r\n",
      "ld_impl_linux-64          2.35.1               hea4e1c9_2    conda-forge\r\n",
      "libblas                   3.9.0                8_openblas    conda-forge\r\n",
      "libcblas                  3.9.0                8_openblas    conda-forge\r\n",
      "libclang                  11.0.1          default_ha53f305_1    conda-forge\r\n",
      "libcurl                   7.71.1               hcdd3856_8    conda-forge\r\n",
      "libedit                   3.1.20191231         he28a2e2_2    conda-forge\r\n",
      "libev                     4.33                 h516909a_1    conda-forge\r\n",
      "libevent                  2.1.10               hcdb4288_3    conda-forge\r\n",
      "libffi                    3.3                  h58526e2_2    conda-forge\r\n",
      "libgcc-devel_linux-64     9.3.0               h7864c58_18    conda-forge\r\n",
      "libgcc-ng                 9.3.0               h2828fa1_18    conda-forge\r\n",
      "libgd                     2.3.0                h47910db_1    conda-forge\r\n",
      "libgfortran-ng            9.3.0               hff62375_18    conda-forge\r\n",
      "libgfortran5              9.3.0               hff62375_18    conda-forge\r\n",
      "libglib                   2.66.7               h1f3bc88_0    conda-forge\r\n",
      "libgomp                   9.3.0               h2828fa1_18    conda-forge\r\n",
      "libiconv                  1.16                 h516909a_0    conda-forge\r\n",
      "liblapack                 3.9.0                8_openblas    conda-forge\r\n",
      "libllvm10                 10.0.1               he513fc3_3    conda-forge\r\n",
      "libllvm11                 11.0.1               hf817b99_0    conda-forge\r\n",
      "libnghttp2                1.43.0               h812cca2_0    conda-forge\r\n",
      "libopenblas               0.3.12          pthreads_h4812303_1    conda-forge\r\n",
      "libpng                    1.6.37               h21135ba_2    conda-forge\r\n",
      "libpq                     13.1                 hfd2b0eb_1    conda-forge\r\n",
      "libprotobuf               3.15.2               h780b84a_0    conda-forge\r\n",
      "librsvg                   2.50.3               hfa39831_1    conda-forge\r\n",
      "libsodium                 1.0.18               h36c2ea0_1    conda-forge\r\n",
      "libspatialindex           1.9.3                h9c3ff4c_3    conda-forge\r\n",
      "libssh2                   1.9.0                hab1572f_5    conda-forge\r\n",
      "libstdcxx-devel_linux-64  9.3.0               hb016644_18    conda-forge\r\n",
      "libstdcxx-ng              9.3.0               h6de172a_18    conda-forge\r\n",
      "libtiff                   4.2.0                hdc55705_0    conda-forge\r\n",
      "libtool                   2.4.6             h58526e2_1007    conda-forge\r\n",
      "libuuid                   2.32.1            h7f98852_1000    conda-forge\r\n",
      "libuv                     1.41.0               h7f98852_0    conda-forge\r\n",
      "libwebp                   1.2.0                h3452ae3_0    conda-forge\r\n",
      "libwebp-base              1.2.0                h7f98852_0    conda-forge\r\n",
      "libxcb                    1.13              h7f98852_1003    conda-forge\r\n",
      "libxkbcommon              1.0.3                he3ba5ed_0    conda-forge\r\n",
      "libxml2                   2.9.10               h72842e0_3    conda-forge\r\n",
      "libxslt                   1.1.33               h15afd5d_2    conda-forge\r\n",
      "llvmlite                  0.35.0           py36h05121d2_1    conda-forge\r\n",
      "locket                    0.2.0                      py_2    conda-forge\r\n",
      "lxml                      4.6.3                    pypi_0    pypi\r\n",
      "lz4-c                     1.9.3                h9c3ff4c_0    conda-forge\r\n",
      "lzo                       2.10              h516909a_1000    conda-forge\r\n",
      "markdown                  3.3.4                    pypi_0    pypi\r\n",
      "markupsafe                1.1.1            py36h8f6f2f9_3    conda-forge\r\n",
      "matplotlib                3.3.4            py36h5fab9bb_0    conda-forge\r\n",
      "matplotlib-base           3.3.4            py36hd391965_0    conda-forge\r\n",
      "mccabe                    0.6.1                      py_1    conda-forge\r\n",
      "mistune                   0.8.4           py36h8f6f2f9_1003    conda-forge\r\n",
      "mkl                       2020.2                      256  \r\n",
      "mkl-service               2.3.0            py36h8c4c3a4_2    conda-forge\r\n",
      "mock                      4.0.3            py36h5fab9bb_1    conda-forge\r\n",
      "more-itertools            8.7.0              pyhd8ed1ab_0    conda-forge\r\n",
      "mpc                       1.1.0             h04dde30_1009    conda-forge\r\n",
      "mpfr                      4.0.2                he80fd80_1    conda-forge\r\n",
      "mpi                       1.0                     openmpi    conda-forge\r\n",
      "mpmath                    1.2.1              pyhd8ed1ab_0    conda-forge\r\n",
      "msgpack-python            1.0.2            py36h605e78d_1    conda-forge\r\n",
      "multidict                 5.1.0            py36h8f6f2f9_1    conda-forge\r\n",
      "multipledispatch          0.6.0                      py_0    conda-forge\r\n",
      "multiprocess              0.70.12.2                pypi_0    pypi\r\n",
      "mypy_extensions           0.4.3            py36h5fab9bb_3    conda-forge\r\n",
      "mysql-common              8.0.23               ha770c72_1    conda-forge\r\n",
      "mysql-libs                8.0.23               h935591d_1    conda-forge\r\n",
      "nb_conda                  2.2.1            py36h5fab9bb_4    conda-forge\r\n",
      "nb_conda_kernels          2.3.1            py36h5fab9bb_0    conda-forge\r\n",
      "nbclassic                 0.2.6              pyhd8ed1ab_0    conda-forge\r\n",
      "nbclient                  0.5.2              pyhd8ed1ab_0    conda-forge\r\n",
      "nbconvert                 6.0.7            py36h5fab9bb_3    conda-forge\r\n",
      "nbformat                  5.1.2              pyhd8ed1ab_1    conda-forge\r\n",
      "ncurses                   6.2                  h58526e2_4    conda-forge\r\n",
      "nest-asyncio              1.4.3              pyhd8ed1ab_0    conda-forge\r\n",
      "networkx                  2.5                        py_0    conda-forge\r\n",
      "nltk                      3.4.4                      py_0    conda-forge\r\n",
      "nose                      1.3.7                   py_1006    conda-forge\r\n",
      "notebook                  6.4.4                    pypi_0    pypi\r\n",
      "nspr                      4.29                 h9c3ff4c_1    conda-forge\r\n",
      "nss                       3.62                 hb5efdd6_0    conda-forge\r\n",
      "numba                     0.52.0           py36h284efc9_0    conda-forge\r\n",
      "numexpr                   2.7.2            py36h284efc9_0    conda-forge\r\n",
      "numpy                     1.19.5                   pypi_0    pypi\r\n",
      "numpydoc                  1.1.0                      py_1    conda-forge\r\n",
      "oauthlib                  3.1.1                    pypi_0    pypi\r\n",
      "odo                       0.5.1                      py_1    conda-forge\r\n",
      "olefile                   0.46               pyh9f0ad1d_1    conda-forge\r\n",
      "opencv-python             4.5.1.48                 pypi_0    pypi\r\n",
      "openmpi                   4.1.0                h9b22176_1    conda-forge\r\n",
      "openmpi-mpicc             4.1.0                h7f98852_1    conda-forge\r\n",
      "openmpi-mpicxx            4.1.0                h4bd325d_1    conda-forge\r\n",
      "openpyxl                  3.0.6              pyhd8ed1ab_0    conda-forge\r\n",
      "openssl                   1.1.1k               h7f98852_0    conda-forge\r\n",
      "opt-einsum                3.3.0                    pypi_0    pypi\r\n",
      "packaging                 21.2                     pypi_0    pypi\r\n",
      "pandas                    1.1.5                    pypi_0    pypi\r\n",
      "pandoc                    2.11.4               h7f98852_0    conda-forge\r\n",
      "pandocfilters             1.4.2                      py_1    conda-forge\r\n",
      "pango                     1.42.4               h69149e4_5    conda-forge\r\n",
      "paramiko                  2.8.0                    pypi_0    pypi\r\n",
      "parso                     0.7.0              pyh9f0ad1d_0    conda-forge\r\n",
      "partd                     1.1.0                      py_0    conda-forge\r\n",
      "patchelf                  0.11                 he1b5a44_0    conda-forge\r\n",
      "path                      15.1.2           py36h5fab9bb_0    conda-forge\r\n",
      "path.py                   12.5.0                        0    conda-forge\r\n",
      "pathlib2                  2.3.5            py36h5fab9bb_3    conda-forge\r\n",
      "pathos                    0.2.8                    pypi_0    pypi\r\n",
      "pathspec                  0.8.1              pyhd3deb0d_0    conda-forge\r\n",
      "patsy                     0.5.1                      py_0    conda-forge\r\n",
      "pcre                      8.44                 he1b5a44_0    conda-forge\r\n",
      "pep8                      1.7.1                      py_0    conda-forge\r\n",
      "pexpect                   4.8.0              pyh9f0ad1d_2    conda-forge\r\n",
      "pickleshare               0.7.5                   py_1003    conda-forge\r\n",
      "pillow                    8.3.2                    pypi_0    pypi\r\n",
      "pip                       21.2.4                   pypi_0    pypi\r\n",
      "pixman                    0.40.0               h36c2ea0_0    conda-forge\r\n",
      "pkginfo                   1.7.0              pyhd8ed1ab_0    conda-forge\r\n",
      "platformdirs              2.4.0                    pypi_0    pypi\r\n",
      "plotly                    5.3.1                    pypi_0    pypi\r\n",
      "pluggy                    0.13.1           py36h5fab9bb_4    conda-forge\r\n",
      "ply                       3.11                       py_1    conda-forge\r\n",
      "pox                       0.3.0                    pypi_0    pypi\r\n",
      "ppft                      1.6.6.4                  pypi_0    pypi\r\n",
      "prometheus_client         0.9.0              pyhd3deb0d_0    conda-forge\r\n",
      "prompt-toolkit            3.0.5                      py_0    conda-forge\r\n",
      "prompt_toolkit            1.0.15                     py_1    conda-forge\r\n",
      "protobuf                  3.19.1                   pypi_0    pypi\r\n",
      "protobuf3-to-dict         0.1.5                    pypi_0    pypi\r\n",
      "psutil                    5.8.0            py36h8f6f2f9_1    conda-forge\r\n",
      "psycopg2                  2.7.5                    pypi_0    pypi\r\n",
      "pthread-stubs             0.4               h36c2ea0_1001    conda-forge\r\n",
      "ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\r\n",
      "py                        1.10.0             pyhd3deb0d_0    conda-forge\r\n",
      "py4j                      0.10.7                   pypi_0    pypi\r\n",
      "pyarrow                   5.0.0                    pypi_0    pypi\r\n",
      "pyasn1                    0.4.8                    pypi_0    pypi\r\n",
      "pyasn1-modules            0.2.8                    pypi_0    pypi\r\n",
      "pycodestyle               2.6.0              pyh9f0ad1d_0    conda-forge\r\n",
      "pycosat                   0.6.3           py36h8f6f2f9_1006    conda-forge\r\n",
      "pycparser                 2.21                     pypi_0    pypi\r\n",
      "pycrypto                  2.6.1           py36he6145b8_1005    conda-forge\r\n",
      "pycurl                    7.43.0.6         py36h66a4f8d_1    conda-forge\r\n",
      "pydocstyle                5.1.1                      py_0    conda-forge\r\n",
      "pyflakes                  2.2.0              pyh9f0ad1d_0    conda-forge\r\n",
      "pyfunctional              1.4.3                    pypi_0    pypi\r\n",
      "pygal                     2.4.0                    pypi_0    pypi\r\n",
      "pygments                  2.8.0              pyhd8ed1ab_0    conda-forge\r\n",
      "pyinstrument              3.4.2                    pypi_0    pypi\r\n",
      "pyinstrument-cext         0.2.4                    pypi_0    pypi\r\n",
      "pykerberos                1.2.1                    pypi_0    pypi\r\n",
      "pylint                    2.11.1                   pypi_0    pypi\r\n",
      "pyls-black                0.4.6              pyh9f0ad1d_0    conda-forge\r\n",
      "pyls-spyder               0.3.2              pyhd8ed1ab_0    conda-forge\r\n",
      "pynacl                    1.4.0                    pypi_0    pypi\r\n",
      "pyodbc                    4.0.30           py36hc4f0c31_1    conda-forge\r\n",
      "pyopenssl                 20.0.1             pyhd8ed1ab_0    conda-forge\r\n",
      "pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\r\n",
      "pyqt                      5.12.3           py36h5fab9bb_7    conda-forge\r\n",
      "pyqt-impl                 5.12.3           py36h7ec31b9_7    conda-forge\r\n",
      "pyqt5-sip                 4.19.18          py36hc4f0c31_7    conda-forge\r\n",
      "pyqtchart                 5.12             py36h7ec31b9_7    conda-forge\r\n",
      "pyqtwebengine             5.12.1           py36h7ec31b9_7    conda-forge\r\n",
      "pyrsistent                0.18.0                   pypi_0    pypi\r\n",
      "pysocks                   1.7.1            py36h5fab9bb_3    conda-forge\r\n",
      "pyspark                   2.4.0                    pypi_0    pypi\r\n",
      "pytables                  3.6.1            py36hb7ec5aa_3    conda-forge\r\n",
      "pytest                    6.2.2            py36h5fab9bb_0    conda-forge\r\n",
      "python                    3.6.13          hffdb5ce_0_cpython    conda-forge\r\n",
      "python-dateutil           2.8.2                    pypi_0    pypi\r\n",
      "python-dotenv             0.19.2                   pypi_0    pypi\r\n",
      "python-jsonrpc-server     0.4.0              pyh9f0ad1d_0    conda-forge\r\n",
      "python-language-server    0.36.2             pyhd8ed1ab_0    conda-forge\r\n",
      "python_abi                3.6                     1_cp36m    conda-forge\r\n",
      "pytz                      2021.3                   pypi_0    pypi\r\n",
      "pywavelets                1.1.1            py36h92226af_3    conda-forge\r\n",
      "pyxdg                     0.26                       py_0    conda-forge\r\n",
      "pyyaml                    5.4.1                    pypi_0    pypi\r\n",
      "pyzmq                     22.0.3           py36h81c33ee_0    conda-forge\r\n",
      "qdarkstyle                2.8.1              pyhd8ed1ab_2    conda-forge\r\n",
      "qt                        5.12.9               hda022c4_4    conda-forge\r\n",
      "qtawesome                 1.0.2              pyhd8ed1ab_0    conda-forge\r\n",
      "qtconsole                 5.0.2              pyhd8ed1ab_0    conda-forge\r\n",
      "qtpy                      1.9.0                      py_0    conda-forge\r\n",
      "readline                  8.0                  he28a2e2_2    conda-forge\r\n",
      "regex                     2020.11.13       py36h8f6f2f9_1    conda-forge\r\n",
      "requests                  2.26.0                   pypi_0    pypi\r\n",
      "requests-kerberos         0.12.0                   pypi_0    pypi\r\n",
      "requests-oauthlib         1.3.0                    pypi_0    pypi\r\n",
      "rope                      0.18.0             pyh9f0ad1d_0    conda-forge\r\n",
      "rsa                       4.7.2                    pypi_0    pypi\r\n",
      "rtree                     0.9.7            py36hb415506_1    conda-forge\r\n",
      "ruamel_yaml               0.15.80         py36h8f6f2f9_1004    conda-forge\r\n",
      "s3fs                      2021.4.0                 pypi_0    pypi\r\n",
      "s3transfer                0.5.0                    pypi_0    pypi\r\n",
      "sagemaker                 2.60.0                   pypi_0    pypi\r\n",
      "sagemaker-pyspark         1.4.2                    pypi_0    pypi\r\n",
      "scikit-image              0.16.2           py36hb3f55d8_0    conda-forge\r\n",
      "scikit-learn              0.24.1           py36he4fde30_0    conda-forge\r\n",
      "scipy                     1.5.3            py36h9e8f40b_0    conda-forge\r\n",
      "seaborn                   0.11.1               hd8ed1ab_1    conda-forge\r\n",
      "seaborn-base              0.11.1             pyhd8ed1ab_1    conda-forge\r\n",
      "secretstorage             3.3.1            py36h5fab9bb_0    conda-forge\r\n",
      "send2trash                1.5.0                      py_0    conda-forge\r\n",
      "setuptools                58.5.3                   pypi_0    pypi\r\n",
      "shap                      0.39.0                   pypi_0    pypi\r\n",
      "simplegeneric             0.8.1                      py_1    conda-forge\r\n",
      "singledispatch            3.6.0              pyh44b312d_0    conda-forge\r\n",
      "sip                       4.19.24          py36hc4f0c31_3    conda-forge\r\n",
      "six                       1.16.0                   pypi_0    pypi\r\n",
      "sklearn                   0.0                      pypi_0    pypi\r\n",
      "slicer                    0.0.7                    pypi_0    pypi\r\n",
      "smclarify                 0.1                      pypi_0    pypi\r\n",
      "smdebug                   1.0.12                   pypi_0    pypi\r\n",
      "smdebug-rulesconfig       1.0.1                    pypi_0    pypi\r\n",
      "sniffio                   1.2.0            py36h5fab9bb_1    conda-forge\r\n",
      "snowballstemmer           2.1.0              pyhd8ed1ab_0    conda-forge\r\n",
      "sortedcollections         2.1.0              pyhd8ed1ab_0    conda-forge\r\n",
      "sortedcontainers          2.3.0              pyhd8ed1ab_0    conda-forge\r\n",
      "soupsieve                 2.0.1                      py_1    conda-forge\r\n",
      "sparkmagic                0.15.0                   pypi_0    pypi\r\n",
      "sphinx                    3.5.1              pyhd8ed1ab_0    conda-forge\r\n",
      "sphinxcontrib             1.0                      py36_1  \r\n",
      "sphinxcontrib-applehelp   1.0.2                      py_0    conda-forge\r\n",
      "sphinxcontrib-devhelp     1.0.2                      py_0    conda-forge\r\n",
      "sphinxcontrib-htmlhelp    1.0.3                      py_0    conda-forge\r\n",
      "sphinxcontrib-jsmath      1.0.1                      py_0    conda-forge\r\n",
      "sphinxcontrib-qthelp      1.0.3                      py_0    conda-forge\r\n",
      "sphinxcontrib-serializinghtml 1.1.4                      py_0    conda-forge\r\n",
      "sphinxcontrib-websupport  1.2.4              pyh9f0ad1d_0    conda-forge\r\n",
      "spyder                    4.2.0            py36h5fab9bb_0    conda-forge\r\n",
      "spyder-kernels            1.10.0           py36h5fab9bb_0    conda-forge\r\n",
      "sqlalchemy                1.3.23           py36h8f6f2f9_0    conda-forge\r\n",
      "sqlite                    3.34.0               h74cdb3f_0    conda-forge\r\n",
      "statsmodels               0.12.2           py36h92226af_0    conda-forge\r\n",
      "sympy                     1.7.1            py36h5fab9bb_1    conda-forge\r\n",
      "sysroot_linux-64          2.12                h77966d4_13    conda-forge\r\n",
      "tabulate                  0.8.9                    pypi_0    pypi\r\n",
      "tblib                     1.6.0                      py_0    conda-forge\r\n",
      "tenacity                  8.0.1                    pypi_0    pypi\r\n",
      "tensorboard               2.1.1                    pypi_0    pypi\r\n",
      "tensorflow-estimator      2.1.0                    pypi_0    pypi\r\n",
      "tensorflow-gpu            2.1.3                    pypi_0    pypi\r\n",
      "tensorflow-serving-api    2.1.0                    pypi_0    pypi\r\n",
      "termcolor                 1.1.0                    pypi_0    pypi\r\n",
      "terminado                 0.9.2            py36h5fab9bb_0    conda-forge\r\n",
      "testpath                  0.4.4                      py_0    conda-forge\r\n",
      "texttable                 1.6.4                    pypi_0    pypi\r\n",
      "threadpoolctl             2.1.0              pyh5ca1d4c_0    conda-forge\r\n",
      "three-merge               0.1.1              pyh9f0ad1d_0    conda-forge\r\n",
      "tk                        8.6.10               h21135ba_1    conda-forge\r\n",
      "toml                      0.10.2             pyhd8ed1ab_0    conda-forge\r\n",
      "toolz                     0.11.1                     py_0    conda-forge\r\n",
      "tornado                   6.1              py36h8f6f2f9_1    conda-forge\r\n",
      "tqdm                      4.62.3                   pypi_0    pypi\r\n",
      "traitlets                 4.3.3            py36h9f0ad1d_1    conda-forge\r\n",
      "typed-ast                 1.4.2            py36h8f6f2f9_0    conda-forge\r\n",
      "typing                    3.7.4.3            pyhd8ed1ab_2    conda-forge\r\n",
      "typing-extensions         3.10.0.2                 pypi_0    pypi\r\n",
      "ujson                     4.0.2            py36hc4f0c31_0    conda-forge\r\n",
      "unicodecsv                0.14.1                     py_1    conda-forge\r\n",
      "unixodbc                  2.3.9                h0e019cf_0    conda-forge\r\n",
      "urllib3                   1.26.7                   pypi_0    pypi\r\n",
      "watchdog                  2.0.2            py36h5fab9bb_0    conda-forge\r\n",
      "wcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge\r\n",
      "webencodings              0.5.1                      py_1    conda-forge\r\n",
      "websocket-client          0.59.0                   pypi_0    pypi\r\n",
      "werkzeug                  1.0.1              pyh9f0ad1d_0    conda-forge\r\n",
      "wheel                     0.36.2             pyhd3deb0d_0    conda-forge\r\n",
      "widgetsnbextension        3.5.1            py36h5fab9bb_4    conda-forge\r\n",
      "wrapt                     1.12.1           py36h8f6f2f9_3    conda-forge\r\n",
      "wurlitzer                 2.0.1            py36h5fab9bb_1    conda-forge\r\n",
      "xlrd                      2.0.1              pyhd8ed1ab_3    conda-forge\r\n",
      "xlsxwriter                1.3.7              pyh9f0ad1d_0    conda-forge\r\n",
      "xlwt                      1.3.0                      py_1    conda-forge\r\n",
      "xorg-kbproto              1.0.7             h7f98852_1002    conda-forge\r\n",
      "xorg-libice               1.0.10               h516909a_0    conda-forge\r\n",
      "xorg-libsm                1.2.3             h84519dc_1000    conda-forge\r\n",
      "xorg-libx11               1.6.12               h516909a_0    conda-forge\r\n",
      "xorg-libxau               1.0.9                h7f98852_0    conda-forge\r\n",
      "xorg-libxdmcp             1.1.3                h7f98852_0    conda-forge\r\n",
      "xorg-libxext              1.3.4                h516909a_0    conda-forge\r\n",
      "xorg-libxrender           0.9.10            h516909a_1002    conda-forge\r\n",
      "xorg-renderproto          0.11.1            h14c3975_1002    conda-forge\r\n",
      "xorg-xextproto            7.3.0             h7f98852_1002    conda-forge\r\n",
      "xorg-xproto               7.0.31            h7f98852_1007    conda-forge\r\n",
      "xz                        5.2.5                h516909a_1    conda-forge\r\n",
      "yaml                      0.2.5                h516909a_0    conda-forge\r\n",
      "yapf                      0.30.0             pyh9f0ad1d_0    conda-forge\r\n",
      "yarl                      1.6.3            py36h8f6f2f9_1    conda-forge\r\n",
      "zeromq                    4.3.4                h9c3ff4c_0    conda-forge\r\n",
      "zict                      2.0.0                      py_0    conda-forge\r\n",
      "zipp                      3.6.0                    pypi_0    pypi\r\n",
      "zlib                      1.2.11            h516909a_1010    conda-forge\r\n",
      "zope.event                4.5.0              pyh9f0ad1d_0    conda-forge\r\n",
      "zope.interface            5.2.0            py36h8f6f2f9_1    conda-forge\r\n",
      "zstd                      1.4.8                ha95c52a_1    conda-forge\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13b8b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iid_modeling_loocv import iid_modeling_loocv\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "# import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score,roc_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea8a85b",
   "metadata": {},
   "source": [
    "## Loading parquet files in dictionary\n",
    "\n",
    "Need to update `specific folder` variable as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dd3c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_parquet_df = {}\n",
    "directory_location = '../data/dwt_df_parquet/'\n",
    "specific_folder = 'seg_0.5_hop_0.5_ovlap_0.5/'\n",
    "for dirName, _, fileList in os.walk(f'{directory_location}{specific_folder}'):\n",
    "    for fname in fileList:\n",
    "        if fname.endswith('parquet'):\n",
    "            loaded_parquet_df[fname] = pd.read_parquet(f'{directory_location}{specific_folder}{fname}')\n",
    "            # print(fname)\n",
    "# parq = pd.read_parquet('../data/dwt_df_parquet/seg_0.5_hop_0.5_ovlap_0.5/2DCEgkjSeRQyMt8KovG8vF.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32f326f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1jfWVd1sTapjjkQwDM4yQX.parquet: (714, 5514)\n",
      "1jfWVd1sTapjjkQwDM4yQX.parquet has 0 missing values\n",
      "0TkGYYIPwRqx8xzP0XGvRG.parquet: (3014, 5514)\n",
      "0TkGYYIPwRqx8xzP0XGvRG.parquet has 0 missing values\n",
      "79aiOALBohH9vEIUHPAoRj.parquet: (5603, 5514)\n",
      "79aiOALBohH9vEIUHPAoRj.parquet has 0 missing values\n",
      "1XgTQnRlfJ0zpDdg2DccbR.parquet: (5630, 5514)\n",
      "1XgTQnRlfJ0zpDdg2DccbR.parquet has 0 missing values\n",
      "7LxbgPH3grqf6lCpLKEwo7.parquet: (828, 5514)\n",
      "7LxbgPH3grqf6lCpLKEwo7.parquet has 0 missing values\n",
      "7r367wUYs1EvyBbeyOcq39.parquet: (921, 5514)\n",
      "7r367wUYs1EvyBbeyOcq39.parquet has 0 missing values\n",
      "6hoNS9LR1Lxb4EzMX72kXR.parquet: (5901, 5514)\n",
      "6hoNS9LR1Lxb4EzMX72kXR.parquet has 5513 missing values\n",
      "7vxD3WNDRkigLnIDHyy0cu.parquet: (930, 5514)\n",
      "7vxD3WNDRkigLnIDHyy0cu.parquet has 0 missing values\n",
      "2DCEgkjSeRQyMt8KovG8vF.parquet: (838, 5514)\n",
      "2DCEgkjSeRQyMt8KovG8vF.parquet has 0 missing values\n",
      "2hgBlERSFYDWndqjWNOV6v.parquet: (4765, 5514)\n",
      "2hgBlERSFYDWndqjWNOV6v.parquet has 44104 missing values\n",
      "0pIwpmg5oPcMWJXVSyrx4E.parquet: (989, 5514)\n",
      "0pIwpmg5oPcMWJXVSyrx4E.parquet has 0 missing values\n",
      "Total number of observations: 30133\n"
     ]
    }
   ],
   "source": [
    "total_obs = 0\n",
    "for key, val in loaded_parquet_df.items():\n",
    "    print(f'{key}: {val.shape}')\n",
    "    total_obs += val.shape[0]\n",
    "    print(f'{key} has {val.isnull().sum().sum()} missing values')\n",
    "\n",
    "print(f'Total number of observations: {total_obs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53447222",
   "metadata": {},
   "source": [
    "### 9 rows for podcasts have missing values (after checking, appears to be just beginning and end of podcast with silence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d8acbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing column name where null is present in 6hoNS9LR1Lxb4EzMX72kXR.parquet:\n",
      "5513\n",
      "Number rows where null is present:\n",
      "1\n",
      "Row(s) with missing values:\n",
      "    0   1   2   3   4   5   6   7   8   9  ...  5504  5505  5506  5507  5508  \\\n",
      "0 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   5509  5510  5511  5512  y  \n",
      "0   NaN   NaN   NaN   NaN  0  \n",
      "\n",
      "[1 rows x 5514 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"printing column name where null is present in 6hoNS9LR1Lxb4EzMX72kXR.parquet:\")\n",
    "col_name = loaded_parquet_df['6hoNS9LR1Lxb4EzMX72kXR.parquet'].columns.to_series()[np.isnan(loaded_parquet_df['6hoNS9LR1Lxb4EzMX72kXR.parquet']).any()]\n",
    "print(len(col_name))\n",
    "\n",
    "print('Number rows where null is present:')\n",
    "print(loaded_parquet_df['6hoNS9LR1Lxb4EzMX72kXR.parquet'].shape[0] - loaded_parquet_df['6hoNS9LR1Lxb4EzMX72kXR.parquet'].dropna().shape[0])\n",
    "print('Row(s) with missing values:')\n",
    "print(loaded_parquet_df['6hoNS9LR1Lxb4EzMX72kXR.parquet'][loaded_parquet_df['6hoNS9LR1Lxb4EzMX72kXR.parquet'].isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc97001c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing column name where null is present in 2hgBlERSFYDWndqjWNOV6v.parquet:\n",
      "5513\n",
      "Number rows where null is present:\n",
      "8\n",
      "Row(s) with missing values:\n",
      "       0   1   2   3   4   5   6   7   8   9  ...  5504  5505  5506  5507  \\\n",
      "4757 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN   NaN   NaN   NaN   \n",
      "4758 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN   NaN   NaN   NaN   \n",
      "4759 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN   NaN   NaN   NaN   \n",
      "4760 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN   NaN   NaN   NaN   \n",
      "4761 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN   NaN   NaN   NaN   \n",
      "4762 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN   NaN   NaN   NaN   \n",
      "4763 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN   NaN   NaN   NaN   \n",
      "4764 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...   NaN   NaN   NaN   NaN   \n",
      "\n",
      "      5508  5509  5510  5511  5512  y  \n",
      "4757   NaN   NaN   NaN   NaN   NaN  0  \n",
      "4758   NaN   NaN   NaN   NaN   NaN  0  \n",
      "4759   NaN   NaN   NaN   NaN   NaN  0  \n",
      "4760   NaN   NaN   NaN   NaN   NaN  0  \n",
      "4761   NaN   NaN   NaN   NaN   NaN  0  \n",
      "4762   NaN   NaN   NaN   NaN   NaN  0  \n",
      "4763   NaN   NaN   NaN   NaN   NaN  0  \n",
      "4764   NaN   NaN   NaN   NaN   NaN  0  \n",
      "\n",
      "[8 rows x 5514 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"printing column name where null is present in 2hgBlERSFYDWndqjWNOV6v.parquet:\")\n",
    "col_name = loaded_parquet_df['2hgBlERSFYDWndqjWNOV6v.parquet'].columns.to_series()[np.isnan(loaded_parquet_df['2hgBlERSFYDWndqjWNOV6v.parquet']).any()]\n",
    "print(len(col_name))\n",
    "\n",
    "print('Number rows where null is present:')\n",
    "print(loaded_parquet_df['2hgBlERSFYDWndqjWNOV6v.parquet'].shape[0] - loaded_parquet_df['2hgBlERSFYDWndqjWNOV6v.parquet'].dropna().shape[0])\n",
    "print('Row(s) with missing values:')\n",
    "print(loaded_parquet_df['2hgBlERSFYDWndqjWNOV6v.parquet'][loaded_parquet_df['2hgBlERSFYDWndqjWNOV6v.parquet'].isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ebdc1",
   "metadata": {},
   "source": [
    "## Creating train-test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27ebcbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1jfWVd1sTapjjkQwDM4yQX.parquet will be the test podcast\n",
      "Training set size: (29410, 5514)\n",
      "Test set size: (714, 5514)\n",
      "1jfWVd1sTapjjkQwDM4yQX.parquet scores: accuracy = 0.8431, precision = 0.0000, recall = 0.0000, f1_score = 0.0000\n",
      "TN=602   FP=109   FN=3   TP=0\n",
      "1jfWVd1sTapjjkQwDM4yQX.parquet completed in 37.65 seconds\n",
      "\n",
      "0TkGYYIPwRqx8xzP0XGvRG.parquet will be the test podcast\n",
      "Training set size: (27110, 5514)\n",
      "Test set size: (3014, 5514)\n",
      "0TkGYYIPwRqx8xzP0XGvRG.parquet scores: accuracy = 0.8945, precision = 0.0372, recall = 0.0957, f1_score = 0.0536\n",
      "TN=2687   FP=233   FN=85   TP=9\n",
      "0TkGYYIPwRqx8xzP0XGvRG.parquet completed in 31.66 seconds\n",
      "\n",
      "79aiOALBohH9vEIUHPAoRj.parquet will be the test podcast\n",
      "Training set size: (24521, 5514)\n",
      "Test set size: (5603, 5514)\n",
      "79aiOALBohH9vEIUHPAoRj.parquet scores: accuracy = 0.9099, precision = 0.0221, recall = 0.1389, f1_score = 0.0381\n",
      "TN=5088   FP=443   FN=62   TP=10\n",
      "79aiOALBohH9vEIUHPAoRj.parquet completed in 30.00 seconds\n",
      "\n",
      "1XgTQnRlfJ0zpDdg2DccbR.parquet will be the test podcast\n",
      "Training set size: (24494, 5514)\n",
      "Test set size: (5630, 5514)\n",
      "1XgTQnRlfJ0zpDdg2DccbR.parquet scores: accuracy = 0.8638, precision = 0.0511, recall = 0.1124, f1_score = 0.0703\n",
      "TN=4834   FP=538   FN=229   TP=29\n",
      "1XgTQnRlfJ0zpDdg2DccbR.parquet completed in 25.95 seconds\n",
      "\n",
      "7LxbgPH3grqf6lCpLKEwo7.parquet will be the test podcast\n",
      "Training set size: (29296, 5514)\n",
      "Test set size: (828, 5514)\n",
      "7LxbgPH3grqf6lCpLKEwo7.parquet scores: accuracy = 0.8539, precision = 0.0177, recall = 0.1667, f1_score = 0.0320\n",
      "TN=705   FP=111   FN=10   TP=2\n",
      "7LxbgPH3grqf6lCpLKEwo7.parquet completed in 36.02 seconds\n",
      "\n",
      "7r367wUYs1EvyBbeyOcq39.parquet will be the test podcast\n",
      "Training set size: (29203, 5514)\n",
      "Test set size: (921, 5514)\n",
      "7r367wUYs1EvyBbeyOcq39.parquet scores: accuracy = 0.8654, precision = 0.0682, recall = 0.1250, f1_score = 0.0882\n",
      "TN=791   FP=82   FN=42   TP=6\n",
      "7r367wUYs1EvyBbeyOcq39.parquet completed in 37.93 seconds\n",
      "\n",
      "6hoNS9LR1Lxb4EzMX72kXR.parquet will be the test podcast\n",
      "Training set size: (24224, 5514)\n",
      "Test set size: (5900, 5514)\n",
      "6hoNS9LR1Lxb4EzMX72kXR.parquet scores: accuracy = 0.8753, precision = 0.0457, recall = 0.1357, f1_score = 0.0684\n",
      "TN=5137   FP=564   FN=172   TP=27\n",
      "6hoNS9LR1Lxb4EzMX72kXR.parquet completed in 26.88 seconds\n",
      "\n",
      "7vxD3WNDRkigLnIDHyy0cu.parquet will be the test podcast\n",
      "Training set size: (29194, 5514)\n",
      "Test set size: (930, 5514)\n",
      "7vxD3WNDRkigLnIDHyy0cu.parquet scores: accuracy = 0.8892, precision = 0.0345, recall = 0.1364, f1_score = 0.0550\n",
      "TN=824   FP=84   FN=19   TP=3\n",
      "7vxD3WNDRkigLnIDHyy0cu.parquet completed in 36.15 seconds\n",
      "\n",
      "2DCEgkjSeRQyMt8KovG8vF.parquet will be the test podcast\n",
      "Training set size: (29286, 5514)\n",
      "Test set size: (838, 5514)\n",
      "2DCEgkjSeRQyMt8KovG8vF.parquet scores: accuracy = 0.8484, precision = 0.0088, recall = 0.0625, f1_score = 0.0155\n",
      "TN=710   FP=112   FN=15   TP=1\n",
      "2DCEgkjSeRQyMt8KovG8vF.parquet completed in 36.11 seconds\n",
      "\n",
      "2hgBlERSFYDWndqjWNOV6v.parquet will be the test podcast\n",
      "Training set size: (25367, 5514)\n",
      "Test set size: (4757, 5514)\n",
      "2hgBlERSFYDWndqjWNOV6v.parquet scores: accuracy = 0.9046, precision = 0.0258, recall = 0.1149, f1_score = 0.0422\n",
      "TN=4293   FP=377   FN=77   TP=10\n",
      "2hgBlERSFYDWndqjWNOV6v.parquet completed in 29.42 seconds\n",
      "\n",
      "0pIwpmg5oPcMWJXVSyrx4E.parquet will be the test podcast\n",
      "Training set size: (29135, 5514)\n",
      "Test set size: (989, 5514)\n",
      "0pIwpmg5oPcMWJXVSyrx4E.parquet scores: accuracy = 0.9050, precision = 0.0286, recall = 0.0714, f1_score = 0.0408\n",
      "TN=893   FP=68   FN=26   TP=2\n",
      "0pIwpmg5oPcMWJXVSyrx4E.parquet completed in 35.46 seconds\n",
      "\n",
      "Finished LOOCV in 6.05 minutes\n",
      "Average scores: accuracy = 0.8775, precision = 0.0309, recall = 0.1054, f1_score = 0.0458\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty = 'l2', class_weight ='balanced', max_iter = 1e10)\n",
    "\n",
    "logreg_model_metrics = iid_modeling_loocv(loaded_parquet_df, logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba60ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1jfWVd1sTapjjkQwDM4yQX.parquet': {'model': LogisticRegression(class_weight='balanced', max_iter=10000000000.0),\n",
       "  'y_pred': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "         0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "         0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       1.00      0.85      0.91       711\\n           1       0.00      0.00      0.00         3\\n\\n    accuracy                           0.84       714\\n   macro avg       0.50      0.42      0.46       714\\nweighted avg       0.99      0.84      0.91       714\\n',\n",
       "  'confusion_matrix': array([[602, 109],\n",
       "         [  3,   0]]),\n",
       "  'y_pred_prob': array([[1.00000000e+00, 2.40075033e-11],\n",
       "         [9.99999975e-01, 2.45184997e-08],\n",
       "         [9.99994393e-01, 5.60691757e-06],\n",
       "         ...,\n",
       "         [9.83695631e-01, 1.63043693e-02],\n",
       "         [8.74647092e-01, 1.25352908e-01],\n",
       "         [9.99095664e-01, 9.04335695e-04]]),\n",
       "  'y_pred_prob_log': array([[-2.40074627e-11, -2.44526547e+01],\n",
       "         [-2.45185000e-08, -1.75238379e+01],\n",
       "         [-5.60693329e-06, -1.20915094e+01],\n",
       "         ...,\n",
       "         [-1.64387482e-02, -4.11632215e+00],\n",
       "         [-1.33934798e-01, -2.07662225e+00],\n",
       "         [-9.04744853e-04, -7.00830992e+00]]),\n",
       "  'accuracy': 0.8431372549019608,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'logit_roc_auc': 0.42334739803094235,\n",
       "  'fpr_tpr_thresholds': (array([0.        , 0.00140647, 0.37412096, 0.37412096, 0.64416315,\n",
       "          0.64416315, 0.98171589, 0.98171589, 1.        ]),\n",
       "   array([0.        , 0.        , 0.        , 0.33333333, 0.33333333,\n",
       "          0.66666667, 0.66666667, 1.        , 1.        ]),\n",
       "   array([2.00000000e+00, 9.99999998e-01, 7.53080450e-03, 7.20233787e-03,\n",
       "          5.96830159e-05, 5.95830478e-05, 8.33713785e-11, 7.85333821e-11,\n",
       "          2.92721796e-14])),\n",
       "  'false_negatives':             0             1  y_pred  y_pred_true_label\n",
       "  100  0.992798  7.202338e-03       0                  1\n",
       "  308  0.999940  5.958305e-05       0                  1\n",
       "  309  1.000000  7.853338e-11       0                  1,\n",
       "  'false_positives':             0         1  y_pred  y_pred_true_label\n",
       "  26   0.034204  0.965796       1                  0\n",
       "  27   0.411988  0.588012       1                  0\n",
       "  33   0.273472  0.726528       1                  0\n",
       "  34   0.000060  0.999940       1                  0\n",
       "  37   0.048021  0.951979       1                  0\n",
       "  ..        ...       ...     ...                ...\n",
       "  666  0.077576  0.922424       1                  0\n",
       "  676  0.159520  0.840480       1                  0\n",
       "  681  0.409357  0.590643       1                  0\n",
       "  685  0.000528  0.999472       1                  0\n",
       "  705  0.004912  0.995088       1                  0\n",
       "  \n",
       "  [109 rows x 4 columns],\n",
       "  'true_positives': Empty DataFrame\n",
       "  Columns: [0, 1, y_pred, y_pred_true_label]\n",
       "  Index: []},\n",
       " '0TkGYYIPwRqx8xzP0XGvRG.parquet': {'model': LogisticRegression(class_weight='balanced', max_iter=10000000000.0),\n",
       "  'y_pred': array([1, 0, 0, ..., 0, 0, 0]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.97      0.92      0.94      2920\\n           1       0.04      0.10      0.05        94\\n\\n    accuracy                           0.89      3014\\n   macro avg       0.50      0.51      0.50      3014\\nweighted avg       0.94      0.89      0.92      3014\\n',\n",
       "  'confusion_matrix': array([[2687,  233],\n",
       "         [  85,    9]]),\n",
       "  'y_pred_prob': array([[2.73521777e-02, 9.72647822e-01],\n",
       "         [6.56536745e-01, 3.43463255e-01],\n",
       "         [9.99990713e-01, 9.28712286e-06],\n",
       "         ...,\n",
       "         [9.97761457e-01, 2.23854266e-03],\n",
       "         [9.99481977e-01, 5.18022700e-04],\n",
       "         [9.99701791e-01, 2.98209371e-04]]),\n",
       "  'y_pred_prob_log': array([[-3.59895913e+00, -2.77332127e-02],\n",
       "         [-4.20776616e-01, -1.06867515e+00],\n",
       "         [-9.28716598e-06, -1.15868818e+01],\n",
       "         ...,\n",
       "         [-2.24105194e-03, -6.10193022e+00],\n",
       "         [-5.18156920e-04, -7.56549149e+00],\n",
       "         [-2.98253845e-04, -8.11771473e+00]]),\n",
       "  'accuracy': 0.8944923689449237,\n",
       "  'precision': 0.0371900826446281,\n",
       "  'recall': 0.09574468085106383,\n",
       "  'f1': 0.05357142857142857,\n",
       "  'logit_roc_auc': 0.5079750801515592,\n",
       "  'fpr_tpr_thresholds': (array([0.00000000e+00, 3.42465753e-04, 1.36986301e-03, 1.36986301e-03,\n",
       "          4.10958904e-03, 4.10958904e-03, 3.28767123e-02, 3.28767123e-02,\n",
       "          3.63013699e-02, 3.63013699e-02, 4.55479452e-02, 4.55479452e-02,\n",
       "          5.13698630e-02, 5.13698630e-02, 5.44520548e-02, 5.44520548e-02,\n",
       "          6.91780822e-02, 6.91780822e-02, 7.56849315e-02, 7.56849315e-02,\n",
       "          8.76712329e-02, 8.76712329e-02, 1.30136986e-01, 1.30136986e-01,\n",
       "          1.56849315e-01, 1.56849315e-01, 1.60616438e-01, 1.60616438e-01,\n",
       "          1.84931507e-01, 1.84931507e-01, 1.86643836e-01, 1.86643836e-01,\n",
       "          1.96232877e-01, 1.96232877e-01, 1.97602740e-01, 1.97602740e-01,\n",
       "          1.98630137e-01, 1.98630137e-01, 2.05479452e-01, 2.05479452e-01,\n",
       "          2.31506849e-01, 2.31506849e-01, 2.38013699e-01, 2.38013699e-01,\n",
       "          2.48630137e-01, 2.48630137e-01, 2.71232877e-01, 2.71232877e-01,\n",
       "          2.71575342e-01, 2.71575342e-01, 3.07876712e-01, 3.07876712e-01,\n",
       "          3.22260274e-01, 3.22260274e-01, 3.25000000e-01, 3.25000000e-01,\n",
       "          3.31849315e-01, 3.31849315e-01, 3.49315068e-01, 3.49315068e-01,\n",
       "          3.54794521e-01, 3.54794521e-01, 3.62671233e-01, 3.62671233e-01,\n",
       "          3.97945205e-01, 3.97945205e-01, 4.03424658e-01, 4.03424658e-01,\n",
       "          4.32191781e-01, 4.32191781e-01, 4.39041096e-01, 4.39041096e-01,\n",
       "          4.78424658e-01, 4.78424658e-01, 4.90753425e-01, 4.90753425e-01,\n",
       "          4.92465753e-01, 4.92465753e-01, 5.25000000e-01, 5.25000000e-01,\n",
       "          5.41780822e-01, 5.41780822e-01, 5.44520548e-01, 5.44520548e-01,\n",
       "          5.79452055e-01, 5.79452055e-01, 5.79794521e-01, 5.79794521e-01,\n",
       "          5.81506849e-01, 5.81506849e-01, 6.08904110e-01, 6.08904110e-01,\n",
       "          6.10616438e-01, 6.10616438e-01, 6.11301370e-01, 6.11301370e-01,\n",
       "          6.20547945e-01, 6.20547945e-01, 6.22945205e-01, 6.22945205e-01,\n",
       "          6.33561644e-01, 6.33561644e-01, 6.35958904e-01, 6.35958904e-01,\n",
       "          6.47260274e-01, 6.47260274e-01, 6.48972603e-01, 6.48972603e-01,\n",
       "          6.54109589e-01, 6.54109589e-01, 6.60958904e-01, 6.60958904e-01,\n",
       "          6.72945205e-01, 6.72945205e-01, 6.95890411e-01, 6.95890411e-01,\n",
       "          6.99315068e-01, 6.99315068e-01, 7.00684932e-01, 7.00684932e-01,\n",
       "          7.09246575e-01, 7.09246575e-01, 7.14041096e-01, 7.14041096e-01,\n",
       "          7.20890411e-01, 7.20890411e-01, 7.30821918e-01, 7.30821918e-01,\n",
       "          7.33904110e-01, 7.33904110e-01, 7.35958904e-01, 7.35958904e-01,\n",
       "          7.39726027e-01, 7.39726027e-01, 7.42808219e-01, 7.42808219e-01,\n",
       "          7.63698630e-01, 7.63698630e-01, 7.83904110e-01, 7.83904110e-01,\n",
       "          7.84931507e-01, 7.84931507e-01, 8.22602740e-01, 8.22602740e-01,\n",
       "          8.22945205e-01, 8.22945205e-01, 8.53767123e-01, 8.53767123e-01,\n",
       "          8.64726027e-01, 8.64726027e-01, 8.77054795e-01, 8.77054795e-01,\n",
       "          9.04794521e-01, 9.04794521e-01, 9.07876712e-01, 9.07876712e-01,\n",
       "          9.11643836e-01, 9.11643836e-01, 9.16780822e-01, 9.16780822e-01,\n",
       "          9.17808219e-01, 9.17808219e-01, 9.18150685e-01, 9.18150685e-01,\n",
       "          9.22945205e-01, 9.22945205e-01, 9.34246575e-01, 9.34246575e-01,\n",
       "          9.36301370e-01, 9.36301370e-01, 9.38013699e-01, 9.38013699e-01,\n",
       "          9.40753425e-01, 9.40753425e-01, 9.45890411e-01, 9.45890411e-01,\n",
       "          9.48287671e-01, 9.48287671e-01, 9.51369863e-01, 9.51369863e-01,\n",
       "          9.56164384e-01, 9.56164384e-01, 9.57876712e-01, 9.57876712e-01,\n",
       "          9.86986301e-01, 9.86986301e-01, 9.96575342e-01, 9.96575342e-01,\n",
       "          1.00000000e+00]),\n",
       "   array([0.        , 0.        , 0.        , 0.0106383 , 0.0106383 ,\n",
       "          0.0212766 , 0.0212766 , 0.03191489, 0.03191489, 0.04255319,\n",
       "          0.04255319, 0.05319149, 0.05319149, 0.06382979, 0.06382979,\n",
       "          0.07446809, 0.07446809, 0.08510638, 0.08510638, 0.09574468,\n",
       "          0.09574468, 0.10638298, 0.10638298, 0.11702128, 0.11702128,\n",
       "          0.12765957, 0.12765957, 0.13829787, 0.13829787, 0.14893617,\n",
       "          0.14893617, 0.15957447, 0.15957447, 0.17021277, 0.17021277,\n",
       "          0.18085106, 0.18085106, 0.19148936, 0.19148936, 0.20212766,\n",
       "          0.20212766, 0.21276596, 0.21276596, 0.22340426, 0.22340426,\n",
       "          0.23404255, 0.23404255, 0.24468085, 0.24468085, 0.25531915,\n",
       "          0.25531915, 0.26595745, 0.26595745, 0.27659574, 0.27659574,\n",
       "          0.28723404, 0.28723404, 0.29787234, 0.29787234, 0.30851064,\n",
       "          0.30851064, 0.31914894, 0.31914894, 0.32978723, 0.32978723,\n",
       "          0.34042553, 0.34042553, 0.35106383, 0.35106383, 0.36170213,\n",
       "          0.36170213, 0.37234043, 0.37234043, 0.38297872, 0.38297872,\n",
       "          0.39361702, 0.39361702, 0.40425532, 0.40425532, 0.41489362,\n",
       "          0.41489362, 0.42553191, 0.42553191, 0.43617021, 0.43617021,\n",
       "          0.44680851, 0.44680851, 0.46808511, 0.46808511, 0.4787234 ,\n",
       "          0.4787234 , 0.4893617 , 0.4893617 , 0.5       , 0.5       ,\n",
       "          0.5106383 , 0.5106383 , 0.5212766 , 0.5212766 , 0.53191489,\n",
       "          0.53191489, 0.54255319, 0.54255319, 0.55319149, 0.55319149,\n",
       "          0.56382979, 0.56382979, 0.57446809, 0.57446809, 0.58510638,\n",
       "          0.58510638, 0.59574468, 0.59574468, 0.60638298, 0.60638298,\n",
       "          0.61702128, 0.61702128, 0.62765957, 0.62765957, 0.63829787,\n",
       "          0.63829787, 0.64893617, 0.64893617, 0.65957447, 0.65957447,\n",
       "          0.67021277, 0.67021277, 0.68085106, 0.68085106, 0.69148936,\n",
       "          0.69148936, 0.70212766, 0.70212766, 0.71276596, 0.71276596,\n",
       "          0.72340426, 0.72340426, 0.73404255, 0.73404255, 0.74468085,\n",
       "          0.74468085, 0.75531915, 0.75531915, 0.76595745, 0.76595745,\n",
       "          0.77659574, 0.77659574, 0.78723404, 0.78723404, 0.79787234,\n",
       "          0.79787234, 0.80851064, 0.80851064, 0.81914894, 0.81914894,\n",
       "          0.82978723, 0.82978723, 0.84042553, 0.84042553, 0.85106383,\n",
       "          0.85106383, 0.86170213, 0.86170213, 0.87234043, 0.87234043,\n",
       "          0.88297872, 0.88297872, 0.89361702, 0.89361702, 0.90425532,\n",
       "          0.90425532, 0.91489362, 0.91489362, 0.92553191, 0.92553191,\n",
       "          0.93617021, 0.93617021, 0.94680851, 0.94680851, 0.95744681,\n",
       "          0.95744681, 0.96808511, 0.96808511, 0.9787234 , 0.9787234 ,\n",
       "          0.9893617 , 0.9893617 , 1.        , 1.        ]),\n",
       "   array([1.99999996e+00, 9.99999963e-01, 9.99972046e-01, 9.99963702e-01,\n",
       "          9.99744899e-01, 9.99662058e-01, 9.44255113e-01, 9.42025065e-01,\n",
       "          9.25013108e-01, 9.22608819e-01, 8.69152946e-01, 8.65958937e-01,\n",
       "          8.31171010e-01, 8.29944148e-01, 8.12906369e-01, 8.11864052e-01,\n",
       "          6.21192410e-01, 6.19801077e-01, 5.55368116e-01, 5.54898811e-01,\n",
       "          3.98859973e-01, 3.93395103e-01, 1.31442115e-01, 1.31136850e-01,\n",
       "          7.01294087e-02, 6.94642791e-02, 6.52601936e-02, 6.50563785e-02,\n",
       "          4.26220713e-02, 4.26171132e-02, 4.16256578e-02, 4.12738241e-02,\n",
       "          3.37641023e-02, 3.37059572e-02, 3.29680909e-02, 3.28618570e-02,\n",
       "          3.22407308e-02, 3.22312981e-02, 2.80530123e-02, 2.78793580e-02,\n",
       "          1.64697596e-02, 1.63699736e-02, 1.49464542e-02, 1.49396924e-02,\n",
       "          1.24197048e-02, 1.23942704e-02, 8.74165347e-03, 8.73776056e-03,\n",
       "          8.69156806e-03, 8.66663629e-03, 5.20733514e-03, 5.19477611e-03,\n",
       "          4.15190265e-03, 4.15095928e-03, 3.98432561e-03, 3.97558103e-03,\n",
       "          3.59142207e-03, 3.58775600e-03, 2.74368183e-03, 2.71480448e-03,\n",
       "          2.55332094e-03, 2.54033994e-03, 2.27935644e-03, 2.27302678e-03,\n",
       "          1.45046034e-03, 1.44081480e-03, 1.34302253e-03, 1.33430678e-03,\n",
       "          9.11085478e-04, 9.07226444e-04, 8.37871777e-04, 8.34203265e-04,\n",
       "          4.78358540e-04, 4.77991631e-04, 4.04689259e-04, 4.04571160e-04,\n",
       "          3.98917540e-04, 3.93420381e-04, 2.67370979e-04, 2.65470518e-04,\n",
       "          2.17922421e-04, 2.17565118e-04, 2.08648473e-04, 2.07705235e-04,\n",
       "          1.26276671e-04, 1.26050253e-04, 1.24678213e-04, 1.23870004e-04,\n",
       "          1.22036865e-04, 1.21908815e-04, 8.10768349e-05, 8.07713572e-05,\n",
       "          7.73635146e-05, 7.72838304e-05, 7.62654851e-05, 7.61061236e-05,\n",
       "          7.04586699e-05, 6.98626880e-05, 6.81524054e-05, 6.81386445e-05,\n",
       "          6.14324277e-05, 6.11649527e-05, 5.77470621e-05, 5.77179452e-05,\n",
       "          5.01232589e-05, 4.99132904e-05, 4.93044458e-05, 4.92685690e-05,\n",
       "          4.59043857e-05, 4.53184340e-05, 4.19206228e-05, 4.14173033e-05,\n",
       "          3.57831201e-05, 3.54632527e-05, 2.71515604e-05, 2.69829353e-05,\n",
       "          2.57645656e-05, 2.56062654e-05, 2.53455346e-05, 2.50817709e-05,\n",
       "          2.19109853e-05, 2.18606384e-05, 1.98061332e-05, 1.95781215e-05,\n",
       "          1.85175157e-05, 1.82600664e-05, 1.55894850e-05, 1.55335167e-05,\n",
       "          1.49005495e-05, 1.47793409e-05, 1.45507433e-05, 1.45333845e-05,\n",
       "          1.35868468e-05, 1.35565582e-05, 1.31090565e-05, 1.30489515e-05,\n",
       "          9.68237420e-06, 9.63235489e-06, 6.23323520e-06, 6.20781434e-06,\n",
       "          6.10997254e-06, 6.10700328e-06, 2.99912002e-06, 2.98179893e-06,\n",
       "          2.93485261e-06, 2.93230863e-06, 1.46744662e-06, 1.44940627e-06,\n",
       "          1.08392610e-06, 1.06805379e-06, 7.98623754e-07, 7.95174407e-07,\n",
       "          3.15048739e-07, 3.13162535e-07, 2.79432493e-07, 2.78603246e-07,\n",
       "          2.55480968e-07, 2.55092444e-07, 2.12440045e-07, 2.10225417e-07,\n",
       "          1.89135169e-07, 1.89128466e-07, 1.86449065e-07, 1.85023819e-07,\n",
       "          1.52204247e-07, 1.49849192e-07, 8.72284350e-08, 8.13518097e-08,\n",
       "          7.81837510e-08, 7.28217317e-08, 6.70328148e-08, 6.53104408e-08,\n",
       "          5.37017803e-08, 5.27859479e-08, 4.31988012e-08, 4.12169600e-08,\n",
       "          3.93555914e-08, 3.75545727e-08, 3.07877154e-08, 3.05899432e-08,\n",
       "          2.28630364e-08, 2.24205168e-08, 2.01726106e-08, 2.00498779e-08,\n",
       "          5.22796161e-10, 4.57672623e-10, 8.86337287e-12, 7.81639210e-12,\n",
       "          5.89473611e-15])),\n",
       "  'false_negatives':              0             1  y_pred  y_pred_true_label\n",
       "  151   0.972121  2.787936e-02       0                  1\n",
       "  152   0.996024  3.975581e-03       0                  1\n",
       "  153   1.000000  2.102254e-07       0                  1\n",
       "  154   0.999974  2.560627e-05       0                  1\n",
       "  718   0.999792  2.077052e-04       0                  1\n",
       "  ...        ...           ...     ...                ...\n",
       "  1469  1.000000  5.278595e-08       0                  1\n",
       "  1470  0.999876  1.238700e-04       0                  1\n",
       "  1471  0.999990  9.632355e-06       0                  1\n",
       "  1472  0.999997  2.932309e-06       0                  1\n",
       "  1473  0.999997  2.981799e-06       0                  1\n",
       "  \n",
       "  [85 rows x 4 columns],\n",
       "  'false_positives':              0         1  y_pred  y_pred_true_label\n",
       "  0     0.027352  0.972648       1                  0\n",
       "  8     0.011627  0.988373       1                  0\n",
       "  22    0.096302  0.903698       1                  0\n",
       "  45    0.415777  0.584223       1                  0\n",
       "  52    0.010153  0.989847       1                  0\n",
       "  ...        ...       ...     ...                ...\n",
       "  2972  0.178766  0.821234       1                  0\n",
       "  2993  0.117573  0.882427       1                  0\n",
       "  3000  0.008938  0.991062       1                  0\n",
       "  3001  0.002013  0.997987       1                  0\n",
       "  3010  0.019975  0.980025       1                  0\n",
       "  \n",
       "  [233 rows x 4 columns],\n",
       "  'true_positives':              0         1  y_pred  y_pred_true_label\n",
       "  726   0.000338  0.999662       1                  1\n",
       "  750   0.188136  0.811864       1                  1\n",
       "  752   0.380199  0.619801       1                  1\n",
       "  849   0.000036  0.999964       1                  1\n",
       "  853   0.170056  0.829944       1                  1\n",
       "  1427  0.134041  0.865959       1                  1\n",
       "  1447  0.057975  0.942025       1                  1\n",
       "  1465  0.445101  0.554899       1                  1\n",
       "  1468  0.077391  0.922609       1                  1},\n",
       " '79aiOALBohH9vEIUHPAoRj.parquet': {'model': LogisticRegression(class_weight='balanced', max_iter=10000000000.0),\n",
       "  'y_pred': array([0, 1, 0, ..., 0, 0, 1]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.99      0.92      0.95      5531\\n           1       0.02      0.14      0.04        72\\n\\n    accuracy                           0.91      5603\\n   macro avg       0.51      0.53      0.50      5603\\nweighted avg       0.98      0.91      0.94      5603\\n',\n",
       "  'confusion_matrix': array([[5088,  443],\n",
       "         [  62,   10]]),\n",
       "  'y_pred_prob': array([[8.88216713e-01, 1.11783287e-01],\n",
       "         [7.11151392e-05, 9.99928885e-01],\n",
       "         [9.99991172e-01, 8.82758758e-06],\n",
       "         ...,\n",
       "         [9.99945976e-01, 5.40241673e-05],\n",
       "         [7.84230987e-01, 2.15769013e-01],\n",
       "         [4.92624502e-04, 9.99507375e-01]]),\n",
       "  'y_pred_prob_log': array([[-1.18539520e-01, -2.19119322e+00],\n",
       "         [-9.55121032e+00, -7.11176680e-05],\n",
       "         [-8.82762654e-06, -1.16376288e+01],\n",
       "         ...,\n",
       "         [-5.40256267e-05, -9.82607907e+00],\n",
       "         [-2.43051676e-01, -1.53354683e+00],\n",
       "         [-7.61576333e+00, -4.92745881e-04]]),\n",
       "  'accuracy': 0.9098697126539353,\n",
       "  'precision': 0.02207505518763797,\n",
       "  'recall': 0.1388888888888889,\n",
       "  'f1': 0.0380952380952381,\n",
       "  'logit_roc_auc': 0.5293974366700818,\n",
       "  'fpr_tpr_thresholds': (array([0.00000000e+00, 1.80799132e-04, 2.16958959e-03, 2.16958959e-03,\n",
       "          1.10287471e-02, 1.10287471e-02, 3.50750316e-02, 3.50750316e-02,\n",
       "          4.70077744e-02, 4.70077744e-02, 5.71325258e-02, 5.71325258e-02,\n",
       "          5.74941240e-02, 5.74941240e-02, 6.02061110e-02, 6.02061110e-02,\n",
       "          6.43644911e-02, 6.43644911e-02, 6.76188754e-02, 6.76188754e-02,\n",
       "          7.64780329e-02, 7.64780329e-02, 8.31676008e-02, 8.31676008e-02,\n",
       "          9.34731513e-02, 9.34731513e-02, 1.01247514e-01, 1.01247514e-01,\n",
       "          1.05405894e-01, 1.05405894e-01, 1.16615440e-01, 1.16615440e-01,\n",
       "          1.17519436e-01, 1.17519436e-01, 1.24209004e-01, 1.24209004e-01,\n",
       "          1.67600796e-01, 1.67600796e-01, 1.88754294e-01, 1.88754294e-01,\n",
       "          1.91466281e-01, 1.91466281e-01, 2.08099801e-01, 2.08099801e-01,\n",
       "          2.62881938e-01, 2.62881938e-01, 2.75176279e-01, 2.75176279e-01,\n",
       "          3.38636775e-01, 3.38636775e-01, 3.48399928e-01, 3.48399928e-01,\n",
       "          3.48761526e-01, 3.48761526e-01, 3.80582173e-01, 3.80582173e-01,\n",
       "          4.02278069e-01, 4.02278069e-01, 4.14572410e-01, 4.14572410e-01,\n",
       "          4.15657205e-01, 4.15657205e-01, 4.30663533e-01, 4.30663533e-01,\n",
       "          4.36449105e-01, 4.36449105e-01, 4.39703489e-01, 4.39703489e-01,\n",
       "          4.71704936e-01, 4.71704936e-01, 4.79479298e-01, 4.79479298e-01,\n",
       "          5.00994395e-01, 5.00994395e-01, 5.09130356e-01, 5.09130356e-01,\n",
       "          5.23594287e-01, 5.23594287e-01, 5.52341349e-01, 5.52341349e-01,\n",
       "          5.54149340e-01, 5.54149340e-01, 5.63912493e-01, 5.63912493e-01,\n",
       "          5.64454891e-01, 5.64454891e-01, 5.64816489e-01, 5.64816489e-01,\n",
       "          5.69155668e-01, 5.69155668e-01, 5.73675646e-01, 5.73675646e-01,\n",
       "          5.74941240e-01, 5.74941240e-01, 5.80184415e-01, 5.80184415e-01,\n",
       "          6.50696077e-01, 6.50696077e-01, 6.99873441e-01, 6.99873441e-01,\n",
       "          7.42361237e-01, 7.42361237e-01, 7.53570783e-01, 7.53570783e-01,\n",
       "          7.60441150e-01, 7.60441150e-01, 7.61345146e-01, 7.61345146e-01,\n",
       "          7.75447478e-01, 7.75447478e-01, 7.86476225e-01, 7.86476225e-01,\n",
       "          7.97504972e-01, 7.97504972e-01, 8.06002531e-01, 8.06002531e-01,\n",
       "          8.11426505e-01, 8.11426505e-01, 8.48128729e-01, 8.48128729e-01,\n",
       "          8.63315856e-01, 8.63315856e-01, 8.68378232e-01, 8.68378232e-01,\n",
       "          8.93690110e-01, 8.93690110e-01, 8.97306093e-01, 8.97306093e-01,\n",
       "          9.18821190e-01, 9.18821190e-01, 9.32923522e-01, 9.32923522e-01,\n",
       "          9.42325077e-01, 9.42325077e-01, 9.52811427e-01, 9.52811427e-01,\n",
       "          9.54438619e-01, 9.54438619e-01, 9.68902549e-01, 9.68902549e-01,\n",
       "          9.89152052e-01, 9.89152052e-01, 9.96564816e-01, 9.96564816e-01,\n",
       "          1.00000000e+00, 1.00000000e+00]),\n",
       "   array([0.        , 0.        , 0.        , 0.01388889, 0.01388889,\n",
       "          0.02777778, 0.02777778, 0.04166667, 0.04166667, 0.05555556,\n",
       "          0.05555556, 0.06944444, 0.06944444, 0.08333333, 0.08333333,\n",
       "          0.09722222, 0.09722222, 0.11111111, 0.11111111, 0.125     ,\n",
       "          0.125     , 0.13888889, 0.13888889, 0.15277778, 0.15277778,\n",
       "          0.16666667, 0.16666667, 0.18055556, 0.18055556, 0.19444444,\n",
       "          0.19444444, 0.20833333, 0.20833333, 0.22222222, 0.22222222,\n",
       "          0.23611111, 0.23611111, 0.25      , 0.25      , 0.26388889,\n",
       "          0.26388889, 0.27777778, 0.27777778, 0.29166667, 0.29166667,\n",
       "          0.30555556, 0.30555556, 0.31944444, 0.31944444, 0.33333333,\n",
       "          0.33333333, 0.34722222, 0.34722222, 0.36111111, 0.36111111,\n",
       "          0.375     , 0.375     , 0.38888889, 0.38888889, 0.40277778,\n",
       "          0.40277778, 0.41666667, 0.41666667, 0.43055556, 0.43055556,\n",
       "          0.44444444, 0.44444444, 0.45833333, 0.45833333, 0.47222222,\n",
       "          0.47222222, 0.48611111, 0.48611111, 0.5       , 0.5       ,\n",
       "          0.51388889, 0.51388889, 0.52777778, 0.52777778, 0.54166667,\n",
       "          0.54166667, 0.55555556, 0.55555556, 0.56944444, 0.56944444,\n",
       "          0.58333333, 0.58333333, 0.59722222, 0.59722222, 0.61111111,\n",
       "          0.61111111, 0.625     , 0.625     , 0.63888889, 0.63888889,\n",
       "          0.65277778, 0.65277778, 0.66666667, 0.66666667, 0.68055556,\n",
       "          0.68055556, 0.69444444, 0.69444444, 0.70833333, 0.70833333,\n",
       "          0.72222222, 0.72222222, 0.73611111, 0.73611111, 0.75      ,\n",
       "          0.75      , 0.76388889, 0.76388889, 0.77777778, 0.77777778,\n",
       "          0.79166667, 0.79166667, 0.80555556, 0.80555556, 0.81944444,\n",
       "          0.81944444, 0.83333333, 0.83333333, 0.84722222, 0.84722222,\n",
       "          0.86111111, 0.86111111, 0.875     , 0.875     , 0.88888889,\n",
       "          0.88888889, 0.90277778, 0.90277778, 0.91666667, 0.91666667,\n",
       "          0.93055556, 0.93055556, 0.94444444, 0.94444444, 0.95833333,\n",
       "          0.95833333, 0.97222222, 0.97222222, 0.98611111, 0.98611111,\n",
       "          1.        ]),\n",
       "   array([2.00000000e+00, 1.00000000e+00, 9.99999563e-01, 9.99999506e-01,\n",
       "          9.99592090e-01, 9.99549404e-01, 9.74048143e-01, 9.73958107e-01,\n",
       "          8.98024986e-01, 8.97373576e-01, 7.87354459e-01, 7.86355631e-01,\n",
       "          7.85237769e-01, 7.81894864e-01, 7.53397482e-01, 7.52687748e-01,\n",
       "          7.05187065e-01, 7.03768196e-01, 6.68015368e-01, 6.64267682e-01,\n",
       "          5.51696821e-01, 5.48788570e-01, 4.71004164e-01, 4.69374655e-01,\n",
       "          3.70531823e-01, 3.68569846e-01, 2.90269024e-01, 2.88072678e-01,\n",
       "          2.57342310e-01, 2.55633227e-01, 1.93242012e-01, 1.92784798e-01,\n",
       "          1.87414468e-01, 1.87148378e-01, 1.58301965e-01, 1.58027630e-01,\n",
       "          3.84739605e-02, 3.84699325e-02, 2.29198436e-02, 2.28847974e-02,\n",
       "          2.14157610e-02, 2.13471902e-02, 1.41933264e-02, 1.41767328e-02,\n",
       "          4.98171442e-03, 4.96160166e-03, 4.07588977e-03, 4.07565740e-03,\n",
       "          1.24378864e-03, 1.24244096e-03, 1.06942108e-03, 1.06609923e-03,\n",
       "          1.05723605e-03, 1.05243600e-03, 6.37089823e-04, 6.37050007e-04,\n",
       "          4.45581842e-04, 4.43315986e-04, 3.54797778e-04, 3.53010007e-04,\n",
       "          3.48788930e-04, 3.48556869e-04, 2.77495382e-04, 2.76987628e-04,\n",
       "          2.48565692e-04, 2.47928722e-04, 2.33570388e-04, 2.32050745e-04,\n",
       "          1.43220773e-04, 1.43138759e-04, 1.25546875e-04, 1.24869076e-04,\n",
       "          8.99256170e-05, 8.85627773e-05, 7.88178261e-05, 7.87075781e-05,\n",
       "          6.26280604e-05, 6.23367252e-05, 3.83708760e-05, 3.83432231e-05,\n",
       "          3.67766192e-05, 3.67087164e-05, 3.17673964e-05, 3.17510484e-05,\n",
       "          3.11183775e-05, 3.10497711e-05, 3.09100679e-05, 3.08635658e-05,\n",
       "          2.87455510e-05, 2.87200702e-05, 2.69937606e-05, 2.69653803e-05,\n",
       "          2.64363835e-05, 2.62325928e-05, 2.47574275e-05, 2.47007141e-05,\n",
       "          7.11423016e-06, 7.05163865e-06, 2.69542030e-06, 2.69502121e-06,\n",
       "          1.07373382e-06, 1.06730923e-06, 8.41428603e-07, 8.41219046e-07,\n",
       "          7.10890819e-07, 7.07572627e-07, 6.99073364e-07, 6.98881892e-07,\n",
       "          5.04360704e-07, 5.04299495e-07, 3.96889850e-07, 3.95343717e-07,\n",
       "          2.85067528e-07, 2.82499826e-07, 2.15818305e-07, 2.14070808e-07,\n",
       "          1.81845285e-07, 1.81728693e-07, 6.08541713e-08, 6.07657932e-08,\n",
       "          3.20731435e-08, 3.17052517e-08, 2.60760392e-08, 2.55672381e-08,\n",
       "          8.55458022e-09, 8.54297679e-09, 7.19369200e-09, 7.17271075e-09,\n",
       "          2.75902944e-09, 2.74172930e-09, 1.27194063e-09, 1.26350097e-09,\n",
       "          6.24896849e-10, 6.24112134e-10, 2.56882602e-10, 2.51568671e-10,\n",
       "          2.34506889e-10, 2.29663069e-10, 5.28344505e-11, 5.06231074e-11,\n",
       "          7.25271745e-13, 6.49803019e-13, 5.02664767e-15, 4.07367576e-15,\n",
       "          7.18334033e-21, 5.58581628e-23])),\n",
       "  'false_negatives':              0             1  y_pred  y_pred_true_label\n",
       "  826   0.995924  4.075657e-03       0                  1\n",
       "  827   0.999723  2.769876e-04       0                  1\n",
       "  828   1.000000  2.741729e-09       0                  1\n",
       "  829   0.744367  2.556332e-01       0                  1\n",
       "  831   0.999647  3.530100e-04       0                  1\n",
       "  ...        ...           ...     ...                ...\n",
       "  4949  0.998934  1.066099e-03       0                  1\n",
       "  4950  1.000000  6.498030e-13       0                  1\n",
       "  4966  0.711927  2.880727e-01       0                  1\n",
       "  4968  0.998758  1.242441e-03       0                  1\n",
       "  4969  0.631430  3.685698e-01       0                  1\n",
       "  \n",
       "  [62 rows x 4 columns],\n",
       "  'false_positives':              0         1  y_pred  y_pred_true_label\n",
       "  1     0.000071  0.999929       1                  0\n",
       "  3     0.003662  0.996338       1                  0\n",
       "  8     0.015409  0.984591       1                  0\n",
       "  22    0.246603  0.753397       1                  0\n",
       "  44    0.007962  0.992038       1                  0\n",
       "  ...        ...       ...     ...                ...\n",
       "  5572  0.176494  0.823506       1                  0\n",
       "  5581  0.472258  0.527742       1                  0\n",
       "  5584  0.109714  0.890286       1                  0\n",
       "  5587  0.441646  0.558354       1                  0\n",
       "  5602  0.000493  0.999507       1                  0\n",
       "  \n",
       "  [443 rows x 4 columns],\n",
       "  'true_positives':                  0         1  y_pred  y_pred_true_label\n",
       "  832   4.512114e-01  0.548789       1                  1\n",
       "  2334  2.136444e-01  0.786356       1                  1\n",
       "  2842  4.505955e-04  0.999549       1                  1\n",
       "  2845  2.473123e-01  0.752688       1                  1\n",
       "  2853  3.357323e-01  0.664268       1                  1\n",
       "  2860  2.604189e-02  0.973958       1                  1\n",
       "  4748  2.962318e-01  0.703768       1                  1\n",
       "  4769  1.026264e-01  0.897374       1                  1\n",
       "  4948  4.944532e-07  1.000000       1                  1\n",
       "  4967  2.181051e-01  0.781895       1                  1},\n",
       " '1XgTQnRlfJ0zpDdg2DccbR.parquet': {'model': LogisticRegression(class_weight='balanced', max_iter=10000000000.0),\n",
       "  'y_pred': array([0, 0, 1, ..., 0, 1, 0]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.95      0.90      0.93      5372\\n           1       0.05      0.11      0.07       258\\n\\n    accuracy                           0.86      5630\\n   macro avg       0.50      0.51      0.50      5630\\nweighted avg       0.91      0.86      0.89      5630\\n',\n",
       "  'confusion_matrix': array([[4834,  538],\n",
       "         [ 229,   29]]),\n",
       "  'y_pred_prob': array([[9.99999995e-01, 5.44884087e-09],\n",
       "         [9.99869906e-01, 1.30094103e-04],\n",
       "         [3.56394418e-01, 6.43605582e-01],\n",
       "         ...,\n",
       "         [9.99984071e-01, 1.59287268e-05],\n",
       "         [4.99141395e-10, 1.00000000e+00],\n",
       "         [9.96367191e-01, 3.63280903e-03]]),\n",
       "  'y_pred_prob_log': array([[-5.44884084e-09, -1.90278629e+01],\n",
       "         [-1.30102566e-04, -8.94725250e+00],\n",
       "         [-1.03171724e+00, -4.40669191e-01],\n",
       "         ...,\n",
       "         [-1.59288536e-05, -1.10473864e+01],\n",
       "         [-2.14181317e+01, -4.99141395e-10],\n",
       "         [-3.63942370e-03, -5.61774909e+00]]),\n",
       "  'accuracy': 0.863765541740675,\n",
       "  'precision': 0.05114638447971781,\n",
       "  'recall': 0.1124031007751938,\n",
       "  'f1': 0.0703030303030303,\n",
       "  'logit_roc_auc': 0.5061270902237845,\n",
       "  'fpr_tpr_thresholds': (array([0.00000000e+00, 1.86150410e-04, 6.51526433e-03, 6.51526433e-03,\n",
       "          1.22859270e-02, 1.22859270e-02, 1.50781832e-02, 1.50781832e-02,\n",
       "          1.73119881e-02, 1.73119881e-02, 1.78704393e-02, 1.78704393e-02,\n",
       "          2.15934475e-02, 2.15934475e-02, 2.71779598e-02, 2.71779598e-02,\n",
       "          2.82948622e-02, 2.82948622e-02, 3.12732688e-02, 3.12732688e-02,\n",
       "          3.35070737e-02, 3.35070737e-02, 3.66716307e-02, 3.66716307e-02,\n",
       "          4.91437081e-02, 4.91437081e-02, 5.11913626e-02, 5.11913626e-02,\n",
       "          5.15636634e-02, 5.15636634e-02, 6.64556962e-02, 6.64556962e-02,\n",
       "          6.83172003e-02, 6.83172003e-02, 7.05510052e-02, 7.05510052e-02,\n",
       "          7.09233060e-02, 7.09233060e-02, 7.18540581e-02, 7.18540581e-02,\n",
       "          7.44601638e-02, 7.44601638e-02, 7.83693224e-02, 7.83693224e-02,\n",
       "          7.98585257e-02, 7.98585257e-02, 8.26507818e-02, 8.26507818e-02,\n",
       "          8.28369322e-02, 8.28369322e-02, 8.97244974e-02, 8.97244974e-02,\n",
       "          9.38198064e-02, 9.38198064e-02, 9.51228593e-02, 9.51228593e-02,\n",
       "          9.84735666e-02, 9.84735666e-02, 1.05547282e-01, 1.05547282e-01,\n",
       "          1.10201042e-01, 1.10201042e-01, 1.27699181e-01, 1.27699181e-01,\n",
       "          1.29746835e-01, 1.29746835e-01, 1.31049888e-01, 1.31049888e-01,\n",
       "          1.31794490e-01, 1.31794490e-01, 1.34028295e-01, 1.34028295e-01,\n",
       "          1.39054356e-01, 1.39054356e-01, 1.43521966e-01, 1.43521966e-01,\n",
       "          1.44638868e-01, 1.44638868e-01, 1.54504840e-01, 1.54504840e-01,\n",
       "          1.55621742e-01, 1.55621742e-01, 1.60833954e-01, 1.60833954e-01,\n",
       "          1.66232316e-01, 1.66232316e-01, 1.71630678e-01, 1.71630678e-01,\n",
       "          1.82613552e-01, 1.82613552e-01, 1.83544304e-01, 1.83544304e-01,\n",
       "          1.86150410e-01, 1.86150410e-01, 1.97319434e-01, 1.97319434e-01,\n",
       "          1.97505585e-01, 1.97505585e-01, 1.98436337e-01, 1.98436337e-01,\n",
       "          1.99180938e-01, 1.99180938e-01, 1.99367089e-01, 1.99367089e-01,\n",
       "          2.01787044e-01, 2.01787044e-01, 2.06626955e-01, 2.06626955e-01,\n",
       "          2.14259121e-01, 2.14259121e-01, 2.25800447e-01, 2.25800447e-01,\n",
       "          2.33618764e-01, 2.33618764e-01, 2.34177215e-01, 2.34177215e-01,\n",
       "          2.39761727e-01, 2.39761727e-01, 2.44043187e-01, 2.44043187e-01,\n",
       "          2.52233805e-01, 2.52233805e-01, 2.52978407e-01, 2.52978407e-01,\n",
       "          2.54095309e-01, 2.54095309e-01, 2.67684289e-01, 2.67684289e-01,\n",
       "          2.68987342e-01, 2.68987342e-01, 2.69731943e-01, 2.69731943e-01,\n",
       "          2.74385704e-01, 2.74385704e-01, 2.76433358e-01, 2.76433358e-01,\n",
       "          2.76805659e-01, 2.76805659e-01, 2.80342517e-01, 2.80342517e-01,\n",
       "          2.86857781e-01, 2.86857781e-01, 2.88533135e-01, 2.88533135e-01,\n",
       "          2.90394639e-01, 2.90394639e-01, 2.90953090e-01, 2.90953090e-01,\n",
       "          2.96537602e-01, 2.96537602e-01, 2.97282204e-01, 2.97282204e-01,\n",
       "          2.98212956e-01, 2.98212956e-01, 2.99702159e-01, 2.99702159e-01,\n",
       "          3.02122115e-01, 3.02122115e-01, 3.03239017e-01, 3.03239017e-01,\n",
       "          3.06031273e-01, 3.06031273e-01, 3.07334326e-01, 3.07334326e-01,\n",
       "          3.08637379e-01, 3.08637379e-01, 3.10126582e-01, 3.10126582e-01,\n",
       "          3.16083395e-01, 3.16083395e-01, 3.18131050e-01, 3.18131050e-01,\n",
       "          3.23157111e-01, 3.23157111e-01, 3.29486225e-01, 3.29486225e-01,\n",
       "          3.30975428e-01, 3.30975428e-01, 3.36932241e-01, 3.36932241e-01,\n",
       "          3.46612063e-01, 3.46612063e-01, 3.56478034e-01, 3.56478034e-01,\n",
       "          3.57594937e-01, 3.57594937e-01, 3.78071482e-01, 3.78071482e-01,\n",
       "          3.82725242e-01, 3.82725242e-01, 3.91288161e-01, 3.91288161e-01,\n",
       "          3.91474311e-01, 3.91474311e-01, 3.95197319e-01, 3.95197319e-01,\n",
       "          3.98175726e-01, 3.98175726e-01, 4.02643336e-01, 4.02643336e-01,\n",
       "          4.03201787e-01, 4.03201787e-01, 4.07483246e-01, 4.07483246e-01,\n",
       "          4.09158600e-01, 4.09158600e-01, 4.11206255e-01, 4.11206255e-01,\n",
       "          4.18652271e-01, 4.18652271e-01, 4.22561430e-01, 4.22561430e-01,\n",
       "          4.23864483e-01, 4.23864483e-01, 4.25167535e-01, 4.25167535e-01,\n",
       "          4.26284438e-01, 4.26284438e-01, 4.28704393e-01, 4.28704393e-01,\n",
       "          4.33544304e-01, 4.33544304e-01, 4.36150410e-01, 4.36150410e-01,\n",
       "          4.38570365e-01, 4.38570365e-01, 4.45457930e-01, 4.45457930e-01,\n",
       "          4.50856292e-01, 4.50856292e-01, 4.51973194e-01, 4.51973194e-01,\n",
       "          4.53462398e-01, 4.53462398e-01, 4.54579300e-01, 4.54579300e-01,\n",
       "          4.77661951e-01, 4.77661951e-01, 4.81384959e-01, 4.81384959e-01,\n",
       "          4.86969471e-01, 4.86969471e-01, 4.97393894e-01, 4.97393894e-01,\n",
       "          5.00930752e-01, 5.00930752e-01, 5.04467610e-01, 5.04467610e-01,\n",
       "          5.05956813e-01, 5.05956813e-01, 5.24571854e-01, 5.24571854e-01,\n",
       "          5.38905436e-01, 5.38905436e-01, 5.44117647e-01, 5.44117647e-01,\n",
       "          5.52494415e-01, 5.52494415e-01, 5.55472822e-01, 5.55472822e-01,\n",
       "          5.58265078e-01, 5.58265078e-01, 5.61243485e-01, 5.61243485e-01,\n",
       "          5.61429635e-01, 5.61429635e-01, 5.62918838e-01, 5.62918838e-01,\n",
       "          5.65711095e-01, 5.65711095e-01, 5.66083395e-01, 5.66083395e-01,\n",
       "          5.67944899e-01, 5.67944899e-01, 5.82464631e-01, 5.82464631e-01,\n",
       "          5.84326136e-01, 5.84326136e-01, 5.87490692e-01, 5.87490692e-01,\n",
       "          5.94750558e-01, 5.94750558e-01, 6.00707372e-01, 6.00707372e-01,\n",
       "          6.09084140e-01, 6.09084140e-01, 6.17088608e-01, 6.17088608e-01,\n",
       "          6.21183917e-01, 6.21183917e-01, 6.24534624e-01, 6.24534624e-01,\n",
       "          6.28257632e-01, 6.28257632e-01, 6.30119136e-01, 6.30119136e-01,\n",
       "          6.35703649e-01, 6.35703649e-01, 6.40915860e-01, 6.40915860e-01,\n",
       "          6.41288161e-01, 6.41288161e-01, 6.42218913e-01, 6.42218913e-01,\n",
       "          6.54504840e-01, 6.54504840e-01, 6.56738645e-01, 6.56738645e-01,\n",
       "          6.59344751e-01, 6.59344751e-01, 6.63440060e-01, 6.63440060e-01,\n",
       "          6.67535369e-01, 6.67535369e-01, 6.69583023e-01, 6.69583023e-01,\n",
       "          6.71816828e-01, 6.71816828e-01, 6.73492182e-01, 6.73492182e-01,\n",
       "          6.74981385e-01, 6.74981385e-01, 6.83172003e-01, 6.83172003e-01,\n",
       "          6.84102755e-01, 6.84102755e-01, 6.84661206e-01, 6.84661206e-01,\n",
       "          6.86895011e-01, 6.86895011e-01, 6.88756515e-01, 6.88756515e-01,\n",
       "          6.96388682e-01, 6.96388682e-01, 7.03090097e-01, 7.03090097e-01,\n",
       "          7.04206999e-01, 7.04206999e-01, 7.05696203e-01, 7.05696203e-01,\n",
       "          7.13700670e-01, 7.13700670e-01, 7.14072971e-01, 7.14072971e-01,\n",
       "          7.18168280e-01, 7.18168280e-01, 7.22635890e-01, 7.22635890e-01,\n",
       "          7.26358898e-01, 7.26358898e-01, 7.33804914e-01, 7.33804914e-01,\n",
       "          7.37900223e-01, 7.37900223e-01, 7.40320179e-01, 7.40320179e-01,\n",
       "          7.45346240e-01, 7.45346240e-01, 7.47393894e-01, 7.47393894e-01,\n",
       "          7.51116902e-01, 7.51116902e-01, 7.52047655e-01, 7.52047655e-01,\n",
       "          7.56887565e-01, 7.56887565e-01, 7.62472077e-01, 7.62472077e-01,\n",
       "          7.62658228e-01, 7.62658228e-01, 7.63216679e-01, 7.63216679e-01,\n",
       "          7.70104244e-01, 7.70104244e-01, 7.73454952e-01, 7.73454952e-01,\n",
       "          7.76433358e-01, 7.76433358e-01, 7.84437826e-01, 7.84437826e-01,\n",
       "          7.96537602e-01, 7.96537602e-01, 8.05472822e-01, 8.05472822e-01,\n",
       "          8.05845123e-01, 8.05845123e-01, 8.10312733e-01, 8.10312733e-01,\n",
       "          8.17572599e-01, 8.17572599e-01, 8.18503351e-01, 8.18503351e-01,\n",
       "          8.19620253e-01, 8.19620253e-01, 8.25204765e-01, 8.25204765e-01,\n",
       "          8.26507818e-01, 8.26507818e-01, 8.27810871e-01, 8.27810871e-01,\n",
       "          8.30044676e-01, 8.30044676e-01, 8.33767684e-01, 8.33767684e-01,\n",
       "          8.37490692e-01, 8.37490692e-01, 8.42516754e-01, 8.42516754e-01,\n",
       "          8.46239762e-01, 8.46239762e-01, 8.48287416e-01, 8.48287416e-01,\n",
       "          8.54802681e-01, 8.54802681e-01, 8.56105733e-01, 8.56105733e-01,\n",
       "          8.57036485e-01, 8.57036485e-01, 8.65227103e-01, 8.65227103e-01,\n",
       "          8.81794490e-01, 8.81794490e-01, 8.87379002e-01, 8.87379002e-01,\n",
       "          8.95383470e-01, 8.95383470e-01, 8.95941921e-01, 8.95941921e-01,\n",
       "          9.02643336e-01, 9.02643336e-01, 9.07855547e-01, 9.07855547e-01,\n",
       "          9.11578555e-01, 9.11578555e-01, 9.14929263e-01, 9.14929263e-01,\n",
       "          9.15860015e-01, 9.15860015e-01, 9.23119881e-01, 9.23119881e-01,\n",
       "          9.23492182e-01, 9.23492182e-01, 9.27029039e-01, 9.27029039e-01,\n",
       "          9.30193596e-01, 9.30193596e-01, 9.30379747e-01, 9.30379747e-01,\n",
       "          9.38756515e-01, 9.38756515e-01, 9.40804170e-01, 9.40804170e-01,\n",
       "          9.41176471e-01, 9.41176471e-01, 9.42479523e-01, 9.42479523e-01,\n",
       "          9.48064036e-01, 9.48064036e-01, 9.48994788e-01, 9.48994788e-01,\n",
       "          9.50483991e-01, 9.50483991e-01, 9.51600894e-01, 9.51600894e-01,\n",
       "          9.56068503e-01, 9.56068503e-01, 9.57185406e-01, 9.57185406e-01,\n",
       "          9.67609829e-01, 9.67609829e-01, 9.69843634e-01, 9.69843634e-01,\n",
       "          9.71891288e-01, 9.71891288e-01, 9.72263589e-01, 9.72263589e-01,\n",
       "          9.74311243e-01, 9.74311243e-01, 9.79709605e-01, 9.79709605e-01,\n",
       "          9.85294118e-01, 9.85294118e-01, 9.87155622e-01, 9.87155622e-01,\n",
       "          9.95904691e-01, 9.95904691e-01, 9.96276992e-01, 9.96276992e-01,\n",
       "          1.00000000e+00]),\n",
       "   array([0.        , 0.        , 0.        , 0.00387597, 0.00387597,\n",
       "          0.00775194, 0.00775194, 0.01162791, 0.01162791, 0.01550388,\n",
       "          0.01550388, 0.01937984, 0.01937984, 0.02325581, 0.02325581,\n",
       "          0.02713178, 0.02713178, 0.03100775, 0.03100775, 0.03488372,\n",
       "          0.03488372, 0.03875969, 0.03875969, 0.04651163, 0.04651163,\n",
       "          0.0503876 , 0.0503876 , 0.05426357, 0.05426357, 0.05813953,\n",
       "          0.05813953, 0.0620155 , 0.0620155 , 0.06589147, 0.06589147,\n",
       "          0.06976744, 0.06976744, 0.07364341, 0.07364341, 0.07751938,\n",
       "          0.07751938, 0.08139535, 0.08139535, 0.08527132, 0.08527132,\n",
       "          0.08914729, 0.08914729, 0.09302326, 0.09302326, 0.09689922,\n",
       "          0.09689922, 0.10077519, 0.10077519, 0.10465116, 0.10465116,\n",
       "          0.10852713, 0.10852713, 0.1124031 , 0.1124031 , 0.11627907,\n",
       "          0.11627907, 0.12015504, 0.12015504, 0.12403101, 0.12403101,\n",
       "          0.12790698, 0.12790698, 0.13178295, 0.13178295, 0.13565891,\n",
       "          0.13565891, 0.13953488, 0.13953488, 0.14341085, 0.14341085,\n",
       "          0.14728682, 0.14728682, 0.15116279, 0.15116279, 0.15503876,\n",
       "          0.15503876, 0.15891473, 0.15891473, 0.1627907 , 0.1627907 ,\n",
       "          0.16666667, 0.16666667, 0.17054264, 0.17054264, 0.1744186 ,\n",
       "          0.1744186 , 0.17829457, 0.17829457, 0.18217054, 0.18217054,\n",
       "          0.18604651, 0.18604651, 0.18992248, 0.18992248, 0.19379845,\n",
       "          0.19379845, 0.19767442, 0.19767442, 0.20155039, 0.20155039,\n",
       "          0.20542636, 0.20542636, 0.20930233, 0.20930233, 0.21317829,\n",
       "          0.21317829, 0.21705426, 0.21705426, 0.22093023, 0.22093023,\n",
       "          0.2248062 , 0.2248062 , 0.22868217, 0.22868217, 0.23255814,\n",
       "          0.23255814, 0.23643411, 0.23643411, 0.24418605, 0.24418605,\n",
       "          0.25193798, 0.25193798, 0.25581395, 0.25581395, 0.25968992,\n",
       "          0.25968992, 0.26356589, 0.26356589, 0.26744186, 0.26744186,\n",
       "          0.27131783, 0.27131783, 0.2751938 , 0.2751938 , 0.27906977,\n",
       "          0.27906977, 0.28294574, 0.28294574, 0.28682171, 0.28682171,\n",
       "          0.29069767, 0.29069767, 0.29844961, 0.29844961, 0.30232558,\n",
       "          0.30232558, 0.30620155, 0.30620155, 0.31007752, 0.31007752,\n",
       "          0.31395349, 0.31395349, 0.31782946, 0.31782946, 0.32170543,\n",
       "          0.32170543, 0.3255814 , 0.3255814 , 0.33333333, 0.33333333,\n",
       "          0.3372093 , 0.3372093 , 0.34108527, 0.34108527, 0.34496124,\n",
       "          0.34496124, 0.34883721, 0.34883721, 0.35271318, 0.35271318,\n",
       "          0.35658915, 0.35658915, 0.36046512, 0.36046512, 0.36434109,\n",
       "          0.36434109, 0.36821705, 0.36821705, 0.37209302, 0.37209302,\n",
       "          0.37596899, 0.37596899, 0.37984496, 0.37984496, 0.38372093,\n",
       "          0.38372093, 0.3875969 , 0.3875969 , 0.39147287, 0.39147287,\n",
       "          0.39534884, 0.39534884, 0.39922481, 0.39922481, 0.40310078,\n",
       "          0.40310078, 0.40697674, 0.40697674, 0.41085271, 0.41085271,\n",
       "          0.41472868, 0.41472868, 0.41860465, 0.41860465, 0.42248062,\n",
       "          0.42248062, 0.42635659, 0.42635659, 0.43023256, 0.43023256,\n",
       "          0.43410853, 0.43410853, 0.4379845 , 0.4379845 , 0.44186047,\n",
       "          0.44186047, 0.44573643, 0.44573643, 0.4496124 , 0.4496124 ,\n",
       "          0.45348837, 0.45348837, 0.45736434, 0.45736434, 0.46124031,\n",
       "          0.46124031, 0.46511628, 0.46511628, 0.46899225, 0.46899225,\n",
       "          0.47286822, 0.47286822, 0.47674419, 0.47674419, 0.48062016,\n",
       "          0.48062016, 0.48449612, 0.48449612, 0.48837209, 0.48837209,\n",
       "          0.49224806, 0.49224806, 0.49612403, 0.49612403, 0.5       ,\n",
       "          0.5       , 0.50387597, 0.50387597, 0.50775194, 0.50775194,\n",
       "          0.51162791, 0.51162791, 0.51550388, 0.51550388, 0.51937984,\n",
       "          0.51937984, 0.52325581, 0.52325581, 0.52713178, 0.52713178,\n",
       "          0.53488372, 0.53488372, 0.53875969, 0.53875969, 0.54263566,\n",
       "          0.54263566, 0.54651163, 0.54651163, 0.5503876 , 0.5503876 ,\n",
       "          0.55426357, 0.55426357, 0.55813953, 0.55813953, 0.5620155 ,\n",
       "          0.5620155 , 0.56589147, 0.56589147, 0.57751938, 0.57751938,\n",
       "          0.58139535, 0.58139535, 0.58527132, 0.58527132, 0.58914729,\n",
       "          0.58914729, 0.59302326, 0.59302326, 0.59689922, 0.59689922,\n",
       "          0.60077519, 0.60077519, 0.60465116, 0.60465116, 0.60852713,\n",
       "          0.60852713, 0.6124031 , 0.6124031 , 0.61627907, 0.61627907,\n",
       "          0.62015504, 0.62015504, 0.62403101, 0.62403101, 0.62790698,\n",
       "          0.62790698, 0.63178295, 0.63178295, 0.63565891, 0.63565891,\n",
       "          0.63953488, 0.63953488, 0.64341085, 0.64341085, 0.65116279,\n",
       "          0.65116279, 0.65503876, 0.65503876, 0.65891473, 0.65891473,\n",
       "          0.6627907 , 0.6627907 , 0.66666667, 0.66666667, 0.67054264,\n",
       "          0.67054264, 0.6744186 , 0.6744186 , 0.67829457, 0.67829457,\n",
       "          0.68604651, 0.68604651, 0.68992248, 0.68992248, 0.69379845,\n",
       "          0.69379845, 0.69767442, 0.69767442, 0.70155039, 0.70155039,\n",
       "          0.70542636, 0.70542636, 0.70930233, 0.70930233, 0.71317829,\n",
       "          0.71317829, 0.71705426, 0.71705426, 0.72093023, 0.72093023,\n",
       "          0.7248062 , 0.7248062 , 0.72868217, 0.72868217, 0.73255814,\n",
       "          0.73255814, 0.73643411, 0.73643411, 0.74031008, 0.74031008,\n",
       "          0.74418605, 0.74418605, 0.75193798, 0.75193798, 0.75581395,\n",
       "          0.75581395, 0.75968992, 0.75968992, 0.76356589, 0.76356589,\n",
       "          0.76744186, 0.76744186, 0.77131783, 0.77131783, 0.7751938 ,\n",
       "          0.7751938 , 0.77906977, 0.77906977, 0.78294574, 0.78294574,\n",
       "          0.78682171, 0.78682171, 0.79069767, 0.79069767, 0.79457364,\n",
       "          0.79457364, 0.79844961, 0.79844961, 0.80232558, 0.80232558,\n",
       "          0.80620155, 0.80620155, 0.81395349, 0.81395349, 0.81782946,\n",
       "          0.81782946, 0.82170543, 0.82170543, 0.8255814 , 0.8255814 ,\n",
       "          0.82945736, 0.82945736, 0.83333333, 0.83333333, 0.8372093 ,\n",
       "          0.8372093 , 0.84108527, 0.84108527, 0.84496124, 0.84496124,\n",
       "          0.84883721, 0.84883721, 0.85271318, 0.85271318, 0.86046512,\n",
       "          0.86046512, 0.86434109, 0.86434109, 0.86821705, 0.86821705,\n",
       "          0.87209302, 0.87209302, 0.87596899, 0.87596899, 0.87984496,\n",
       "          0.87984496, 0.88372093, 0.88372093, 0.8875969 , 0.8875969 ,\n",
       "          0.89147287, 0.89147287, 0.89534884, 0.89534884, 0.89922481,\n",
       "          0.89922481, 0.90310078, 0.90310078, 0.90697674, 0.90697674,\n",
       "          0.91085271, 0.91085271, 0.91472868, 0.91472868, 0.91860465,\n",
       "          0.91860465, 0.92248062, 0.92248062, 0.92635659, 0.92635659,\n",
       "          0.93023256, 0.93023256, 0.93410853, 0.93410853, 0.9379845 ,\n",
       "          0.9379845 , 0.94186047, 0.94186047, 0.94573643, 0.94573643,\n",
       "          0.9496124 , 0.9496124 , 0.95348837, 0.95348837, 0.96124031,\n",
       "          0.96124031, 0.96511628, 0.96511628, 0.96899225, 0.96899225,\n",
       "          0.97674419, 0.97674419, 0.98062016, 0.98062016, 0.98449612,\n",
       "          0.98449612, 0.98837209, 0.98837209, 0.99224806, 0.99224806,\n",
       "          0.99612403, 0.99612403, 1.        , 1.        ]),\n",
       "   array([2.00000000e+00, 1.00000000e+00, 9.99952331e-01, 9.99949120e-01,\n",
       "          9.99510589e-01, 9.99417125e-01, 9.98785789e-01, 9.98773834e-01,\n",
       "          9.98322739e-01, 9.98227804e-01, 9.97912855e-01, 9.97894111e-01,\n",
       "          9.96765692e-01, 9.96730727e-01, 9.93627528e-01, 9.93467491e-01,\n",
       "          9.92918578e-01, 9.92632506e-01, 9.89450081e-01, 9.89239629e-01,\n",
       "          9.86708376e-01, 9.86386754e-01, 9.81424026e-01, 9.80975260e-01,\n",
       "          9.47969487e-01, 9.47249705e-01, 9.40746000e-01, 9.39547599e-01,\n",
       "          9.38773901e-01, 9.38399011e-01, 8.42765064e-01, 8.41432953e-01,\n",
       "          8.31338384e-01, 8.29935967e-01, 8.11178645e-01, 8.10685701e-01,\n",
       "          8.09226579e-01, 8.07517287e-01, 7.98892420e-01, 7.97389421e-01,\n",
       "          7.67161818e-01, 7.66268932e-01, 7.38314631e-01, 7.37029273e-01,\n",
       "          7.25680491e-01, 7.22554432e-01, 6.86846594e-01, 6.83783913e-01,\n",
       "          6.81981355e-01, 6.79771066e-01, 6.14994685e-01, 6.13077773e-01,\n",
       "          5.66209605e-01, 5.65558083e-01, 5.54470614e-01, 5.54344599e-01,\n",
       "          5.21327056e-01, 5.21306331e-01, 4.49046699e-01, 4.44311477e-01,\n",
       "          4.05039523e-01, 4.04817677e-01, 2.79340052e-01, 2.75276789e-01,\n",
       "          2.51724644e-01, 2.51131230e-01, 2.41799503e-01, 2.41355014e-01,\n",
       "          2.39385317e-01, 2.39275116e-01, 2.24041910e-01, 2.19966361e-01,\n",
       "          1.98670338e-01, 1.98129551e-01, 1.74782215e-01, 1.74555276e-01,\n",
       "          1.67858991e-01, 1.66647347e-01, 1.31126166e-01, 1.29164361e-01,\n",
       "          1.27184467e-01, 1.26810823e-01, 1.13669060e-01, 1.13029645e-01,\n",
       "          9.75030847e-02, 9.64671000e-02, 8.68118551e-02, 8.51589267e-02,\n",
       "          6.42551102e-02, 6.39994056e-02, 6.33039727e-02, 6.33022365e-02,\n",
       "          5.94146006e-02, 5.93063816e-02, 4.69523644e-02, 4.67171701e-02,\n",
       "          4.66624296e-02, 4.64816796e-02, 4.51007109e-02, 4.49691704e-02,\n",
       "          4.43004399e-02, 4.41262826e-02, 4.37582581e-02, 4.36053689e-02,\n",
       "          4.14444133e-02, 4.13935870e-02, 3.73696770e-02, 3.72703014e-02,\n",
       "          3.18016572e-02, 3.16508334e-02, 2.44336566e-02, 2.44145822e-02,\n",
       "          2.02379848e-02, 2.01704112e-02, 1.98535195e-02, 1.98480749e-02,\n",
       "          1.78518946e-02, 1.77461912e-02, 1.64248859e-02, 1.64156983e-02,\n",
       "          1.40895176e-02, 1.39808406e-02, 1.38499464e-02, 1.37683028e-02,\n",
       "          1.35809388e-02, 1.34647092e-02, 1.06606963e-02, 1.06592615e-02,\n",
       "          1.04374029e-02, 1.03842248e-02, 1.02240764e-02, 1.01929710e-02,\n",
       "          9.09837129e-03, 9.09478362e-03, 8.68658695e-03, 8.58940762e-03,\n",
       "          8.47510430e-03, 8.42915484e-03, 7.85275769e-03, 7.84568972e-03,\n",
       "          7.14001847e-03, 7.13007448e-03, 6.75970559e-03, 6.75319345e-03,\n",
       "          6.49792730e-03, 6.49699044e-03, 6.38244323e-03, 6.34358114e-03,\n",
       "          5.77868998e-03, 5.77583435e-03, 5.67105341e-03, 5.66917137e-03,\n",
       "          5.59988609e-03, 5.59653981e-03, 5.48167218e-03, 5.47903504e-03,\n",
       "          5.22595205e-03, 5.21657793e-03, 5.16415859e-03, 5.15039048e-03,\n",
       "          4.87927569e-03, 4.86266003e-03, 4.75946625e-03, 4.75520248e-03,\n",
       "          4.71183708e-03, 4.69672675e-03, 4.59463742e-03, 4.54966768e-03,\n",
       "          4.26186132e-03, 4.25824402e-03, 4.09934157e-03, 4.09517992e-03,\n",
       "          3.79430787e-03, 3.79391587e-03, 3.44112640e-03, 3.43144816e-03,\n",
       "          3.39327028e-03, 3.37910986e-03, 3.09561402e-03, 3.08863407e-03,\n",
       "          2.62109852e-03, 2.61817312e-03, 2.22826585e-03, 2.22291163e-03,\n",
       "          2.18890725e-03, 2.18427419e-03, 1.69501721e-03, 1.69501671e-03,\n",
       "          1.59577501e-03, 1.59415966e-03, 1.43167017e-03, 1.43123421e-03,\n",
       "          1.42990528e-03, 1.42784185e-03, 1.35197081e-03, 1.34544417e-03,\n",
       "          1.26693748e-03, 1.26601444e-03, 1.18209707e-03, 1.17351097e-03,\n",
       "          1.15666377e-03, 1.15317513e-03, 1.09484903e-03, 1.09440221e-03,\n",
       "          1.06946406e-03, 1.06787578e-03, 1.04045351e-03, 1.03862818e-03,\n",
       "          9.45827372e-04, 9.39350997e-04, 8.92549067e-04, 8.85115019e-04,\n",
       "          8.61111933e-04, 8.59659838e-04, 8.38379133e-04, 8.36390433e-04,\n",
       "          8.15028679e-04, 8.09159986e-04, 7.73380142e-04, 7.72112499e-04,\n",
       "          7.25224251e-04, 7.25006527e-04, 7.03401800e-04, 7.01921160e-04,\n",
       "          6.77061501e-04, 6.76900516e-04, 6.22335123e-04, 6.20582070e-04,\n",
       "          5.76180629e-04, 5.75688929e-04, 5.65655962e-04, 5.64595505e-04,\n",
       "          5.54670063e-04, 5.54397875e-04, 5.47491746e-04, 5.46692552e-04,\n",
       "          3.91448357e-04, 3.91133873e-04, 3.75558846e-04, 3.75540164e-04,\n",
       "          3.51557255e-04, 3.48942805e-04, 3.02957311e-04, 3.02052788e-04,\n",
       "          2.89233569e-04, 2.89014437e-04, 2.79031718e-04, 2.78230411e-04,\n",
       "          2.74893697e-04, 2.71183224e-04, 2.01587644e-04, 2.01484299e-04,\n",
       "          1.67749698e-04, 1.67699678e-04, 1.55636708e-04, 1.54707223e-04,\n",
       "          1.38253575e-04, 1.38095270e-04, 1.29779404e-04, 1.29740263e-04,\n",
       "          1.24748881e-04, 1.24345869e-04, 1.19254564e-04, 1.19243151e-04,\n",
       "          1.19013176e-04, 1.18280180e-04, 1.15500311e-04, 1.15232508e-04,\n",
       "          1.11412090e-04, 1.11040740e-04, 1.10178573e-04, 1.09997529e-04,\n",
       "          1.07339823e-04, 1.07326101e-04, 8.42468965e-05, 8.38012047e-05,\n",
       "          8.08121842e-05, 7.95123828e-05, 7.48390129e-05, 7.46057579e-05,\n",
       "          6.51902477e-05, 6.49972178e-05, 6.00703966e-05, 5.96512271e-05,\n",
       "          5.21847957e-05, 5.19618631e-05, 4.49222144e-05, 4.48620583e-05,\n",
       "          4.15928402e-05, 4.13295780e-05, 3.95866228e-05, 3.95105063e-05,\n",
       "          3.77973586e-05, 3.77800529e-05, 3.58503004e-05, 3.57753918e-05,\n",
       "          3.23714640e-05, 3.22560724e-05, 3.02085019e-05, 3.01937484e-05,\n",
       "          3.01112965e-05, 2.98350595e-05, 2.91198046e-05, 2.89329975e-05,\n",
       "          2.41111393e-05, 2.40831094e-05, 2.32835766e-05, 2.32218498e-05,\n",
       "          2.22850030e-05, 2.22387884e-05, 2.07556780e-05, 2.06479339e-05,\n",
       "          1.92025818e-05, 1.91120607e-05, 1.84498801e-05, 1.84230996e-05,\n",
       "          1.79376879e-05, 1.79268198e-05, 1.76933159e-05, 1.76744805e-05,\n",
       "          1.69808859e-05, 1.69694736e-05, 1.44519289e-05, 1.44368926e-05,\n",
       "          1.42473646e-05, 1.42431693e-05, 1.42154202e-05, 1.41618436e-05,\n",
       "          1.36716886e-05, 1.34133857e-05, 1.30203622e-05, 1.30063627e-05,\n",
       "          1.18319564e-05, 1.17897184e-05, 1.04515695e-05, 1.04458719e-05,\n",
       "          1.02829081e-05, 1.02463177e-05, 9.96779972e-06, 9.89566108e-06,\n",
       "          8.54893061e-06, 8.51475618e-06, 8.50649864e-06, 8.44585377e-06,\n",
       "          8.11865903e-06, 8.10604063e-06, 7.49154447e-06, 7.47960041e-06,\n",
       "          7.09480834e-06, 7.09435778e-06, 6.15300747e-06, 6.14387783e-06,\n",
       "          5.68314337e-06, 5.66778122e-06, 5.46140627e-06, 5.44566349e-06,\n",
       "          5.07882467e-06, 5.06739240e-06, 4.89951719e-06, 4.87784124e-06,\n",
       "          4.50603653e-06, 4.49233784e-06, 4.44558862e-06, 4.42671835e-06,\n",
       "          4.03933015e-06, 4.03597326e-06, 3.58486090e-06, 3.55641382e-06,\n",
       "          3.55611801e-06, 3.55107146e-06, 3.45717025e-06, 3.45271361e-06,\n",
       "          3.18597218e-06, 3.16306632e-06, 2.91183419e-06, 2.89998188e-06,\n",
       "          2.76826697e-06, 2.75925605e-06, 2.25129614e-06, 2.25124837e-06,\n",
       "          1.72247706e-06, 1.71966071e-06, 1.37493731e-06, 1.37399049e-06,\n",
       "          1.37167076e-06, 1.36012307e-06, 1.21684360e-06, 1.20427413e-06,\n",
       "          1.01665474e-06, 1.00804318e-06, 9.85286223e-07, 9.82913297e-07,\n",
       "          9.67232424e-07, 9.63570527e-07, 8.34699788e-07, 8.27767777e-07,\n",
       "          8.04054087e-07, 8.01134019e-07, 7.83635874e-07, 7.81014886e-07,\n",
       "          7.32602006e-07, 7.32520065e-07, 6.46271156e-07, 6.44811689e-07,\n",
       "          5.86964154e-07, 5.85073836e-07, 4.98728265e-07, 4.98466641e-07,\n",
       "          4.36101057e-07, 4.35506257e-07, 4.08411467e-07, 4.07839960e-07,\n",
       "          3.50413912e-07, 3.50318365e-07, 3.37722764e-07, 3.37044581e-07,\n",
       "          3.30134141e-07, 3.29799276e-07, 2.39959367e-07, 2.38383319e-07,\n",
       "          1.26860017e-07, 1.26737932e-07, 1.03086377e-07, 1.01735855e-07,\n",
       "          7.84471140e-08, 7.69366202e-08, 7.48374267e-08, 7.45937691e-08,\n",
       "          5.76670647e-08, 5.68602582e-08, 4.56430926e-08, 4.53583846e-08,\n",
       "          4.04240150e-08, 3.96686904e-08, 3.44889752e-08, 3.42007280e-08,\n",
       "          3.28246353e-08, 3.26940315e-08, 2.00031626e-08, 1.99373519e-08,\n",
       "          1.93162586e-08, 1.90128073e-08, 1.56488277e-08, 1.53166679e-08,\n",
       "          1.22570489e-08, 1.22557598e-08, 1.22483072e-08, 1.20837190e-08,\n",
       "          8.38446778e-09, 8.35654729e-09, 7.75324485e-09, 7.67382869e-09,\n",
       "          7.41216105e-09, 7.35394328e-09, 6.95672504e-09, 6.80656275e-09,\n",
       "          4.70965278e-09, 4.62073289e-09, 4.40349338e-09, 4.37100945e-09,\n",
       "          3.59487340e-09, 3.57314655e-09, 3.32769443e-09, 3.30344378e-09,\n",
       "          2.58075415e-09, 2.52251786e-09, 2.30543010e-09, 2.29509678e-09,\n",
       "          1.03068281e-09, 1.01755166e-09, 7.72828963e-10, 7.41865921e-10,\n",
       "          5.90163046e-10, 5.79676423e-10, 5.69306787e-10, 5.62865180e-10,\n",
       "          4.51694699e-10, 4.45460746e-10, 2.10119068e-10, 2.02546192e-10,\n",
       "          8.90824894e-11, 8.58770681e-11, 4.58145857e-11, 4.47357158e-11,\n",
       "          2.65232104e-12, 1.35439988e-12, 9.51667571e-13, 7.47955576e-13,\n",
       "          1.18668038e-16])),\n",
       "  'false_negatives':              0             1  y_pred  y_pred_true_label\n",
       "  238   0.993247  6.753193e-03       0                  1\n",
       "  239   0.995137  4.862660e-03       0                  1\n",
       "  240   1.000000  6.806563e-09       0                  1\n",
       "  271   1.000000  3.297993e-07       0                  1\n",
       "  272   0.999992  8.445854e-06       0                  1\n",
       "  ...        ...           ...     ...                ...\n",
       "  5190  0.999999  1.373990e-06       0                  1\n",
       "  5191  0.999446  5.543979e-04       0                  1\n",
       "  5192  0.999995  5.067392e-06       0                  1\n",
       "  5193  0.999453  5.466926e-04       0                  1\n",
       "  5194  0.997382  2.618173e-03       0                  1\n",
       "  \n",
       "  [229 rows x 4 columns],\n",
       "  'false_positives':                  0         1  y_pred  y_pred_true_label\n",
       "  2     3.563944e-01  0.643606       1                  0\n",
       "  4     9.042265e-02  0.909577       1                  0\n",
       "  7     5.645493e-06  0.999994       1                  0\n",
       "  10    7.048030e-02  0.929520       1                  0\n",
       "  13    2.639595e-03  0.997360       1                  0\n",
       "  ...            ...       ...     ...                ...\n",
       "  5582  2.404227e-01  0.759577       1                  0\n",
       "  5599  2.926524e-01  0.707348       1                  0\n",
       "  5610  2.851614e-04  0.999715       1                  0\n",
       "  5619  5.188697e-02  0.948113       1                  0\n",
       "  5628  4.991414e-10  1.000000       1                  0\n",
       "  \n",
       "  [538 rows x 4 columns],\n",
       "  'true_positives':              0         1  y_pred  y_pred_true_label\n",
       "  274   0.060452  0.939548       1                  1\n",
       "  1152  0.202611  0.797389       1                  1\n",
       "  1945  0.052750  0.947250       1                  1\n",
       "  2129  0.170064  0.829936       1                  1\n",
       "  2507  0.320229  0.679771       1                  1\n",
       "  2508  0.158567  0.841433       1                  1\n",
       "  2564  0.434442  0.565558       1                  1\n",
       "  2565  0.001772  0.998228       1                  1\n",
       "  2671  0.233731  0.766269       1                  1\n",
       "  2680  0.001226  0.998774       1                  1\n",
       "  2689  0.192483  0.807517       1                  1\n",
       "  2693  0.386922  0.613078       1                  1\n",
       "  2699  0.019025  0.980975       1                  1\n",
       "  2717  0.316216  0.683784       1                  1\n",
       "  2857  0.445655  0.554345       1                  1\n",
       "  2879  0.000583  0.999417       1                  1\n",
       "  2881  0.003269  0.996731       1                  1\n",
       "  2882  0.006533  0.993467       1                  1\n",
       "  2944  0.000051  0.999949       1                  1\n",
       "  2958  0.262971  0.737029       1                  1\n",
       "  2998  0.189314  0.810686       1                  1\n",
       "  3001  0.002106  0.997894       1                  1\n",
       "  3088  0.478694  0.521306       1                  1\n",
       "  3094  0.061601  0.938399       1                  1\n",
       "  3971  0.010760  0.989240       1                  1\n",
       "  4651  0.007367  0.992633       1                  1\n",
       "  4654  0.013613  0.986387       1                  1\n",
       "  4930  0.018780  0.981220       1                  1\n",
       "  4932  0.277446  0.722554       1                  1},\n",
       " '7LxbgPH3grqf6lCpLKEwo7.parquet': {'model': LogisticRegression(class_weight='balanced', max_iter=10000000000.0),\n",
       "  'y_pred': array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "         0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "         0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "         0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.99      0.86      0.92       816\\n           1       0.02      0.17      0.03        12\\n\\n    accuracy                           0.85       828\\n   macro avg       0.50      0.52      0.48       828\\nweighted avg       0.97      0.85      0.91       828\\n',\n",
       "  'confusion_matrix': array([[705, 111],\n",
       "         [ 10,   2]]),\n",
       "  'y_pred_prob': array([[9.99573825e-01, 4.26175084e-04],\n",
       "         [9.99023682e-01, 9.76317562e-04],\n",
       "         [9.99983069e-01, 1.69305447e-05],\n",
       "         ...,\n",
       "         [9.99969497e-01, 3.05026406e-05],\n",
       "         [9.99780675e-01, 2.19325386e-04],\n",
       "         [9.99999984e-01, 1.60178839e-08]]),\n",
       "  'y_pred_prob_log': array([[-4.26265922e-04, -7.76066030e+00],\n",
       "         [-9.76794471e-04, -6.93172265e+00],\n",
       "         [-1.69306881e-05, -1.09863912e+01],\n",
       "         ...,\n",
       "         [-3.05031058e-05, -1.03976973e+01],\n",
       "         [-2.19349442e-04, -8.42495415e+00],\n",
       "         [-1.60178840e-08, -1.79495600e+01]]),\n",
       "  'accuracy': 0.8538647342995169,\n",
       "  'precision': 0.017699115044247787,\n",
       "  'recall': 0.16666666666666666,\n",
       "  'f1': 0.032,\n",
       "  'logit_roc_auc': 0.5153186274509804,\n",
       "  'fpr_tpr_thresholds': (array([0.        , 0.00122549, 0.06004902, 0.06004902, 0.1127451 ,\n",
       "          0.1127451 , 0.15808824, 0.15808824, 0.20343137, 0.20343137,\n",
       "          0.20833333, 0.20833333, 0.31372549, 0.31372549, 0.56372549,\n",
       "          0.56372549, 0.59803922, 0.59803922, 0.77941176, 0.77941176,\n",
       "          0.83946078, 0.83946078, 0.90686275, 0.90686275, 0.98161765,\n",
       "          0.98161765, 1.        ]),\n",
       "   array([0.        , 0.        , 0.        , 0.08333333, 0.08333333,\n",
       "          0.16666667, 0.16666667, 0.25      , 0.25      , 0.33333333,\n",
       "          0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "          0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "          0.75      , 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "          1.        , 1.        ]),\n",
       "   array([1.99999997e+00, 9.99999971e-01, 9.20036999e-01, 9.19630947e-01,\n",
       "          6.84954836e-01, 6.82076005e-01, 3.33833097e-01, 3.32130079e-01,\n",
       "          1.05245985e-01, 1.02845129e-01, 9.98566441e-02, 9.72248922e-02,\n",
       "          1.36380295e-02, 1.30949366e-02, 2.86711966e-04, 2.83351249e-04,\n",
       "          1.73259130e-04, 1.69025415e-04, 5.71777953e-06, 5.64000058e-06,\n",
       "          9.15083441e-07, 8.84755923e-07, 5.01525591e-08, 4.94657957e-08,\n",
       "          4.50784511e-11, 2.80029876e-11, 1.54614057e-14])),\n",
       "  'false_negatives':             0             1  y_pred  y_pred_true_label\n",
       "  130  0.897155  1.028451e-01       0                  1\n",
       "  132  0.999999  8.847559e-07       0                  1\n",
       "  204  1.000000  4.946580e-08       0                  1\n",
       "  205  0.999831  1.690254e-04       0                  1\n",
       "  373  0.902775  9.722489e-02       0                  1\n",
       "  374  1.000000  2.800299e-11       0                  1\n",
       "  375  0.999994  5.640001e-06       0                  1\n",
       "  766  0.986905  1.309494e-02       0                  1\n",
       "  767  0.667870  3.321301e-01       0                  1\n",
       "  768  0.999717  2.833512e-04       0                  1,\n",
       "  'false_positives':             0         1  y_pred  y_pred_true_label\n",
       "  8    0.051815  0.948185       1                  0\n",
       "  12   0.309880  0.690120       1                  0\n",
       "  23   0.188775  0.811225       1                  0\n",
       "  25   0.414813  0.585187       1                  0\n",
       "  34   0.201709  0.798291       1                  0\n",
       "  ..        ...       ...     ...                ...\n",
       "  793  0.147132  0.852868       1                  0\n",
       "  801  0.263792  0.736208       1                  0\n",
       "  806  0.053353  0.946647       1                  0\n",
       "  807  0.022171  0.977829       1                  0\n",
       "  818  0.009507  0.990493       1                  0\n",
       "  \n",
       "  [111 rows x 4 columns],\n",
       "  'true_positives':             0         1  y_pred  y_pred_true_label\n",
       "  131  0.080369  0.919631       1                  1\n",
       "  769  0.317924  0.682076       1                  1},\n",
       " '7r367wUYs1EvyBbeyOcq39.parquet': {'model': LogisticRegression(class_weight='balanced', max_iter=10000000000.0),\n",
       "  'y_pred': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "         0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.95      0.91      0.93       873\\n           1       0.07      0.12      0.09        48\\n\\n    accuracy                           0.87       921\\n   macro avg       0.51      0.52      0.51       921\\nweighted avg       0.90      0.87      0.88       921\\n',\n",
       "  'confusion_matrix': array([[791,  82],\n",
       "         [ 42,   6]]),\n",
       "  'y_pred_prob': array([[9.99995683e-01, 4.31663490e-06],\n",
       "         [9.98558290e-01, 1.44170970e-03],\n",
       "         [9.95119834e-01, 4.88016642e-03],\n",
       "         ...,\n",
       "         [9.99860913e-01, 1.39086850e-04],\n",
       "         [9.99984381e-01, 1.56193289e-05],\n",
       "         [1.03313928e-03, 9.98966861e-01]]),\n",
       "  'y_pred_prob_log': array([[-4.31664422e-06, -1.23530344e+01],\n",
       "         [-1.44274996e-03, -6.54192558e+00],\n",
       "         [-4.89211331e-03, -5.32257596e+00],\n",
       "         ...,\n",
       "         [-1.39096524e-04, -8.88041200e+00],\n",
       "         [-1.56194509e-05, -1.10670014e+01],\n",
       "         [-6.87515327e+00, -1.03367333e-03]]),\n",
       "  'accuracy': 0.8653637350705755,\n",
       "  'precision': 0.06818181818181818,\n",
       "  'recall': 0.125,\n",
       "  'f1': 0.08823529411764705,\n",
       "  'logit_roc_auc': 0.5155355097365406,\n",
       "  'fpr_tpr_thresholds': (array([0.        , 0.00114548, 0.02520046, 0.02520046, 0.03436426,\n",
       "          0.03436426, 0.04123711, 0.04123711, 0.04352806, 0.04352806,\n",
       "          0.08934708, 0.08934708, 0.10309278, 0.10309278, 0.12485682,\n",
       "          0.12485682, 0.1443299 , 0.1443299 , 0.17411226, 0.17411226,\n",
       "          0.18442153, 0.18442153, 0.19702176, 0.19702176, 0.20847652,\n",
       "          0.20847652, 0.22451317, 0.22451317, 0.2279496 , 0.2279496 ,\n",
       "          0.23940435, 0.23940435, 0.24284078, 0.24284078, 0.25200458,\n",
       "          0.25200458, 0.3069874 , 0.3069874 , 0.30813288, 0.30813288,\n",
       "          0.3207331 , 0.3207331 , 0.35624284, 0.35624284, 0.35738832,\n",
       "          0.35738832, 0.36769759, 0.36769759, 0.40664376, 0.40664376,\n",
       "          0.40778923, 0.40778923, 0.43642612, 0.43642612, 0.45819015,\n",
       "          0.45819015, 0.47995418, 0.47995418, 0.52004582, 0.52004582,\n",
       "          0.56242841, 0.56242841, 0.64146621, 0.64146621, 0.67124857,\n",
       "          0.67124857, 0.71821306, 0.71821306, 0.73424971, 0.73424971,\n",
       "          0.74226804, 0.74226804, 0.74341352, 0.74341352, 0.79037801,\n",
       "          0.79037801, 0.91294387, 0.91294387, 0.9209622 , 0.9209622 ,\n",
       "          0.92668958, 0.92668958, 0.93356243, 0.93356243, 0.95876289,\n",
       "          0.95876289, 0.96449026, 0.96449026, 0.97250859, 0.97250859,\n",
       "          1.        ]),\n",
       "   array([0.        , 0.        , 0.        , 0.02083333, 0.02083333,\n",
       "          0.0625    , 0.0625    , 0.08333333, 0.08333333, 0.10416667,\n",
       "          0.10416667, 0.125     , 0.125     , 0.14583333, 0.14583333,\n",
       "          0.16666667, 0.16666667, 0.1875    , 0.1875    , 0.20833333,\n",
       "          0.20833333, 0.22916667, 0.22916667, 0.25      , 0.25      ,\n",
       "          0.27083333, 0.27083333, 0.29166667, 0.29166667, 0.3125    ,\n",
       "          0.3125    , 0.33333333, 0.33333333, 0.35416667, 0.35416667,\n",
       "          0.375     , 0.375     , 0.39583333, 0.39583333, 0.41666667,\n",
       "          0.41666667, 0.4375    , 0.4375    , 0.47916667, 0.47916667,\n",
       "          0.5       , 0.5       , 0.52083333, 0.52083333, 0.54166667,\n",
       "          0.54166667, 0.5625    , 0.5625    , 0.58333333, 0.58333333,\n",
       "          0.60416667, 0.60416667, 0.625     , 0.625     , 0.66666667,\n",
       "          0.66666667, 0.6875    , 0.6875    , 0.70833333, 0.70833333,\n",
       "          0.72916667, 0.72916667, 0.75      , 0.75      , 0.77083333,\n",
       "          0.77083333, 0.79166667, 0.79166667, 0.8125    , 0.8125    ,\n",
       "          0.83333333, 0.83333333, 0.875     , 0.875     , 0.89583333,\n",
       "          0.89583333, 0.91666667, 0.91666667, 0.9375    , 0.9375    ,\n",
       "          0.95833333, 0.95833333, 0.97916667, 0.97916667, 1.        ,\n",
       "          1.        ]),\n",
       "   array([1.99998541e+00, 9.99985412e-01, 9.86019471e-01, 9.84374494e-01,\n",
       "          9.67903528e-01, 9.66246811e-01, 9.38674332e-01, 9.37063031e-01,\n",
       "          9.05681670e-01, 8.89377097e-01, 5.69015915e-01, 5.44535062e-01,\n",
       "          3.90601657e-01, 3.81683666e-01, 2.18512586e-01, 2.03315630e-01,\n",
       "          1.35473048e-01, 1.34374888e-01, 7.17772957e-02, 7.01821810e-02,\n",
       "          5.37650217e-02, 5.24850486e-02, 4.63914547e-02, 4.41701792e-02,\n",
       "          3.60873419e-02, 3.57616720e-02, 2.53819864e-02, 2.47846786e-02,\n",
       "          2.34916731e-02, 2.29610981e-02, 1.95926594e-02, 1.95784206e-02,\n",
       "          1.84652493e-02, 1.79067156e-02, 1.39082084e-02, 1.38321916e-02,\n",
       "          5.43142102e-03, 5.37872324e-03, 5.17998251e-03, 5.01273046e-03,\n",
       "          3.99327025e-03, 3.89705559e-03, 2.02544632e-03, 1.84363109e-03,\n",
       "          1.83884581e-03, 1.81167069e-03, 1.65226368e-03, 1.60702278e-03,\n",
       "          9.60431677e-04, 9.15316830e-04, 9.08748903e-04, 8.99436485e-04,\n",
       "          4.96950343e-04, 4.88790503e-04, 3.71863537e-04, 3.64152021e-04,\n",
       "          2.81012013e-04, 2.76990708e-04, 1.78635022e-04, 1.74710639e-04,\n",
       "          1.11406363e-04, 1.09616201e-04, 3.88579499e-05, 3.86322233e-05,\n",
       "          2.75454692e-05, 2.73981440e-05, 1.56193289e-05, 1.54958992e-05,\n",
       "          1.27110087e-05, 1.25443806e-05, 1.15302697e-05, 1.13939384e-05,\n",
       "          1.11631874e-05, 1.05271989e-05, 5.53504771e-06, 5.46762929e-06,\n",
       "          1.95103792e-07, 1.81718881e-07, 1.48790672e-07, 1.36493940e-07,\n",
       "          9.67289899e-08, 9.32276148e-08, 6.64780009e-08, 6.27568242e-08,\n",
       "          1.88387824e-08, 1.68433290e-08, 1.41555377e-08, 1.21938370e-08,\n",
       "          8.14329990e-09, 7.60394476e-09, 1.75729700e-12])),\n",
       "  'false_negatives':             0             1  y_pred  y_pred_true_label\n",
       "  216  1.000000  7.603945e-09       0                  1\n",
       "  217  0.999961  3.863222e-05       0                  1\n",
       "  218  0.998393  1.607023e-03       0                  1\n",
       "  219  0.975215  2.478468e-02       0                  1\n",
       "  220  0.999636  3.641520e-04       0                  1\n",
       "  221  0.999987  1.254438e-05       0                  1\n",
       "  222  1.000000  6.275682e-08       0                  1\n",
       "  223  0.998042  1.958226e-03       0                  1\n",
       "  450  0.999985  1.549590e-05       0                  1\n",
       "  452  0.618316  3.816837e-01       0                  1\n",
       "  455  0.999825  1.747106e-04       0                  1\n",
       "  456  1.000000  9.322761e-08       0                  1\n",
       "  457  0.994987  5.012730e-03       0                  1\n",
       "  458  0.999995  5.467629e-06       0                  1\n",
       "  459  0.999511  4.887905e-04       0                  1\n",
       "  460  0.999989  1.052720e-05       0                  1\n",
       "  466  0.996103  3.897056e-03       0                  1\n",
       "  467  0.865625  1.343749e-01       0                  1\n",
       "  468  0.980422  1.957842e-02       0                  1\n",
       "  469  0.964238  3.576167e-02       0                  1\n",
       "  470  1.000000  1.364939e-07       0                  1\n",
       "  471  0.955830  4.417018e-02       0                  1\n",
       "  473  0.796684  2.033156e-01       0                  1\n",
       "  474  0.999822  1.784597e-04       0                  1\n",
       "  475  0.986168  1.383219e-02       0                  1\n",
       "  476  1.000000  1.932520e-07       0                  1\n",
       "  477  0.999085  9.153168e-04       0                  1\n",
       "  478  0.998188  1.811671e-03       0                  1\n",
       "  479  0.994621  5.378723e-03       0                  1\n",
       "  480  0.999973  2.739814e-05       0                  1\n",
       "  481  0.929818  7.018218e-02       0                  1\n",
       "  482  0.998156  1.843631e-03       0                  1\n",
       "  483  0.999890  1.096162e-04       0                  1\n",
       "  484  0.999101  8.994365e-04       0                  1\n",
       "  871  0.982093  1.790672e-02       0                  1\n",
       "  872  0.999723  2.769907e-04       0                  1\n",
       "  873  0.947515  5.248505e-02       0                  1\n",
       "  874  1.000000  1.817189e-07       0                  1\n",
       "  875  1.000000  1.684333e-08       0                  1\n",
       "  876  0.977039  2.296110e-02       0                  1\n",
       "  877  0.999989  1.139394e-05       0                  1\n",
       "  878  1.000000  1.219384e-08       0                  1,\n",
       "  'false_positives':             0         1  y_pred  y_pred_true_label\n",
       "  26   0.005554  0.994446       1                  0\n",
       "  33   0.030333  0.969667       1                  0\n",
       "  37   0.024316  0.975684       1                  0\n",
       "  52   0.381305  0.618695       1                  0\n",
       "  61   0.005749  0.994251       1                  0\n",
       "  ..        ...       ...     ...                ...\n",
       "  884  0.387193  0.612807       1                  0\n",
       "  889  0.168902  0.831098       1                  0\n",
       "  890  0.166367  0.833633       1                  0\n",
       "  911  0.204969  0.795031       1                  0\n",
       "  920  0.001033  0.998967       1                  0\n",
       "  \n",
       "  [82 rows x 4 columns],\n",
       "  'true_positives':             0         1  y_pred  y_pred_true_label\n",
       "  215  0.032639  0.967361       1                  1\n",
       "  451  0.015626  0.984374       1                  1\n",
       "  453  0.110623  0.889377       1                  1\n",
       "  454  0.033753  0.966247       1                  1\n",
       "  465  0.062937  0.937063       1                  1\n",
       "  472  0.455465  0.544535       1                  1},\n",
       " '6hoNS9LR1Lxb4EzMX72kXR.parquet': {'model': LogisticRegression(class_weight='balanced', max_iter=10000000000.0),\n",
       "  'y_pred': array([0, 0, 0, ..., 1, 0, 0]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.97      0.90      0.93      5701\\n           1       0.05      0.14      0.07       199\\n\\n    accuracy                           0.88      5900\\n   macro avg       0.51      0.52      0.50      5900\\nweighted avg       0.94      0.88      0.90      5900\\n',\n",
       "  'confusion_matrix': array([[5137,  564],\n",
       "         [ 172,   27]]),\n",
       "  'y_pred_prob': array([[9.93000329e-01, 6.99967076e-03],\n",
       "         [9.99987893e-01, 1.21069770e-05],\n",
       "         [9.99999958e-01, 4.21886131e-08],\n",
       "         ...,\n",
       "         [1.27283848e-02, 9.87271615e-01],\n",
       "         [9.99626960e-01, 3.73040258e-04],\n",
       "         [9.99987425e-01, 1.25747144e-05]]),\n",
       "  'y_pred_prob_log': array([[-7.02428338e-03, -4.96189216e+00],\n",
       "         [-1.21070503e-05, -1.13217287e+01],\n",
       "         [-4.21886140e-08, -1.69811155e+01],\n",
       "         ...,\n",
       "         [-4.36392076e+00, -1.28100847e-02],\n",
       "         [-3.73109855e-04, -7.89382421e+00],\n",
       "         [-1.25747935e-05, -1.12838226e+01]]),\n",
       "  'accuracy': 0.8752542372881356,\n",
       "  'precision': 0.04568527918781726,\n",
       "  'recall': 0.135678391959799,\n",
       "  'f1': 0.06835443037974683,\n",
       "  'logit_roc_auc': 0.5183741898406257,\n",
       "  'fpr_tpr_thresholds': (array([0.00000000e+00, 1.75407823e-04, 8.77039116e-04, 8.77039116e-04,\n",
       "          1.57867041e-03, 1.57867041e-03, 3.68356429e-03, 3.68356429e-03,\n",
       "          6.49008946e-03, 6.49008946e-03, 6.84090510e-03, 6.84090510e-03,\n",
       "          8.24416769e-03, 8.24416769e-03, 8.41957551e-03, 8.41957551e-03,\n",
       "          1.12261007e-02, 1.12261007e-02, 1.29801789e-02, 1.29801789e-02,\n",
       "          1.66637432e-02, 1.66637432e-02, 1.71899667e-02, 1.71899667e-02,\n",
       "          2.50833187e-02, 2.50833187e-02, 2.96439221e-02, 2.96439221e-02,\n",
       "          3.13980004e-02, 3.13980004e-02, 3.38537099e-02, 3.38537099e-02,\n",
       "          4.43781793e-02, 4.43781793e-02, 6.10419225e-02, 6.10419225e-02,\n",
       "          6.15681459e-02, 6.15681459e-02, 6.47254868e-02, 6.47254868e-02,\n",
       "          7.73548500e-02, 7.73548500e-02, 7.77056657e-02, 7.77056657e-02,\n",
       "          8.06875987e-02, 8.06875987e-02, 8.24416769e-02, 8.24416769e-02,\n",
       "          8.48973864e-02, 8.48973864e-02, 8.57744255e-02, 8.57744255e-02,\n",
       "          9.06858446e-02, 9.06858446e-02, 9.15628837e-02, 9.15628837e-02,\n",
       "          9.94562357e-02, 9.94562357e-02, 1.01911945e-01, 1.01911945e-01,\n",
       "          1.07174180e-01, 1.07174180e-01, 1.26469041e-01, 1.26469041e-01,\n",
       "          1.26644448e-01, 1.26644448e-01, 1.29626381e-01, 1.29626381e-01,\n",
       "          1.30678828e-01, 1.30678828e-01, 1.31906683e-01, 1.31906683e-01,\n",
       "          1.37519733e-01, 1.37519733e-01, 1.43659007e-01, 1.43659007e-01,\n",
       "          1.58744080e-01, 1.58744080e-01, 1.64532538e-01, 1.64532538e-01,\n",
       "          1.68742326e-01, 1.68742326e-01, 1.73127521e-01, 1.73127521e-01,\n",
       "          1.75934047e-01, 1.75934047e-01, 1.76460270e-01, 1.76460270e-01,\n",
       "          1.77863533e-01, 1.77863533e-01, 1.79091387e-01, 1.79091387e-01,\n",
       "          1.82599544e-01, 1.82599544e-01, 1.82950360e-01, 1.82950360e-01,\n",
       "          1.83301175e-01, 1.83301175e-01, 1.84529030e-01, 1.84529030e-01,\n",
       "          1.86283108e-01, 1.86283108e-01, 1.94001052e-01, 1.94001052e-01,\n",
       "          2.01543589e-01, 2.01543589e-01, 2.05051745e-01, 2.05051745e-01,\n",
       "          2.07332047e-01, 2.07332047e-01, 2.07858270e-01, 2.07858270e-01,\n",
       "          2.12243466e-01, 2.12243466e-01, 2.15751623e-01, 2.15751623e-01,\n",
       "          2.25574461e-01, 2.25574461e-01, 2.25925276e-01, 2.25925276e-01,\n",
       "          2.29959656e-01, 2.29959656e-01, 2.34695667e-01, 2.34695667e-01,\n",
       "          2.43290651e-01, 2.43290651e-01, 2.46623399e-01, 2.46623399e-01,\n",
       "          2.55569198e-01, 2.55569198e-01, 2.56095422e-01, 2.56095422e-01,\n",
       "          2.56797053e-01, 2.56797053e-01, 2.61708472e-01, 2.61708472e-01,\n",
       "          2.75039467e-01, 2.75039467e-01, 2.75214875e-01, 2.75214875e-01,\n",
       "          2.92054026e-01, 2.92054026e-01, 3.02578495e-01, 3.02578495e-01,\n",
       "          3.11524294e-01, 3.11524294e-01, 3.12752149e-01, 3.12752149e-01,\n",
       "          3.19593054e-01, 3.19593054e-01, 3.20820909e-01, 3.20820909e-01,\n",
       "          3.21522540e-01, 3.21522540e-01, 3.46430451e-01, 3.46430451e-01,\n",
       "          3.50464831e-01, 3.50464831e-01, 3.51341870e-01, 3.51341870e-01,\n",
       "          3.52218909e-01, 3.52218909e-01, 3.53095948e-01, 3.53095948e-01,\n",
       "          3.68005613e-01, 3.68005613e-01, 3.71864585e-01, 3.71864585e-01,\n",
       "          3.84143133e-01, 3.84143133e-01, 3.92211893e-01, 3.92211893e-01,\n",
       "          3.93088932e-01, 3.93088932e-01, 4.06770742e-01, 4.06770742e-01,\n",
       "          4.10278898e-01, 4.10278898e-01, 4.16242764e-01, 4.16242764e-01,\n",
       "          4.41676899e-01, 4.41676899e-01, 4.42553938e-01, 4.42553938e-01,\n",
       "          4.46237502e-01, 4.46237502e-01, 4.52025960e-01, 4.52025960e-01,\n",
       "          4.69742150e-01, 4.69742150e-01, 4.75355201e-01, 4.75355201e-01,\n",
       "          4.75706016e-01, 4.75706016e-01, 5.20259604e-01, 5.20259604e-01,\n",
       "          5.27275917e-01, 5.27275917e-01, 5.46746185e-01, 5.46746185e-01,\n",
       "          5.47447816e-01, 5.47447816e-01, 5.49728118e-01, 5.49728118e-01,\n",
       "          5.53411682e-01, 5.53411682e-01, 5.53762498e-01, 5.53762498e-01,\n",
       "          5.54990353e-01, 5.54990353e-01, 5.80424487e-01, 5.80424487e-01,\n",
       "          5.80775303e-01, 5.80775303e-01, 5.84985090e-01, 5.84985090e-01,\n",
       "          5.87265392e-01, 5.87265392e-01, 5.92878442e-01, 5.92878442e-01,\n",
       "          6.03578320e-01, 6.03578320e-01, 6.11997895e-01, 6.11997895e-01,\n",
       "          6.18312577e-01, 6.18312577e-01, 6.25153482e-01, 6.25153482e-01,\n",
       "          6.27960007e-01, 6.27960007e-01, 6.28486230e-01, 6.28486230e-01,\n",
       "          6.28661638e-01, 6.28661638e-01, 6.31292756e-01, 6.31292756e-01,\n",
       "          6.33923873e-01, 6.33923873e-01, 6.34625504e-01, 6.34625504e-01,\n",
       "          6.40940186e-01, 6.40940186e-01, 6.45325382e-01, 6.45325382e-01,\n",
       "          6.54797404e-01, 6.54797404e-01, 6.55674443e-01, 6.55674443e-01,\n",
       "          6.56726890e-01, 6.56726890e-01, 6.58656376e-01, 6.58656376e-01,\n",
       "          6.58831784e-01, 6.58831784e-01, 6.63567795e-01, 6.63567795e-01,\n",
       "          6.63918611e-01, 6.63918611e-01, 6.73566041e-01, 6.73566041e-01,\n",
       "          6.81459393e-01, 6.81459393e-01, 6.83564287e-01, 6.83564287e-01,\n",
       "          6.87247851e-01, 6.87247851e-01, 6.89878969e-01, 6.89878969e-01,\n",
       "          6.94088756e-01, 6.94088756e-01, 6.94790388e-01, 6.94790388e-01,\n",
       "          6.96895282e-01, 6.96895282e-01, 6.98123136e-01, 6.98123136e-01,\n",
       "          7.00403438e-01, 7.00403438e-01, 7.16540958e-01, 7.16540958e-01,\n",
       "          7.32853885e-01, 7.32853885e-01, 7.39694790e-01, 7.39694790e-01,\n",
       "          7.52324154e-01, 7.52324154e-01, 7.52499561e-01, 7.52499561e-01,\n",
       "          7.54779863e-01, 7.54779863e-01, 7.63024031e-01, 7.63024031e-01,\n",
       "          7.70040344e-01, 7.70040344e-01, 7.84599193e-01, 7.84599193e-01,\n",
       "          7.96526925e-01, 7.96526925e-01, 8.10208735e-01, 8.10208735e-01,\n",
       "          8.10384143e-01, 8.10384143e-01, 8.15821786e-01, 8.15821786e-01,\n",
       "          8.20908613e-01, 8.20908613e-01, 8.21084020e-01, 8.21084020e-01,\n",
       "          8.31082266e-01, 8.31082266e-01, 8.36519909e-01, 8.36519909e-01,\n",
       "          8.39151026e-01, 8.39151026e-01, 8.40729697e-01, 8.40729697e-01,\n",
       "          8.41255920e-01, 8.41255920e-01, 8.43536222e-01, 8.43536222e-01,\n",
       "          8.52657429e-01, 8.52657429e-01, 8.55288546e-01, 8.55288546e-01,\n",
       "          8.60550781e-01, 8.60550781e-01, 8.63357306e-01, 8.63357306e-01,\n",
       "          8.66690054e-01, 8.66690054e-01, 8.97035608e-01, 8.97035608e-01,\n",
       "          9.00719172e-01, 9.00719172e-01, 9.07735485e-01, 9.07735485e-01,\n",
       "          9.14225574e-01, 9.14225574e-01, 9.15102614e-01, 9.15102614e-01,\n",
       "          9.17207507e-01, 9.17207507e-01, 9.34923698e-01, 9.34923698e-01,\n",
       "          9.39835117e-01, 9.39835117e-01, 9.47903877e-01, 9.47903877e-01,\n",
       "          9.49657955e-01, 9.49657955e-01, 9.52113664e-01, 9.52113664e-01,\n",
       "          9.63690581e-01, 9.63690581e-01, 9.64041396e-01, 9.64041396e-01,\n",
       "          9.66672514e-01, 9.66672514e-01, 9.72285564e-01, 9.72285564e-01,\n",
       "          9.72636380e-01, 9.72636380e-01, 9.72811787e-01, 9.72811787e-01,\n",
       "          9.75442905e-01, 9.75442905e-01, 9.77196983e-01, 9.77196983e-01,\n",
       "          9.80705139e-01, 9.80705139e-01, 9.81582179e-01, 9.81582179e-01,\n",
       "          9.81757586e-01, 9.81757586e-01, 9.85967374e-01, 9.85967374e-01,\n",
       "          9.88247676e-01, 9.88247676e-01, 9.88598491e-01, 9.88598491e-01,\n",
       "          9.90001754e-01, 9.90001754e-01, 9.90703385e-01, 9.90703385e-01,\n",
       "          9.91405017e-01, 9.91405017e-01, 9.98421330e-01, 9.98421330e-01,\n",
       "          9.99122961e-01, 9.99122961e-01, 1.00000000e+00]),\n",
       "   array([0.        , 0.        , 0.        , 0.00502513, 0.00502513,\n",
       "          0.01005025, 0.01005025, 0.01507538, 0.01507538, 0.0201005 ,\n",
       "          0.0201005 , 0.02512563, 0.02512563, 0.03015075, 0.03015075,\n",
       "          0.03517588, 0.03517588, 0.04020101, 0.04020101, 0.04522613,\n",
       "          0.04522613, 0.05025126, 0.05025126, 0.05527638, 0.05527638,\n",
       "          0.06030151, 0.06030151, 0.06532663, 0.06532663, 0.07035176,\n",
       "          0.07035176, 0.07537688, 0.07537688, 0.08040201, 0.08040201,\n",
       "          0.08542714, 0.08542714, 0.09045226, 0.09045226, 0.09547739,\n",
       "          0.09547739, 0.10050251, 0.10050251, 0.10552764, 0.10552764,\n",
       "          0.11055276, 0.11055276, 0.11557789, 0.11557789, 0.12060302,\n",
       "          0.12060302, 0.12562814, 0.12562814, 0.13065327, 0.13065327,\n",
       "          0.13567839, 0.13567839, 0.14070352, 0.14070352, 0.14572864,\n",
       "          0.14572864, 0.15075377, 0.15075377, 0.15577889, 0.15577889,\n",
       "          0.16080402, 0.16080402, 0.16582915, 0.16582915, 0.17085427,\n",
       "          0.17085427, 0.1758794 , 0.1758794 , 0.18090452, 0.18090452,\n",
       "          0.18592965, 0.18592965, 0.19095477, 0.19095477, 0.1959799 ,\n",
       "          0.1959799 , 0.20100503, 0.20100503, 0.20603015, 0.20603015,\n",
       "          0.21105528, 0.21105528, 0.2160804 , 0.2160804 , 0.22110553,\n",
       "          0.22110553, 0.22613065, 0.22613065, 0.23115578, 0.23115578,\n",
       "          0.2361809 , 0.2361809 , 0.24120603, 0.24120603, 0.24623116,\n",
       "          0.24623116, 0.25125628, 0.25125628, 0.25628141, 0.25628141,\n",
       "          0.26130653, 0.26130653, 0.26633166, 0.26633166, 0.27135678,\n",
       "          0.27135678, 0.27638191, 0.27638191, 0.28140704, 0.28140704,\n",
       "          0.28643216, 0.28643216, 0.29145729, 0.29145729, 0.29648241,\n",
       "          0.29648241, 0.30150754, 0.30150754, 0.30653266, 0.30653266,\n",
       "          0.31155779, 0.31155779, 0.31658291, 0.31658291, 0.32160804,\n",
       "          0.32160804, 0.32663317, 0.32663317, 0.33668342, 0.33668342,\n",
       "          0.34170854, 0.34170854, 0.34673367, 0.34673367, 0.35175879,\n",
       "          0.35175879, 0.35678392, 0.35678392, 0.36180905, 0.36180905,\n",
       "          0.36683417, 0.36683417, 0.3718593 , 0.3718593 , 0.37688442,\n",
       "          0.37688442, 0.38190955, 0.38190955, 0.38693467, 0.38693467,\n",
       "          0.3919598 , 0.3919598 , 0.39698492, 0.39698492, 0.40201005,\n",
       "          0.40201005, 0.40703518, 0.40703518, 0.4120603 , 0.4120603 ,\n",
       "          0.41708543, 0.41708543, 0.42211055, 0.42211055, 0.42713568,\n",
       "          0.42713568, 0.4321608 , 0.4321608 , 0.43718593, 0.43718593,\n",
       "          0.44221106, 0.44221106, 0.44723618, 0.44723618, 0.45226131,\n",
       "          0.45226131, 0.45728643, 0.45728643, 0.46231156, 0.46231156,\n",
       "          0.46733668, 0.46733668, 0.47236181, 0.47236181, 0.47738693,\n",
       "          0.47738693, 0.48241206, 0.48241206, 0.48743719, 0.48743719,\n",
       "          0.49246231, 0.49246231, 0.49748744, 0.49748744, 0.50251256,\n",
       "          0.50251256, 0.50753769, 0.50753769, 0.51256281, 0.51256281,\n",
       "          0.51758794, 0.51758794, 0.52261307, 0.52261307, 0.52763819,\n",
       "          0.52763819, 0.53266332, 0.53266332, 0.53768844, 0.53768844,\n",
       "          0.54271357, 0.54271357, 0.54773869, 0.54773869, 0.55276382,\n",
       "          0.55276382, 0.55778894, 0.55778894, 0.56281407, 0.56281407,\n",
       "          0.5678392 , 0.5678392 , 0.57286432, 0.57286432, 0.57788945,\n",
       "          0.57788945, 0.58291457, 0.58291457, 0.5879397 , 0.5879397 ,\n",
       "          0.59296482, 0.59296482, 0.59798995, 0.59798995, 0.60301508,\n",
       "          0.60301508, 0.6080402 , 0.6080402 , 0.61306533, 0.61306533,\n",
       "          0.61809045, 0.61809045, 0.62311558, 0.62311558, 0.6281407 ,\n",
       "          0.6281407 , 0.63316583, 0.63316583, 0.63819095, 0.63819095,\n",
       "          0.64321608, 0.64321608, 0.64824121, 0.64824121, 0.65326633,\n",
       "          0.65326633, 0.65829146, 0.65829146, 0.66331658, 0.66331658,\n",
       "          0.66834171, 0.66834171, 0.67336683, 0.67336683, 0.67839196,\n",
       "          0.67839196, 0.68341709, 0.68341709, 0.68844221, 0.68844221,\n",
       "          0.69346734, 0.69346734, 0.69849246, 0.69849246, 0.70351759,\n",
       "          0.70351759, 0.70854271, 0.70854271, 0.71356784, 0.71356784,\n",
       "          0.71859296, 0.71859296, 0.72361809, 0.72361809, 0.72864322,\n",
       "          0.72864322, 0.73366834, 0.73366834, 0.73869347, 0.73869347,\n",
       "          0.74371859, 0.74371859, 0.74874372, 0.74874372, 0.75376884,\n",
       "          0.75376884, 0.75879397, 0.75879397, 0.7638191 , 0.7638191 ,\n",
       "          0.76884422, 0.76884422, 0.77386935, 0.77386935, 0.77889447,\n",
       "          0.77889447, 0.7839196 , 0.7839196 , 0.78894472, 0.78894472,\n",
       "          0.79396985, 0.79396985, 0.79899497, 0.79899497, 0.8040201 ,\n",
       "          0.8040201 , 0.80904523, 0.80904523, 0.81407035, 0.81407035,\n",
       "          0.81909548, 0.81909548, 0.8241206 , 0.8241206 , 0.82914573,\n",
       "          0.82914573, 0.83417085, 0.83417085, 0.83919598, 0.83919598,\n",
       "          0.84422111, 0.84422111, 0.84924623, 0.84924623, 0.85427136,\n",
       "          0.85427136, 0.85929648, 0.85929648, 0.86432161, 0.86432161,\n",
       "          0.87437186, 0.87437186, 0.87939698, 0.87939698, 0.88442211,\n",
       "          0.88442211, 0.88944724, 0.88944724, 0.89949749, 0.89949749,\n",
       "          0.90954774, 0.90954774, 0.91457286, 0.91457286, 0.91959799,\n",
       "          0.91959799, 0.92462312, 0.92462312, 0.92964824, 0.92964824,\n",
       "          0.93467337, 0.93467337, 0.93969849, 0.93969849, 0.94472362,\n",
       "          0.94472362, 0.94974874, 0.94974874, 0.95477387, 0.95477387,\n",
       "          0.95979899, 0.95979899, 0.96482412, 0.96482412, 0.97487437,\n",
       "          0.97487437, 0.9798995 , 0.9798995 , 0.98492462, 0.98492462,\n",
       "          0.98994975, 0.98994975, 0.99497487, 0.99497487, 1.        ,\n",
       "          1.        ]),\n",
       "   array([2.00000000e+00, 1.00000000e+00, 9.99999997e-01, 9.99999997e-01,\n",
       "          9.99999982e-01, 9.99999971e-01, 9.99999032e-01, 9.99998741e-01,\n",
       "          9.99988056e-01, 9.99987036e-01, 9.99984671e-01, 9.99984340e-01,\n",
       "          9.99966915e-01, 9.99965572e-01, 9.99964911e-01, 9.99955856e-01,\n",
       "          9.99859660e-01, 9.99841821e-01, 9.99712762e-01, 9.99704515e-01,\n",
       "          9.98847453e-01, 9.98829159e-01, 9.98719834e-01, 9.98661150e-01,\n",
       "          9.95236872e-01, 9.95062276e-01, 9.91569747e-01, 9.91479436e-01,\n",
       "          9.89327325e-01, 9.89274475e-01, 9.86662625e-01, 9.86557729e-01,\n",
       "          9.56222792e-01, 9.55948806e-01, 8.74236905e-01, 8.73737150e-01,\n",
       "          8.71825555e-01, 8.71499267e-01, 8.48881906e-01, 8.47684424e-01,\n",
       "          7.36489031e-01, 7.36118687e-01, 7.30290369e-01, 7.29653933e-01,\n",
       "          7.03523545e-01, 7.02252523e-01, 6.91164340e-01, 6.88633250e-01,\n",
       "          6.60597027e-01, 6.58915139e-01, 6.48063249e-01, 6.42772542e-01,\n",
       "          5.93310441e-01, 5.92771393e-01, 5.83996235e-01, 5.82192653e-01,\n",
       "          4.91262202e-01, 4.90898664e-01, 4.73391095e-01, 4.72391421e-01,\n",
       "          4.26604982e-01, 4.25670481e-01, 2.79794803e-01, 2.78218451e-01,\n",
       "          2.76075466e-01, 2.73507633e-01, 2.54229917e-01, 2.52950584e-01,\n",
       "          2.45604403e-01, 2.45389281e-01, 2.38843485e-01, 2.37462918e-01,\n",
       "          2.08684039e-01, 2.07306510e-01, 1.76777291e-01, 1.76292771e-01,\n",
       "          1.27668173e-01, 1.27479309e-01, 1.12907535e-01, 1.12903309e-01,\n",
       "          1.02495038e-01, 1.02176292e-01, 9.09711437e-02, 9.08545310e-02,\n",
       "          8.56155618e-02, 8.54689024e-02, 8.34701735e-02, 8.31930474e-02,\n",
       "          8.04878986e-02, 8.01379042e-02, 7.85909419e-02, 7.84177620e-02,\n",
       "          7.28739070e-02, 7.27893942e-02, 7.18599236e-02, 7.16699114e-02,\n",
       "          7.15103195e-02, 7.00452260e-02, 6.77458955e-02, 6.72848091e-02,\n",
       "          6.46516395e-02, 6.46456000e-02, 5.46614292e-02, 5.45756647e-02,\n",
       "          4.47644605e-02, 4.44709446e-02, 3.93423222e-02, 3.92744158e-02,\n",
       "          3.61279491e-02, 3.59825840e-02, 3.57110932e-02, 3.56478834e-02,\n",
       "          3.25235223e-02, 3.24306749e-02, 2.97154789e-02, 2.96761288e-02,\n",
       "          2.36946053e-02, 2.36418436e-02, 2.34671251e-02, 2.32493052e-02,\n",
       "          2.13055281e-02, 2.12115408e-02, 1.97176221e-02, 1.96244477e-02,\n",
       "          1.65390866e-02, 1.64150446e-02, 1.56838932e-02, 1.56073132e-02,\n",
       "          1.31441649e-02, 1.30124911e-02, 1.29288025e-02, 1.29268646e-02,\n",
       "          1.26281743e-02, 1.25333686e-02, 1.16875950e-02, 1.16843464e-02,\n",
       "          9.06468926e-03, 9.01184710e-03, 9.00269906e-03, 8.98741320e-03,\n",
       "          6.99967076e-03, 6.98831633e-03, 5.84879929e-03, 5.81330340e-03,\n",
       "          5.05073252e-03, 4.99988297e-03, 4.88569761e-03, 4.88142560e-03,\n",
       "          4.26512637e-03, 4.25752162e-03, 4.16533461e-03, 4.16292801e-03,\n",
       "          4.12534255e-03, 4.11932239e-03, 2.65319040e-03, 2.65121780e-03,\n",
       "          2.49645733e-03, 2.47113203e-03, 2.44772963e-03, 2.44032186e-03,\n",
       "          2.41742087e-03, 2.40133416e-03, 2.39398552e-03, 2.39235787e-03,\n",
       "          1.90519775e-03, 1.90247938e-03, 1.77439379e-03, 1.77389020e-03,\n",
       "          1.43493310e-03, 1.43080380e-03, 1.30110080e-03, 1.29985913e-03,\n",
       "          1.28760198e-03, 1.28715812e-03, 1.07113990e-03, 1.07052095e-03,\n",
       "          1.02983040e-03, 1.02960207e-03, 9.51760961e-04, 9.47150802e-04,\n",
       "          6.75813154e-04, 6.75307148e-04, 6.71367700e-04, 6.71041463e-04,\n",
       "          6.35136738e-04, 6.31058588e-04, 5.87935579e-04, 5.86621715e-04,\n",
       "          4.73882517e-04, 4.73735913e-04, 4.29180979e-04, 4.25625107e-04,\n",
       "          4.21225792e-04, 4.21170422e-04, 2.28381671e-04, 2.28094883e-04,\n",
       "          2.08677912e-04, 2.07789669e-04, 1.65041863e-04, 1.64939207e-04,\n",
       "          1.63342444e-04, 1.63238797e-04, 1.58932892e-04, 1.58760193e-04,\n",
       "          1.52980269e-04, 1.52823173e-04, 1.50986031e-04, 1.50851071e-04,\n",
       "          1.48071894e-04, 1.47571956e-04, 1.07338345e-04, 1.07163646e-04,\n",
       "          1.06229905e-04, 1.06108529e-04, 1.01368142e-04, 1.01259340e-04,\n",
       "          9.82524464e-05, 9.81721265e-05, 9.29782793e-05, 9.29546347e-05,\n",
       "          8.13239281e-05, 8.12578552e-05, 7.30183197e-05, 7.30120716e-05,\n",
       "          6.50615379e-05, 6.50185775e-05, 5.98629876e-05, 5.98374615e-05,\n",
       "          5.68949321e-05, 5.68084813e-05, 5.63973353e-05, 5.63265704e-05,\n",
       "          5.61700803e-05, 5.58287735e-05, 5.45690948e-05, 5.45134895e-05,\n",
       "          5.30580195e-05, 5.27904919e-05, 5.21772335e-05, 5.21446039e-05,\n",
       "          4.75496006e-05, 4.75298724e-05, 4.50121401e-05, 4.49438377e-05,\n",
       "          3.95690948e-05, 3.94687147e-05, 3.90400269e-05, 3.88596359e-05,\n",
       "          3.79191086e-05, 3.78737819e-05, 3.68891430e-05, 3.67819170e-05,\n",
       "          3.65619088e-05, 3.65313279e-05, 3.36699954e-05, 3.36082416e-05,\n",
       "          3.35102558e-05, 3.32837093e-05, 2.87479366e-05, 2.86842184e-05,\n",
       "          2.56224085e-05, 2.54697006e-05, 2.47587172e-05, 2.47365252e-05,\n",
       "          2.33102850e-05, 2.32919069e-05, 2.12310358e-05, 2.11492455e-05,\n",
       "          1.97678086e-05, 1.97628577e-05, 1.95105164e-05, 1.94668137e-05,\n",
       "          1.88255690e-05, 1.86917758e-05, 1.81932515e-05, 1.81854939e-05,\n",
       "          1.75149349e-05, 1.74920048e-05, 1.36855558e-05, 1.36145505e-05,\n",
       "          1.03638181e-05, 1.03323422e-05, 9.16875441e-06, 9.14149994e-06,\n",
       "          7.24872564e-06, 7.20536485e-06, 7.19253097e-06, 7.16468646e-06,\n",
       "          6.67704039e-06, 6.66283186e-06, 5.73444332e-06, 5.73428465e-06,\n",
       "          4.83912262e-06, 4.82891826e-06, 3.57840469e-06, 3.57791308e-06,\n",
       "          2.70407289e-06, 2.69507342e-06, 2.10312776e-06, 2.10241465e-06,\n",
       "          2.09913249e-06, 2.09795544e-06, 1.84869399e-06, 1.83665460e-06,\n",
       "          1.62843330e-06, 1.62128049e-06, 1.61076747e-06, 1.60152348e-06,\n",
       "          1.26275459e-06, 1.25846398e-06, 1.05071530e-06, 1.04836380e-06,\n",
       "          9.86972627e-07, 9.82520460e-07, 9.26768557e-07, 9.22770361e-07,\n",
       "          9.09315404e-07, 9.07443094e-07, 8.56365948e-07, 8.53129771e-07,\n",
       "          7.26488097e-07, 7.25088093e-07, 6.89919630e-07, 6.89349060e-07,\n",
       "          5.68276790e-07, 5.55827368e-07, 5.10562809e-07, 5.07528639e-07,\n",
       "          4.55308295e-07, 4.54385374e-07, 1.65093576e-07, 1.64773510e-07,\n",
       "          1.32084799e-07, 1.31601734e-07, 9.64550552e-08, 9.60425176e-08,\n",
       "          6.99525114e-08, 6.99499205e-08, 6.67233356e-08, 6.65538123e-08,\n",
       "          5.92330768e-08, 5.83542715e-08, 2.45330485e-08, 2.44952663e-08,\n",
       "          1.76938246e-08, 1.75279331e-08, 9.94371426e-09, 9.75338168e-09,\n",
       "          8.79439313e-09, 8.71221125e-09, 7.50279524e-09, 7.36503451e-09,\n",
       "          2.47319454e-09, 2.39666411e-09, 2.38339819e-09, 2.34709367e-09,\n",
       "          1.88537615e-09, 1.85440218e-09, 9.91302299e-10, 9.77473497e-10,\n",
       "          8.91406201e-10, 8.87561797e-10, 8.80399628e-10, 8.74455204e-10,\n",
       "          6.14878440e-10, 6.11950382e-10, 5.07385648e-10, 5.01740755e-10,\n",
       "          2.78065083e-10, 2.76485652e-10, 2.35310748e-10, 2.25349498e-10,\n",
       "          2.23338180e-10, 2.21605880e-10, 6.80724693e-11, 6.73817884e-11,\n",
       "          3.38239932e-11, 3.20200946e-11, 2.80527296e-11, 2.67418643e-11,\n",
       "          1.87208360e-11, 1.83150232e-11, 1.60517292e-11, 1.47663564e-11,\n",
       "          1.12970792e-11, 1.08992432e-11, 4.15791247e-14, 1.86211049e-14,\n",
       "          4.58910658e-15, 1.23235459e-15, 2.95351887e-19])),\n",
       "  'false_negatives':              0             1  y_pred  y_pred_true_label\n",
       "  4817  1.000000  8.875618e-10       0                1.0\n",
       "  4818  0.999971  2.868422e-05       0                1.0\n",
       "  4819  0.999329  6.710415e-04       0                1.0\n",
       "  4820  0.999942  5.834117e-05       0                1.0\n",
       "  4829  0.999981  1.946681e-05       0                1.0\n",
       "  ...        ...           ...     ...                ...\n",
       "  5288  0.999940  5.983746e-05       0                1.0\n",
       "  5289  1.000000  5.017408e-10       0                1.0\n",
       "  5290  0.993012  6.988316e-03       0                1.0\n",
       "  5291  0.726492  2.735076e-01       0                1.0\n",
       "  5292  0.996865  3.134623e-03       0                1.0\n",
       "  \n",
       "  [173 rows x 4 columns],\n",
       "  'false_positives':              0         1  y_pred  y_pred_true_label\n",
       "  7     0.077571  0.922429       1                0.0\n",
       "  9     0.385301  0.614699       1                0.0\n",
       "  10    0.047386  0.952614       1                0.0\n",
       "  13    0.029716  0.970284       1                0.0\n",
       "  18    0.112006  0.887994       1                0.0\n",
       "  ...        ...       ...     ...                ...\n",
       "  5856  0.002640  0.997360       1                0.0\n",
       "  5872  0.027636  0.972364       1                0.0\n",
       "  5877  0.384279  0.615721       1                0.0\n",
       "  5896  0.262062  0.737938       1                0.0\n",
       "  5897  0.012728  0.987272       1                0.0\n",
       "  \n",
       "  [565 rows x 4 columns],\n",
       "  'true_positives':                  0         1  y_pred  y_pred_true_label\n",
       "  4918  1.581790e-04  0.999842       1                1.0\n",
       "  4938  3.410849e-01  0.658915       1                1.0\n",
       "  4941  1.285007e-01  0.871499       1                1.0\n",
       "  4942  4.178073e-01  0.582193       1                1.0\n",
       "  4946  3.113667e-01  0.688633       1                1.0\n",
       "  4986  1.344227e-02  0.986558       1                1.0\n",
       "  4990  4.405119e-02  0.955949       1                1.0\n",
       "  5011  1.296448e-05  0.999987       1                1.0\n",
       "  5013  2.954850e-04  0.999705       1                1.0\n",
       "  5019  3.442840e-05  0.999966       1                1.0\n",
       "  5075  1.072553e-02  0.989274       1                1.0\n",
       "  5076  8.520564e-03  0.991479       1                1.0\n",
       "  5095  1.338850e-03  0.998661       1                1.0\n",
       "  5097  4.072286e-01  0.592771       1                1.0\n",
       "  5098  3.069120e-09  1.000000       1                1.0\n",
       "  5102  1.523156e-01  0.847684       1                1.0\n",
       "  5104  2.977475e-01  0.702253       1                1.0\n",
       "  5154  5.627551e-03  0.994372       1                1.0\n",
       "  5236  1.566006e-05  0.999984       1                1.0\n",
       "  5239  4.414432e-05  0.999956       1                1.0\n",
       "  5241  1.170841e-03  0.998829       1                1.0\n",
       "  5247  2.931732e-08  1.000000       1                1.0\n",
       "  5254  2.703461e-01  0.729654       1                1.0\n",
       "  5255  4.937724e-03  0.995062       1                1.0\n",
       "  5264  1.262628e-01  0.873737       1                1.0\n",
       "  5287  2.638813e-01  0.736119       1                1.0},\n",
       " '7vxD3WNDRkigLnIDHyy0cu.parquet': {'model': LogisticRegression(class_weight='balanced', max_iter=10000000000.0),\n",
       "  'y_pred': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.98      0.91      0.94       908\\n           1       0.03      0.14      0.06        22\\n\\n    accuracy                           0.89       930\\n   macro avg       0.51      0.52      0.50       930\\nweighted avg       0.96      0.89      0.92       930\\n',\n",
       "  'confusion_matrix': array([[824,  84],\n",
       "         [ 19,   3]]),\n",
       "  'y_pred_prob': array([[9.99915966e-01, 8.40338181e-05],\n",
       "         [9.82027903e-01, 1.79720969e-02],\n",
       "         [9.99978891e-01, 2.11085938e-05],\n",
       "         ...,\n",
       "         [9.99847039e-01, 1.52961398e-04],\n",
       "         [9.99997987e-01, 2.01315130e-06],\n",
       "         [7.35151476e-01, 2.64848524e-01]]),\n",
       "  'y_pred_prob_log': array([[-8.40373492e-05, -9.38429124e+00],\n",
       "         [-1.81355564e-02, -4.01893490e+00],\n",
       "         [-2.11088166e-05, -1.07658303e+01],\n",
       "         ...,\n",
       "         [-1.52973098e-04, -8.78532497e+00],\n",
       "         [-2.01315333e-06, -1.31158093e+01],\n",
       "         [-3.07678711e-01, -1.32859723e+00]]),\n",
       "  'accuracy': 0.889247311827957,\n",
       "  'precision': 0.034482758620689655,\n",
       "  'recall': 0.13636363636363635,\n",
       "  'f1': 0.05504587155963302,\n",
       "  'logit_roc_auc': 0.5219263115738887,\n",
       "  'fpr_tpr_thresholds': (array([0.        , 0.00110132, 0.04625551, 0.04625551, 0.08259912,\n",
       "          0.08259912, 0.09251101, 0.09251101, 0.1376652 , 0.1376652 ,\n",
       "          0.19162996, 0.19162996, 0.22577093, 0.22577093, 0.25660793,\n",
       "          0.25660793, 0.28964758, 0.28964758, 0.32709251, 0.32709251,\n",
       "          0.50550661, 0.50550661, 0.54845815, 0.54845815, 0.62885463,\n",
       "          0.62885463, 0.71365639, 0.71365639, 0.73788546, 0.73788546,\n",
       "          0.77312775, 0.77312775, 0.8215859 , 0.8215859 , 0.84801762,\n",
       "          0.84801762, 0.91519824, 0.91519824, 0.9339207 , 0.9339207 ,\n",
       "          0.94823789, 0.94823789, 0.95154185, 0.95154185, 1.        ]),\n",
       "   array([0.        , 0.        , 0.        , 0.04545455, 0.04545455,\n",
       "          0.09090909, 0.09090909, 0.13636364, 0.13636364, 0.18181818,\n",
       "          0.18181818, 0.22727273, 0.22727273, 0.27272727, 0.27272727,\n",
       "          0.31818182, 0.31818182, 0.36363636, 0.36363636, 0.40909091,\n",
       "          0.40909091, 0.45454545, 0.45454545, 0.5       , 0.5       ,\n",
       "          0.54545455, 0.54545455, 0.59090909, 0.59090909, 0.63636364,\n",
       "          0.63636364, 0.68181818, 0.68181818, 0.72727273, 0.72727273,\n",
       "          0.77272727, 0.77272727, 0.81818182, 0.81818182, 0.86363636,\n",
       "          0.86363636, 0.90909091, 0.90909091, 1.        , 1.        ]),\n",
       "   array([1.99999888e+00, 9.99998881e-01, 9.50466070e-01, 9.47452968e-01,\n",
       "          5.69457691e-01, 5.51741195e-01, 5.22975919e-01, 5.04618434e-01,\n",
       "          1.88727122e-01, 1.88079004e-01, 5.61291771e-02, 5.58247685e-02,\n",
       "          3.52272613e-02, 3.40885432e-02, 2.19240417e-02, 2.13715646e-02,\n",
       "          1.23588303e-02, 1.22235726e-02, 6.17502573e-03, 6.06833707e-03,\n",
       "          5.99654313e-04, 5.75844404e-04, 3.34549707e-04, 3.22423288e-04,\n",
       "          1.35884547e-04, 1.33064834e-04, 3.96292642e-05, 3.90476755e-05,\n",
       "          3.11630385e-05, 3.00616963e-05, 1.56406570e-05, 1.45321594e-05,\n",
       "          5.68546097e-06, 5.63395434e-06, 2.75961401e-06, 2.52294873e-06,\n",
       "          2.76463418e-07, 2.45084376e-07, 1.50784900e-07, 1.46547529e-07,\n",
       "          6.27356579e-08, 5.99307337e-08, 5.00724488e-08, 4.90032460e-08,\n",
       "          2.57971330e-15])),\n",
       "  'false_negatives':             0             1  y_pred  y_pred_true_label\n",
       "  214  0.944175  5.582477e-02       0                  1\n",
       "  215  1.000000  4.900325e-08       0                  1\n",
       "  218  0.811921  1.880790e-01       0                  1\n",
       "  219  0.999970  3.006170e-05       0                  1\n",
       "  220  0.999985  1.453216e-05       0                  1\n",
       "  221  1.000000  1.465475e-07       0                  1\n",
       "  524  1.000000  4.902032e-08       0                  1\n",
       "  525  1.000000  2.450844e-07       0                  1\n",
       "  526  1.000000  5.993073e-08       0                  1\n",
       "  527  0.999678  3.224233e-04       0                  1\n",
       "  693  0.999997  2.522949e-06       0                  1\n",
       "  694  0.978628  2.137156e-02       0                  1\n",
       "  695  0.999867  1.330648e-04       0                  1\n",
       "  696  0.999994  5.633954e-06       0                  1\n",
       "  697  0.993932  6.068337e-03       0                  1\n",
       "  698  0.987776  1.222357e-02       0                  1\n",
       "  699  0.999961  3.904768e-05       0                  1\n",
       "  700  0.965911  3.408854e-02       0                  1\n",
       "  701  0.999424  5.758444e-04       0                  1,\n",
       "  'false_positives':             0         1  y_pred  y_pred_true_label\n",
       "  12   0.082958  0.917042       1                  0\n",
       "  18   0.070398  0.929602       1                  0\n",
       "  33   0.001145  0.998855       1                  0\n",
       "  35   0.257328  0.742672       1                  0\n",
       "  81   0.461278  0.538722       1                  0\n",
       "  ..        ...       ...     ...                ...\n",
       "  880  0.002385  0.997615       1                  0\n",
       "  884  0.056340  0.943660       1                  0\n",
       "  900  0.295586  0.704414       1                  0\n",
       "  908  0.049534  0.950466       1                  0\n",
       "  925  0.114366  0.885634       1                  0\n",
       "  \n",
       "  [84 rows x 4 columns],\n",
       "  'true_positives':             0         1  y_pred  y_pred_true_label\n",
       "  216  0.448259  0.551741       1                  1\n",
       "  217  0.495382  0.504618       1                  1\n",
       "  523  0.052547  0.947453       1                  1},\n",
       " '2DCEgkjSeRQyMt8KovG8vF.parquet': {'model': LogisticRegression(class_weight='balanced', max_iter=10000000000.0),\n",
       "  'y_pred': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "         0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "         0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.98      0.86      0.92       822\\n           1       0.01      0.06      0.02        16\\n\\n    accuracy                           0.85       838\\n   macro avg       0.49      0.46      0.47       838\\nweighted avg       0.96      0.85      0.90       838\\n',\n",
       "  'confusion_matrix': array([[710, 112],\n",
       "         [ 15,   1]]),\n",
       "  'y_pred_prob': array([[1.00000000e+00, 4.31995264e-12],\n",
       "         [9.99999874e-01, 1.26393635e-07],\n",
       "         [9.99997441e-01, 2.55879121e-06],\n",
       "         ...,\n",
       "         [9.98697196e-01, 1.30280447e-03],\n",
       "         [9.22421597e-01, 7.75784031e-02],\n",
       "         [8.06497806e-01, 1.93502194e-01]]),\n",
       "  'y_pred_prob_log': array([[-4.31998881e-12, -2.61677767e+01],\n",
       "         [-1.26393643e-07, -1.58838647e+01],\n",
       "         [-2.55879448e-06, -1.28759756e+01],\n",
       "         ...,\n",
       "         [-1.30365386e-03, -6.64323605e+00],\n",
       "         [-8.07528965e-02, -2.55646620e+00],\n",
       "         [-2.15054102e-01, -1.64246643e+00]]),\n",
       "  'accuracy': 0.8484486873508353,\n",
       "  'precision': 0.008849557522123894,\n",
       "  'recall': 0.0625,\n",
       "  'f1': 0.015503875968992248,\n",
       "  'logit_roc_auc': 0.46312347931873477,\n",
       "  'fpr_tpr_thresholds': (array([0.        , 0.00121655, 0.0973236 , 0.0973236 , 0.16180049,\n",
       "          0.16180049, 0.16666667, 0.16666667, 0.16788321, 0.16788321,\n",
       "          0.20316302, 0.20316302, 0.28345499, 0.28345499, 0.33090024,\n",
       "          0.33090024, 0.62530414, 0.62530414, 0.63868613, 0.63868613,\n",
       "          0.68248175, 0.68248175, 0.74574209, 0.74574209, 0.82481752,\n",
       "          0.82481752, 0.84549878, 0.84549878, 0.95985401, 0.95985401,\n",
       "          0.98783455, 0.98783455, 0.99513382, 0.99513382, 1.        ]),\n",
       "   array([0.    , 0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875,\n",
       "          0.1875, 0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.375 , 0.4375,\n",
       "          0.4375, 0.5   , 0.5   , 0.5625, 0.5625, 0.625 , 0.625 , 0.6875,\n",
       "          0.6875, 0.75  , 0.75  , 0.8125, 0.8125, 0.875 , 0.875 , 0.9375,\n",
       "          0.9375, 1.    , 1.    ]),\n",
       "   array([2.00000000e+00, 1.00000000e+00, 8.74184563e-01, 8.70964744e-01,\n",
       "          2.83480182e-01, 2.81595543e-01, 2.61040274e-01, 2.27885561e-01,\n",
       "          2.25771257e-01, 2.25160372e-01, 7.75784031e-02, 7.23562067e-02,\n",
       "          1.54482684e-02, 1.49687626e-02, 5.08653353e-03, 4.93083747e-03,\n",
       "          5.47753871e-05, 5.41864360e-05, 4.26156953e-05, 4.22825216e-05,\n",
       "          1.69497445e-05, 1.67242436e-05, 4.85823528e-06, 4.65738137e-06,\n",
       "          8.87323530e-07, 8.83159501e-07, 4.49434365e-07, 4.07211548e-07,\n",
       "          1.21727678e-09, 1.18785571e-09, 7.29170873e-12, 5.07849470e-12,\n",
       "          8.72473638e-13, 8.26048437e-13, 4.35904408e-15])),\n",
       "  'false_negatives':             0             1  y_pred  y_pred_true_label\n",
       "  194  0.774840  2.251604e-01       0                  1\n",
       "  195  0.995069  4.930837e-03       0                  1\n",
       "  196  0.927644  7.235621e-02       0                  1\n",
       "  197  1.000000  5.078495e-12       0                  1\n",
       "  240  1.000000  1.187856e-09       0                  1\n",
       "  241  0.985031  1.496876e-02       0                  1\n",
       "  323  1.000000  4.072115e-07       0                  1\n",
       "  325  0.999958  4.228252e-05       0                  1\n",
       "  336  0.999983  1.672424e-05       0                  1\n",
       "  624  1.000000  8.260484e-13       0                  1\n",
       "  625  0.999995  4.657381e-06       0                  1\n",
       "  626  0.718404  2.815955e-01       0                  1\n",
       "  803  0.999999  8.831595e-07       0                  1\n",
       "  804  0.772114  2.278856e-01       0                  1\n",
       "  805  0.999946  5.418644e-05       0                  1,\n",
       "  'false_positives':                 0         1  y_pred  y_pred_true_label\n",
       "  48   1.340604e-03  0.998659       1                  0\n",
       "  58   1.761200e-01  0.823880       1                  0\n",
       "  65   2.803999e-10  1.000000       1                  0\n",
       "  69   4.257053e-06  0.999996       1                  0\n",
       "  76   2.796672e-02  0.972033       1                  0\n",
       "  ..            ...       ...     ...                ...\n",
       "  816  1.595907e-01  0.840409       1                  0\n",
       "  817  4.361552e-01  0.563845       1                  0\n",
       "  828  1.097076e-03  0.998903       1                  0\n",
       "  829  2.353080e-01  0.764692       1                  0\n",
       "  833  7.308060e-02  0.926919       1                  0\n",
       "  \n",
       "  [112 rows x 4 columns],\n",
       "  'true_positives':             0         1  y_pred  y_pred_true_label\n",
       "  324  0.129035  0.870965       1                  1},\n",
       " '2hgBlERSFYDWndqjWNOV6v.parquet': {'model': LogisticRegression(class_weight='balanced', max_iter=10000000000.0),\n",
       "  'y_pred': array([0, 0, 0, ..., 1, 0, 0]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.98      0.92      0.95      4670\\n           1       0.03      0.11      0.04        87\\n\\n    accuracy                           0.90      4757\\n   macro avg       0.50      0.52      0.50      4757\\nweighted avg       0.96      0.90      0.93      4757\\n',\n",
       "  'confusion_matrix': array([[4293,  377],\n",
       "         [  77,   10]]),\n",
       "  'y_pred_prob': array([[9.96134540e-01, 3.86546006e-03],\n",
       "         [9.99973425e-01, 2.65750696e-05],\n",
       "         [9.45038605e-01, 5.49613950e-02],\n",
       "         ...,\n",
       "         [1.24876116e-02, 9.87512388e-01],\n",
       "         [9.91824810e-01, 8.17519046e-03],\n",
       "         [1.00000000e+00, 5.56372442e-14]]),\n",
       "  'y_pred_prob_log': array([[-3.87295026e-03, -5.55567457e+00],\n",
       "         [-2.65754227e-05, -1.05355370e+01],\n",
       "         [-5.65295004e-02, -2.90112425e+00],\n",
       "         ...,\n",
       "         [-4.38301820e+00, -1.25662371e-02],\n",
       "         [-8.20879058e-03, -4.80665127e+00],\n",
       "         [-5.56221735e-14, -3.05199236e+01]]),\n",
       "  'accuracy': 0.904561698549506,\n",
       "  'precision': 0.025839793281653745,\n",
       "  'recall': 0.11494252873563218,\n",
       "  'f1': 0.04219409282700422,\n",
       "  'logit_roc_auc': 0.5171072386718847,\n",
       "  'fpr_tpr_thresholds': (array([0.00000000e+00, 2.14132762e-04, 9.20770878e-03, 9.20770878e-03,\n",
       "          1.28479657e-02, 1.28479657e-02, 1.49892934e-02, 1.49892934e-02,\n",
       "          2.14132762e-02, 2.14132762e-02, 5.09635974e-02, 5.09635974e-02,\n",
       "          5.20342612e-02, 5.20342612e-02, 5.52462527e-02, 5.52462527e-02,\n",
       "          5.93147752e-02, 5.93147752e-02, 5.99571734e-02, 5.99571734e-02,\n",
       "          6.50963597e-02, 6.50963597e-02, 8.26552463e-02, 8.26552463e-02,\n",
       "          9.16488223e-02, 9.16488223e-02, 9.97858672e-02, 9.97858672e-02,\n",
       "          1.00428266e-01, 1.00428266e-01, 1.02141328e-01, 1.02141328e-01,\n",
       "          1.23982869e-01, 1.23982869e-01, 1.26338330e-01, 1.26338330e-01,\n",
       "          1.32119914e-01, 1.32119914e-01, 1.40899358e-01, 1.40899358e-01,\n",
       "          1.47965739e-01, 1.47965739e-01, 1.61456103e-01, 1.61456103e-01,\n",
       "          1.63169165e-01, 1.63169165e-01, 1.64882227e-01, 1.64882227e-01,\n",
       "          1.80942184e-01, 1.80942184e-01, 1.89507495e-01, 1.89507495e-01,\n",
       "          2.17987152e-01, 2.17987152e-01, 2.19486081e-01, 2.19486081e-01,\n",
       "          2.28051392e-01, 2.28051392e-01, 2.82655246e-01, 2.82655246e-01,\n",
       "          2.85010707e-01, 2.85010707e-01, 2.98501071e-01, 2.98501071e-01,\n",
       "          3.14775161e-01, 3.14775161e-01, 3.53961456e-01, 3.53961456e-01,\n",
       "          3.62955032e-01, 3.62955032e-01, 3.70449679e-01, 3.70449679e-01,\n",
       "          4.13062099e-01, 4.13062099e-01, 4.41113490e-01, 4.41113490e-01,\n",
       "          4.41327623e-01, 4.41327623e-01, 4.50963597e-01, 4.50963597e-01,\n",
       "          4.59743041e-01, 4.59743041e-01, 4.60599572e-01, 4.60599572e-01,\n",
       "          4.62526767e-01, 4.62526767e-01, 4.63169165e-01, 4.63169165e-01,\n",
       "          5.00000000e-01, 5.00000000e-01, 5.15631692e-01, 5.15631692e-01,\n",
       "          5.20342612e-01, 5.20342612e-01, 5.22698073e-01, 5.22698073e-01,\n",
       "          5.75374732e-01, 5.75374732e-01, 5.92933619e-01, 5.92933619e-01,\n",
       "          5.94004283e-01, 5.94004283e-01, 5.96145610e-01, 5.96145610e-01,\n",
       "          6.27837259e-01, 6.27837259e-01, 6.42398287e-01, 6.42398287e-01,\n",
       "          6.70235546e-01, 6.70235546e-01, 6.93147752e-01, 6.93147752e-01,\n",
       "          6.96359743e-01, 6.96359743e-01, 7.00856531e-01, 7.00856531e-01,\n",
       "          7.01927195e-01, 7.01927195e-01, 7.03854390e-01, 7.03854390e-01,\n",
       "          7.04068522e-01, 7.04068522e-01, 7.40685225e-01, 7.40685225e-01,\n",
       "          7.58886510e-01, 7.58886510e-01, 7.77087794e-01, 7.77087794e-01,\n",
       "          7.95931478e-01, 7.95931478e-01, 8.10492505e-01, 8.10492505e-01,\n",
       "          8.22698073e-01, 8.22698073e-01, 8.22912206e-01, 8.22912206e-01,\n",
       "          8.24197002e-01, 8.24197002e-01, 8.35331906e-01, 8.35331906e-01,\n",
       "          8.41113490e-01, 8.41113490e-01, 8.43040685e-01, 8.43040685e-01,\n",
       "          8.49464668e-01, 8.49464668e-01, 8.61027837e-01, 8.61027837e-01,\n",
       "          8.68094218e-01, 8.68094218e-01, 8.76017131e-01, 8.76017131e-01,\n",
       "          8.88222698e-01, 8.88222698e-01, 8.93576017e-01, 8.93576017e-01,\n",
       "          9.15845824e-01, 9.15845824e-01, 9.21199143e-01, 9.21199143e-01,\n",
       "          9.32119914e-01, 9.32119914e-01, 9.50749465e-01, 9.50749465e-01,\n",
       "          9.80942184e-01, 9.80942184e-01, 9.91220557e-01, 9.91220557e-01,\n",
       "          9.92719486e-01, 9.92719486e-01, 9.98072805e-01, 9.98072805e-01,\n",
       "          1.00000000e+00, 1.00000000e+00]),\n",
       "   array([0.        , 0.        , 0.        , 0.01149425, 0.01149425,\n",
       "          0.02298851, 0.02298851, 0.03448276, 0.03448276, 0.04597701,\n",
       "          0.04597701, 0.05747126, 0.05747126, 0.06896552, 0.06896552,\n",
       "          0.08045977, 0.08045977, 0.09195402, 0.09195402, 0.10344828,\n",
       "          0.10344828, 0.11494253, 0.11494253, 0.12643678, 0.12643678,\n",
       "          0.13793103, 0.13793103, 0.14942529, 0.14942529, 0.16091954,\n",
       "          0.16091954, 0.17241379, 0.17241379, 0.18390805, 0.18390805,\n",
       "          0.1954023 , 0.1954023 , 0.20689655, 0.20689655, 0.2183908 ,\n",
       "          0.2183908 , 0.22988506, 0.22988506, 0.24137931, 0.24137931,\n",
       "          0.25287356, 0.25287356, 0.26436782, 0.26436782, 0.27586207,\n",
       "          0.27586207, 0.28735632, 0.28735632, 0.29885057, 0.29885057,\n",
       "          0.31034483, 0.31034483, 0.32183908, 0.32183908, 0.33333333,\n",
       "          0.33333333, 0.34482759, 0.34482759, 0.35632184, 0.35632184,\n",
       "          0.36781609, 0.36781609, 0.37931034, 0.37931034, 0.3908046 ,\n",
       "          0.3908046 , 0.40229885, 0.40229885, 0.4137931 , 0.4137931 ,\n",
       "          0.42528736, 0.42528736, 0.43678161, 0.43678161, 0.44827586,\n",
       "          0.44827586, 0.45977011, 0.45977011, 0.47126437, 0.47126437,\n",
       "          0.48275862, 0.48275862, 0.49425287, 0.49425287, 0.50574713,\n",
       "          0.50574713, 0.51724138, 0.51724138, 0.52873563, 0.52873563,\n",
       "          0.54022989, 0.54022989, 0.55172414, 0.55172414, 0.56321839,\n",
       "          0.56321839, 0.57471264, 0.57471264, 0.5862069 , 0.5862069 ,\n",
       "          0.59770115, 0.59770115, 0.6091954 , 0.6091954 , 0.62068966,\n",
       "          0.62068966, 0.63218391, 0.63218391, 0.64367816, 0.64367816,\n",
       "          0.65517241, 0.65517241, 0.66666667, 0.66666667, 0.67816092,\n",
       "          0.67816092, 0.68965517, 0.68965517, 0.70114943, 0.70114943,\n",
       "          0.72413793, 0.72413793, 0.73563218, 0.73563218, 0.74712644,\n",
       "          0.74712644, 0.75862069, 0.75862069, 0.77011494, 0.77011494,\n",
       "          0.7816092 , 0.7816092 , 0.79310345, 0.79310345, 0.8045977 ,\n",
       "          0.8045977 , 0.81609195, 0.81609195, 0.82758621, 0.82758621,\n",
       "          0.83908046, 0.83908046, 0.85057471, 0.85057471, 0.86206897,\n",
       "          0.86206897, 0.87356322, 0.87356322, 0.88505747, 0.88505747,\n",
       "          0.89655172, 0.89655172, 0.90804598, 0.90804598, 0.91954023,\n",
       "          0.91954023, 0.93103448, 0.93103448, 0.94252874, 0.94252874,\n",
       "          0.95402299, 0.95402299, 0.96551724, 0.96551724, 0.97701149,\n",
       "          0.97701149, 0.98850575, 0.98850575, 1.        ]),\n",
       "   array([1.99999969e+00, 9.99999686e-01, 9.97959379e-01, 9.97762572e-01,\n",
       "          9.95649593e-01, 9.95623402e-01, 9.92949712e-01, 9.92742972e-01,\n",
       "          9.83762508e-01, 9.83338284e-01, 8.48646481e-01, 8.46729733e-01,\n",
       "          8.16553375e-01, 8.13572291e-01, 7.95406382e-01, 7.94013102e-01,\n",
       "          7.59176097e-01, 7.54902227e-01, 7.50637752e-01, 7.50377718e-01,\n",
       "          6.89108137e-01, 6.84839806e-01, 4.87575853e-01, 4.84339991e-01,\n",
       "          4.23767827e-01, 4.22168988e-01, 3.38840278e-01, 3.37339636e-01,\n",
       "          3.34056868e-01, 3.32811387e-01, 3.24173395e-01, 3.23921960e-01,\n",
       "          2.03147066e-01, 2.02211785e-01, 1.91430021e-01, 1.91398497e-01,\n",
       "          1.67501070e-01, 1.67363540e-01, 1.40277572e-01, 1.40256218e-01,\n",
       "          1.22067482e-01, 1.21560493e-01, 9.58683632e-02, 9.56116480e-02,\n",
       "          9.30209464e-02, 9.25713237e-02, 9.03141908e-02, 9.00028177e-02,\n",
       "          6.48661832e-02, 6.47739269e-02, 5.69887151e-02, 5.69768325e-02,\n",
       "          3.10420211e-02, 3.08509465e-02, 3.02282777e-02, 3.00813427e-02,\n",
       "          2.55847315e-02, 2.55723372e-02, 1.02325085e-02, 1.02283348e-02,\n",
       "          9.92370798e-03, 9.83168104e-03, 7.73752553e-03, 7.67476224e-03,\n",
       "          6.08837792e-03, 6.04603813e-03, 3.39325950e-03, 3.36212237e-03,\n",
       "          2.99663663e-03, 2.98895177e-03, 2.74157382e-03, 2.73753317e-03,\n",
       "          1.47140628e-03, 1.47018315e-03, 1.03023591e-03, 1.02955553e-03,\n",
       "          1.02149000e-03, 1.01078036e-03, 8.86527532e-04, 8.85389495e-04,\n",
       "          7.70571481e-04, 7.69522607e-04, 7.58632815e-04, 7.56502911e-04,\n",
       "          7.35429535e-04, 7.31842358e-04, 7.18208519e-04, 7.17535105e-04,\n",
       "          4.37738721e-04, 4.37547984e-04, 3.59130691e-04, 3.58452096e-04,\n",
       "          3.35509615e-04, 3.35418746e-04, 3.25553282e-04, 3.24479504e-04,\n",
       "          1.75459510e-04, 1.74967590e-04, 1.41578589e-04, 1.41565387e-04,\n",
       "          1.39983353e-04, 1.39563448e-04, 1.34709886e-04, 1.34337499e-04,\n",
       "          9.30588896e-05, 9.26717537e-05, 7.68597902e-05, 7.64611675e-05,\n",
       "          5.45380297e-05, 5.43867537e-05, 3.83322602e-05, 3.82693078e-05,\n",
       "          3.68445409e-05, 3.67989025e-05, 3.50031138e-05, 3.48439605e-05,\n",
       "          3.43385548e-05, 3.42839972e-05, 3.34971611e-05, 3.34143665e-05,\n",
       "          3.32575212e-05, 3.31526431e-05, 1.88610584e-05, 1.87916339e-05,\n",
       "          1.37581181e-05, 1.36921594e-05, 9.17199601e-06, 9.17041798e-06,\n",
       "          6.42806423e-06, 6.38649293e-06, 4.61498540e-06, 4.60810936e-06,\n",
       "          3.73896132e-06, 3.67588239e-06, 3.66361605e-06, 3.65793111e-06,\n",
       "          3.53477701e-06, 3.49865915e-06, 2.64503191e-06, 2.64381803e-06,\n",
       "          2.30215762e-06, 2.26807035e-06, 2.12510159e-06, 2.12166726e-06,\n",
       "          1.79617881e-06, 1.78673391e-06, 1.40242516e-06, 1.40068230e-06,\n",
       "          1.19960710e-06, 1.19833798e-06, 9.63657431e-07, 9.48183286e-07,\n",
       "          6.74791678e-07, 6.70381569e-07, 5.52182450e-07, 5.49363591e-07,\n",
       "          2.39119627e-07, 2.38612255e-07, 2.04327807e-07, 2.03973115e-07,\n",
       "          1.40960452e-07, 1.37786349e-07, 4.59454976e-08, 4.56800286e-08,\n",
       "          2.78317705e-09, 2.77924706e-09, 3.06178435e-10, 3.03066714e-10,\n",
       "          2.20698255e-10, 2.06603365e-10, 9.82847519e-12, 6.70610333e-12,\n",
       "          1.64875704e-14, 3.98737263e-15])),\n",
       "  'false_negatives':              0             1  y_pred  y_pred_true_label\n",
       "  526   0.999967  3.315264e-05       0                  1\n",
       "  527   0.999963  3.679890e-05       0                  1\n",
       "  528   0.999998  2.268070e-06       0                  1\n",
       "  529   0.797788  2.022118e-01       0                  1\n",
       "  530   0.859744  1.402562e-01       0                  1\n",
       "  ...        ...           ...     ...                ...\n",
       "  2445  1.000000  4.568003e-08       0                  1\n",
       "  2446  0.676078  3.239220e-01       0                  1\n",
       "  3772  0.878440  1.215605e-01       0                  1\n",
       "  3773  0.998530  1.470183e-03       0                  1\n",
       "  3774  0.997262  2.737533e-03       0                  1\n",
       "  \n",
       "  [77 rows x 4 columns],\n",
       "  'false_positives':              0         1  y_pred  y_pred_true_label\n",
       "  5     0.014587  0.985413       1                  0\n",
       "  13    0.075375  0.924625       1                  0\n",
       "  25    0.332868  0.667132       1                  0\n",
       "  26    0.138265  0.861735       1                  0\n",
       "  34    0.031764  0.968236       1                  0\n",
       "  ...        ...       ...     ...                ...\n",
       "  4697  0.000911  0.999089       1                  0\n",
       "  4703  0.034164  0.965836       1                  0\n",
       "  4713  0.296659  0.703341       1                  0\n",
       "  4733  0.100985  0.899015       1                  0\n",
       "  4754  0.012488  0.987512       1                  0\n",
       "  \n",
       "  [377 rows x 4 columns],\n",
       "  'true_positives':              0         1  y_pred  y_pred_true_label\n",
       "  803   0.004377  0.995623       1                  1\n",
       "  976   0.249622  0.750378       1                  1\n",
       "  1095  0.315160  0.684840       1                  1\n",
       "  1096  0.186428  0.813572       1                  1\n",
       "  1101  0.002237  0.997763       1                  1\n",
       "  1102  0.016662  0.983338       1                  1\n",
       "  1380  0.153270  0.846730       1                  1\n",
       "  1381  0.205987  0.794013       1                  1\n",
       "  1469  0.007257  0.992743       1                  1\n",
       "  1568  0.245098  0.754902       1                  1},\n",
       " '0pIwpmg5oPcMWJXVSyrx4E.parquet': {'model': LogisticRegression(class_weight='balanced', max_iter=10000000000.0),\n",
       "  'y_pred': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.97      0.93      0.95       961\\n           1       0.03      0.07      0.04        28\\n\\n    accuracy                           0.90       989\\n   macro avg       0.50      0.50      0.50       989\\nweighted avg       0.95      0.90      0.92       989\\n',\n",
       "  'confusion_matrix': array([[893,  68],\n",
       "         [ 26,   2]]),\n",
       "  'y_pred_prob': array([[9.71723396e-01, 2.82766039e-02],\n",
       "         [9.99993797e-01, 6.20270267e-06],\n",
       "         [9.99970057e-01, 2.99432343e-05],\n",
       "         ...,\n",
       "         [9.99998399e-01, 1.60085208e-06],\n",
       "         [9.52684012e-01, 4.73159883e-02],\n",
       "         [9.99995683e-01, 4.31728293e-06]]),\n",
       "  'y_pred_prob_log': array([[-2.86840869e-02, -3.56572053e+00],\n",
       "         [-6.20272190e-06, -1.19905254e+01],\n",
       "         [-2.99436826e-05, -1.04162072e+01],\n",
       "         ...,\n",
       "         [-1.60085336e-06, -1.33449745e+01],\n",
       "         [-4.84720025e-02, -3.05090702e+00],\n",
       "         [-4.31729225e-06, -1.23528843e+01]]),\n",
       "  'accuracy': 0.9049544994944388,\n",
       "  'precision': 0.02857142857142857,\n",
       "  'recall': 0.07142857142857142,\n",
       "  'f1': 0.04081632653061224,\n",
       "  'logit_roc_auc': 0.5003344730191764,\n",
       "  'fpr_tpr_thresholds': (array([0.        , 0.00104058, 0.01248699, 0.01248699, 0.06763788,\n",
       "          0.06763788, 0.07388137, 0.07388137, 0.0905307 , 0.0905307 ,\n",
       "          0.1082206 , 0.1082206 , 0.11654527, 0.11654527, 0.12799168,\n",
       "          0.12799168, 0.14047867, 0.14047867, 0.16545265, 0.16545265,\n",
       "          0.17898023, 0.17898023, 0.18730489, 0.18730489, 0.1987513 ,\n",
       "          0.1987513 , 0.26118626, 0.26118626, 0.31009365, 0.31009365,\n",
       "          0.3673257 , 0.3673257 , 0.52965661, 0.52965661, 0.53902185,\n",
       "          0.53902185, 0.56191467, 0.56191467, 0.57440166, 0.57440166,\n",
       "          0.60353798, 0.60353798, 0.73673257, 0.73673257, 0.76690947,\n",
       "          0.76690947, 0.86264308, 0.86264308, 0.89073881, 0.89073881,\n",
       "          0.97086368, 0.97086368, 0.98231009, 0.98231009, 0.99687825,\n",
       "          0.99687825, 1.        ]),\n",
       "   array([0.        , 0.        , 0.        , 0.03571429, 0.03571429,\n",
       "          0.07142857, 0.07142857, 0.10714286, 0.10714286, 0.14285714,\n",
       "          0.14285714, 0.17857143, 0.17857143, 0.21428571, 0.21428571,\n",
       "          0.25      , 0.25      , 0.28571429, 0.28571429, 0.32142857,\n",
       "          0.32142857, 0.35714286, 0.35714286, 0.39285714, 0.39285714,\n",
       "          0.42857143, 0.42857143, 0.46428571, 0.46428571, 0.5       ,\n",
       "          0.5       , 0.53571429, 0.53571429, 0.57142857, 0.57142857,\n",
       "          0.64285714, 0.64285714, 0.67857143, 0.67857143, 0.71428571,\n",
       "          0.71428571, 0.75      , 0.75      , 0.78571429, 0.78571429,\n",
       "          0.82142857, 0.82142857, 0.85714286, 0.85714286, 0.89285714,\n",
       "          0.89285714, 0.92857143, 0.92857143, 0.96428571, 0.96428571,\n",
       "          1.        , 1.        ]),\n",
       "   array([1.99979469e+00, 9.99794685e-01, 9.92778740e-01, 9.90014715e-01,\n",
       "          5.86307512e-01, 5.74921114e-01, 4.90221231e-01, 4.70643784e-01,\n",
       "          3.15200840e-01, 3.07859203e-01, 2.12592278e-01, 2.09370814e-01,\n",
       "          1.87693136e-01, 1.87247542e-01, 1.23895105e-01, 1.23541802e-01,\n",
       "          9.00849645e-02, 8.69540224e-02, 6.27044737e-02, 6.17480153e-02,\n",
       "          4.53504639e-02, 4.42734718e-02, 3.80575179e-02, 3.60032391e-02,\n",
       "          2.85707028e-02, 2.85115298e-02, 1.18788136e-02, 1.18613804e-02,\n",
       "          6.05675278e-03, 6.04217558e-03, 3.02224095e-03, 2.91176343e-03,\n",
       "          3.93975542e-04, 3.90988855e-04, 3.65534245e-04, 3.62318843e-04,\n",
       "          2.89685698e-04, 2.89044600e-04, 2.32417002e-04, 2.29082573e-04,\n",
       "          1.60176898e-04, 1.60143210e-04, 3.16066779e-05, 3.13645076e-05,\n",
       "          1.98335216e-05, 1.95074500e-05, 3.84979682e-06, 3.74619115e-06,\n",
       "          2.04627515e-06, 1.88577255e-06, 1.74678096e-08, 1.69886813e-08,\n",
       "          2.11105635e-09, 1.85425259e-09, 1.72538023e-10, 1.40661014e-10,\n",
       "          4.63864124e-11])),\n",
       "  'false_negatives':             0             1  y_pred  y_pred_true_label\n",
       "  157  0.993958  6.042176e-03       0                  1\n",
       "  159  0.988139  1.186138e-02       0                  1\n",
       "  161  0.812752  1.872475e-01       0                  1\n",
       "  162  0.999996  3.746191e-06       0                  1\n",
       "  163  0.529356  4.706438e-01       0                  1\n",
       "  164  0.999637  3.634291e-04       0                  1\n",
       "  165  1.000000  1.698868e-08       0                  1\n",
       "  166  0.971488  2.851153e-02       0                  1\n",
       "  167  1.000000  1.854253e-09       0                  1\n",
       "  168  0.913046  8.695402e-02       0                  1\n",
       "  169  0.999969  3.136451e-05       0                  1\n",
       "  170  0.955727  4.427347e-02       0                  1\n",
       "  171  0.692141  3.078592e-01       0                  1\n",
       "  192  0.999711  2.890446e-04       0                  1\n",
       "  195  0.876458  1.235418e-01       0                  1\n",
       "  196  1.000000  1.406610e-10       0                  1\n",
       "  197  0.963997  3.600324e-02       0                  1\n",
       "  198  0.999998  1.885773e-06       0                  1\n",
       "  199  0.999771  2.290826e-04       0                  1\n",
       "  200  0.999840  1.601432e-04       0                  1\n",
       "  235  0.999638  3.623188e-04       0                  1\n",
       "  236  0.938252  6.174802e-02       0                  1\n",
       "  462  0.790629  2.093708e-01       0                  1\n",
       "  463  0.997088  2.911763e-03       0                  1\n",
       "  586  0.999980  1.950745e-05       0                  1\n",
       "  587  0.999609  3.909889e-04       0                  1,\n",
       "  'false_positives':             0         1  y_pred  y_pred_true_label\n",
       "  42   0.142229  0.857771       1                  0\n",
       "  46   0.010556  0.989444       1                  0\n",
       "  81   0.486304  0.513696       1                  0\n",
       "  87   0.012698  0.987302       1                  0\n",
       "  96   0.024348  0.975652       1                  0\n",
       "  ..        ...       ...     ...                ...\n",
       "  938  0.285761  0.714239       1                  0\n",
       "  947  0.298807  0.701193       1                  0\n",
       "  948  0.359708  0.640292       1                  0\n",
       "  969  0.161227  0.838773       1                  0\n",
       "  971  0.002276  0.997724       1                  0\n",
       "  \n",
       "  [68 rows x 4 columns],\n",
       "  'true_positives':             0         1  y_pred  y_pred_true_label\n",
       "  158  0.009985  0.990015       1                  1\n",
       "  160  0.425079  0.574921       1                  1}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc93f372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0989a36c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ed751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f9f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be9169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c7e7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dec1582",
   "metadata": {},
   "source": [
    "## Create a single model used for testing Random Forest and Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1886e53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29296, 5514)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(828, 5514)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dfs = []\n",
    "\n",
    "test_podcast = '7LxbgPH3grqf6lCpLKEwo7.parquet'\n",
    "for key, val in loaded_parquet_df.items():\n",
    "    if key != test_podcast:\n",
    "        train_dfs.append(val)\n",
    "    \n",
    "# get the training set\n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
    "train_set = pd.concat(train_dfs).dropna()\n",
    "print(train_set.shape)\n",
    "\n",
    "# get the test set\n",
    "test_set = loaded_parquet_df[test_podcast].dropna()\n",
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c00ad7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29296, 5513)\n",
      "(29296,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = train_set.drop('y', axis=1), train_set['y']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adb68739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(828, 5513)\n",
      "(828,)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = test_set.drop('y', axis=1), test_set['y']\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e107bf7c",
   "metadata": {},
   "source": [
    "# Modeling with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea8a6443",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smaller = X_train.head(10000)\n",
    "y_train_smaller = y_train.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24040861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.99\n",
      "CPU times: user 7min 47s, sys: 22.4 ms, total: 7min 47s\n",
      "Wall time: 7min 47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:722: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rmf = RandomForestClassifier(random_state = 34)\n",
    "rmf.fit(X_train_smaller, y_train_smaller)\n",
    "\n",
    "y_pred_rmf = rmf.predict(X_test)\n",
    "y_pred_prob_rmf = rmf.predict_proba(X_test)\n",
    "y_pred_prob_log_rmf = rmf.predict_log_proba(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(rmf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04b581ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       816\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.99       828\n",
      "   macro avg       0.49      0.50      0.50       828\n",
      "weighted avg       0.97      0.99      0.98       828\n",
      "\n",
      "[[816   0]\n",
      " [ 12   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rmf))\n",
    "print(confusion_matrix(y_test, y_pred_rmf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e262bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smaller = X_train.head(12000)\n",
    "y_train_smaller = y_train.head(12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5491bf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.99\n",
      "CPU times: user 12min 29s, sys: 42.8 ms, total: 12min 29s\n",
      "Wall time: 12min 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:722: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rmf = RandomForestClassifier(random_state = 34)\n",
    "rmf.fit(X_train_smaller, y_train_smaller)\n",
    "\n",
    "y_pred_rmf = rmf.predict(X_test)\n",
    "y_pred_prob_rmf = rmf.predict_proba(X_test)\n",
    "y_pred_prob_log_rmf = rmf.predict_log_proba(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(rmf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f44543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       816\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.99       828\n",
      "   macro avg       0.49      0.50      0.50       828\n",
      "weighted avg       0.97      0.99      0.98       828\n",
      "\n",
      "[[816   0]\n",
      " [ 12   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rmf))\n",
    "print(confusion_matrix(y_test, y_pred_rmf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a223487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smaller = X_train.head(15000)\n",
    "y_train_smaller = y_train.head(15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9262b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.99\n",
      "CPU times: user 20min, sys: 33.8 ms, total: 20min\n",
      "Wall time: 20min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sklearn/ensemble/_forest.py:722: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rmf = RandomForestClassifier(random_state = 34)\n",
    "rmf.fit(X_train_smaller, y_train_smaller)\n",
    "\n",
    "y_pred_rmf = rmf.predict(X_test)\n",
    "y_pred_prob_rmf = rmf.predict_proba(X_test)\n",
    "y_pred_prob_log_rmf = rmf.predict_log_proba(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(rmf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7df63da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       816\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.99       828\n",
      "   macro avg       0.49      0.50      0.50       828\n",
      "weighted avg       0.97      0.99      0.98       828\n",
      "\n",
      "[[816   0]\n",
      " [ 12   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rmf))\n",
    "print(confusion_matrix(y_test, y_pred_rmf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1001d4cd",
   "metadata": {},
   "source": [
    "## Modeling with AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ce7da76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.98\n",
      "CPU times: user 3.5 s, sys: 6 s, total: 3.5 s\n",
      "Wall time: 3.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Initialise the model with Decision Tree classifier as the base model\n",
    "boost = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(), \n",
    "                            algorithm = 'SAMME.R', learning_rate=1,random_state = 10)\n",
    "\n",
    "X_train_smaller = X_train.head(1000)\n",
    "y_train_smaller = y_train.head(1000)\n",
    "\n",
    "# Fit on the entire data\n",
    "boost.fit(X_train_smaller,y_train_smaller)\n",
    "\n",
    "y_pred_boost = boost.predict(X_test)\n",
    "y_pred_prob_boost = boost.predict_proba(X_test)\n",
    "y_pred_prob_log_boost = boost.predict_log_proba(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(boost.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50a973f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[812   4]\n",
      " [ 12   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       816\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.98       828\n",
      "   macro avg       0.49      0.50      0.50       828\n",
      "weighted avg       0.97      0.98      0.98       828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_boost))\n",
    "print(classification_report(y_test, y_pred_boost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "297e13f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.97\n",
      "CPU times: user 55.2 s, sys: 339 s, total: 55.2 s\n",
      "Wall time: 55.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Initialise the model with Decision Tree classifier as the base model\n",
    "boost = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(), \n",
    "                            algorithm = 'SAMME.R', learning_rate=1,random_state = 10)\n",
    "\n",
    "X_train_smaller = X_train.head(2000)\n",
    "y_train_smaller = y_train.head(2000)\n",
    "\n",
    "# Fit on the entire data\n",
    "boost.fit(X_train_smaller,y_train_smaller)\n",
    "\n",
    "y_pred_boost = boost.predict(X_test)\n",
    "y_pred_prob_boost = boost.predict_proba(X_test)\n",
    "y_pred_prob_log_boost = boost.predict_log_proba(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(boost.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b85c566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[801  15]\n",
      " [ 12   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       816\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.97       828\n",
      "   macro avg       0.49      0.49      0.49       828\n",
      "weighted avg       0.97      0.97      0.97       828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_boost))\n",
    "print(classification_report(y_test, y_pred_boost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "030e8db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.97\n",
      "CPU times: user 3min 8s, sys: 8.97 ms, total: 3min 8s\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Initialise the model with Decision Tree classifier as the base model\n",
    "boost = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(), \n",
    "                            algorithm = 'SAMME.R', learning_rate=1,random_state = 10)\n",
    "\n",
    "X_train_smaller = X_train.head(4000)\n",
    "y_train_smaller = y_train.head(4000)\n",
    "\n",
    "# Fit on the entire data\n",
    "boost.fit(X_train_smaller,y_train_smaller)\n",
    "\n",
    "y_pred_boost = boost.predict(X_test)\n",
    "y_pred_prob_boost = boost.predict_proba(X_test)\n",
    "y_pred_prob_log_boost = boost.predict_log_proba(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(boost.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c61aea9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[807   9]\n",
      " [ 12   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       816\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.97       828\n",
      "   macro avg       0.49      0.49      0.49       828\n",
      "weighted avg       0.97      0.97      0.97       828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_boost))\n",
    "print(classification_report(y_test, y_pred_boost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8e32521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.96\n",
      "CPU times: user 55min 32s, sys: 86.3 ms, total: 55min 32s\n",
      "Wall time: 55min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Initialise the model with Decision Tree classifier as the base model\n",
    "boost = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(), \n",
    "                            algorithm = 'SAMME.R', learning_rate=1,random_state = 10)\n",
    "\n",
    "X_train_smaller = X_train.head(15000)\n",
    "y_train_smaller = y_train.head(15000)\n",
    "\n",
    "# Fit on the entire data\n",
    "boost.fit(X_train_smaller,y_train_smaller)\n",
    "\n",
    "y_pred_boost = boost.predict(X_test)\n",
    "y_pred_prob_boost = boost.predict_proba(X_test)\n",
    "y_pred_prob_log_boost = boost.predict_log_proba(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(boost.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d02c136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[798  18]\n",
      " [ 12   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       816\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.96       828\n",
      "   macro avg       0.49      0.49      0.49       828\n",
      "weighted avg       0.97      0.96      0.97       828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_boost))\n",
    "print(classification_report(y_test, y_pred_boost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6317d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
